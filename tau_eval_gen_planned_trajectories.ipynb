{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of planned agent trajectories\n",
    "\n",
    "- This Jupyter notebook implements a system for generating planned trajectory sequences for agent evaluation in the TAU (Task-oriented Agent Understanding) benchmark framework using open source models that fit in a RTX 4090.\n",
    "- Rather than executing the actual agent steps, this notebook focuses solely on generating a zero shot planned trajectories (e.g. sequence of tools calls to resolve the user query)\n",
    "- It is tested with `gemma-3-4b-it`, `Meta-Llama-Guard-2-8B` and `Mistral-7B-Instruct-v0.1`\n",
    "- The notebook will output a couple of `.parquet` files with the tasks instructions, the ground truth function calls and the LLM planned generated function calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before launching this notebook, you need load the desired model in the local environment, for example:\n",
    "\n",
    "1. Start Docker Desktop\n",
    "2. Write this `docker-composer.yaml` file\n",
    "```yaml\n",
    "services:\n",
    "    vllm-openai:\n",
    "        deploy:\n",
    "            resources:\n",
    "                reservations:\n",
    "                    devices:\n",
    "                        - driver: nvidia\n",
    "                          count: all\n",
    "                          capabilities:\n",
    "                              - gpu\n",
    "        volumes:\n",
    "            - ~/.cache/huggingface:/root/.cache/huggingface\n",
    "            - ./models:/models\n",
    "        environment:\n",
    "            - HUGGING_FACE_HUB_TOKEN=<YOUR_HF_TOKEN_HERE>\n",
    "        ports:\n",
    "            - 8000:8000\n",
    "        ipc: host\n",
    "        image: vllm/vllm-openai:latest\n",
    "        command: --model ${VLLM_MODEL}\n",
    "```\n",
    "3. Start the server, for example in Windows:\n",
    "```powershell\n",
    "@echo off\n",
    "\n",
    "set \"model1=google/gemma-3-4b-it\"\n",
    "set \"model2=mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "set \"model3=meta-llama/Meta-Llama-Guard-2-8B\"\n",
    "\n",
    "if \"%1\"==\"\" (\n",
    "    echo Usage: start-vllm.bat ^<model_name^>\n",
    "    echo Example: start-vllm.bat %model1%\n",
    "    echo Allowed models:\n",
    "    echo   - %model1%\n",
    "    echo   - %model2%\n",
    "    echo   - %model3%\n",
    "    goto :eof\n",
    ")\n",
    "\n",
    "set \"input_model=%1\"\n",
    "\n",
    "if /I \"%input_model%\"==\"%model1%\" goto :start_vllm\n",
    "if /I \"%input_model%\"==\"%model2%\" goto :start_vllm\n",
    "if /I \"%input_model%\"==\"%model3%\" goto :start_vllm\n",
    "\n",
    "echo Error: Invalid model specified: %input_model%\n",
    "echo Please choose one of the following models:\n",
    "echo   - %model1%\n",
    "echo   - %model2%\n",
    "echo   - %model3%\n",
    "goto :eof\n",
    "\n",
    ":start_vllm\n",
    "set VLLM_MODEL=%input_model%\n",
    "\n",
    "echo Starting vLLM service with model: %VLLM_MODEL%\n",
    "echo The OpenAI-compatible API will be available at: http://localhost:8000\n",
    "echo Press Ctrl+C to stop the service\n",
    "echo.\n",
    "docker-compose down\n",
    "docker-compose up\n",
    "\n",
    "echo vLLM service has been stopped \n",
    "```\n",
    "4. Then run the script, for example:\n",
    "```cmd\n",
    ".\\start-vllm.bat google/gemma-3-4b-it\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE : Prior downloading the model weights from HF, you need to accept the T&Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm>=1.0.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 1)) (1.65.4.post1)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 2)) (2.1.3)\n",
      "Requirement already satisfied: tqdm>=4.66.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: fastparquet>=2023.0.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 4)) (2024.11.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.0.0->-r requirements.txt (line 1)) (3.11.16)\n",
      "Requirement already satisfied: click in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.0.0->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: httpx>=0.23.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.0.0->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.0.0->-r requirements.txt (line 1)) (8.6.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.0.0->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.0.0->-r requirements.txt (line 1)) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.68.2 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.0.0->-r requirements.txt (line 1)) (1.70.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.0.0->-r requirements.txt (line 1)) (2.11.2)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.0.0->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.0.0->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.0.0->-r requirements.txt (line 1)) (0.21.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.66.0->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fastparquet>=2023.0.0->-r requirements.txt (line 4)) (2.9.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fastparquet>=2023.0.0->-r requirements.txt (line 4)) (2025.3.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fastparquet>=2023.0.0->-r requirements.txt (line 4)) (23.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.23.0->litellm>=1.0.0->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.23.0->litellm>=1.0.0->-r requirements.txt (line 1)) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.23.0->litellm>=1.0.0->-r requirements.txt (line 1)) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.23.0->litellm>=1.0.0->-r requirements.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.0.0->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from importlib-metadata>=6.8.0->litellm>=1.0.0->-r requirements.txt (line 1)) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.0.0->-r requirements.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.0.0->-r requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.0.0->-r requirements.txt (line 1)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.0.0->-r requirements.txt (line 1)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.0.0->-r requirements.txt (line 1)) (0.24.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai>=1.68.2->litellm>=1.0.0->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai>=1.68.2->litellm>=1.0.0->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai>=1.68.2->litellm>=1.0.0->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai>=1.68.2->litellm>=1.0.0->-r requirements.txt (line 1)) (4.13.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3.0.0,>=2.0.0->litellm>=1.0.0->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3.0.0,>=2.0.0->litellm>=1.0.0->-r requirements.txt (line 1)) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3.0.0,>=2.0.0->litellm>=1.0.0->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken>=0.7.0->litellm>=1.0.0->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken>=0.7.0->litellm>=1.0.0->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm>=1.0.0->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm>=1.0.0->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm>=1.0.0->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm>=1.0.0->-r requirements.txt (line 1)) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm>=1.0.0->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm>=1.0.0->-r requirements.txt (line 1)) (1.19.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tokenizers->litellm>=1.0.0->-r requirements.txt (line 1)) (0.30.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.0.0->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.0.0->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm>=1.0.0->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm>=1.0.0->-r requirements.txt (line 1)) (2.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\luisv\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/luisv/sandbox/agent-eval/src/notebooks/tau-bench\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: openai>=1.13.3 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tau_bench==0.1.0) (1.70.0)\n",
      "Requirement already satisfied: mistralai>=0.4.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tau_bench==0.1.0) (1.6.0)\n",
      "Requirement already satisfied: anthropic>=0.26.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tau_bench==0.1.0) (0.49.0)\n",
      "Requirement already satisfied: google-generativeai>=0.5.4 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tau_bench==0.1.0) (0.8.4)\n",
      "Requirement already satisfied: tenacity>=8.3.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tau_bench==0.1.0) (9.1.2)\n",
      "Requirement already satisfied: termcolor>=2.4.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tau_bench==0.1.0) (3.0.1)\n",
      "Requirement already satisfied: numpy>=1.26.4 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tau_bench==0.1.0) (1.26.4)\n",
      "Requirement already satisfied: litellm>=1.41.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tau_bench==0.1.0) (1.65.4.post1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anthropic>=0.26.1->tau_bench==0.1.0) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anthropic>=0.26.1->tau_bench==0.1.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anthropic>=0.26.1->tau_bench==0.1.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anthropic>=0.26.1->tau_bench==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anthropic>=0.26.1->tau_bench==0.1.0) (2.11.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anthropic>=0.26.1->tau_bench==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anthropic>=0.26.1->tau_bench==0.1.0) (4.13.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-generativeai>=0.5.4->tau_bench==0.1.0) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-generativeai>=0.5.4->tau_bench==0.1.0) (2.14.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-generativeai>=0.5.4->tau_bench==0.1.0) (2.166.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-generativeai>=0.5.4->tau_bench==0.1.0) (2.23.4)\n",
      "Requirement already satisfied: protobuf in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-generativeai>=0.5.4->tau_bench==0.1.0) (4.25.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-generativeai>=0.5.4->tau_bench==0.1.0) (4.67.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.4->tau_bench==0.1.0) (1.22.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.41.0->tau_bench==0.1.0) (3.11.16)\n",
      "Requirement already satisfied: click in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.41.0->tau_bench==0.1.0) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.41.0->tau_bench==0.1.0) (8.6.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.41.0->tau_bench==0.1.0) (3.1.2)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.41.0->tau_bench==0.1.0) (4.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.41.0->tau_bench==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.41.0->tau_bench==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from litellm>=1.41.0->tau_bench==0.1.0) (0.21.1)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mistralai>=0.4.0->tau_bench==0.1.0) (0.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mistralai>=0.4.0->tau_bench==0.1.0) (2.8.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mistralai>=0.4.0->tau_bench==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anyio<5,>=3.5.0->anthropic>=0.26.1->tau_bench==0.1.0) (3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.4->tau_bench==0.1.0) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.4->tau_bench==0.1.0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.4->tau_bench==0.1.0) (4.9)\n",
      "Requirement already satisfied: certifi in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->anthropic>=0.26.1->tau_bench==0.1.0) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->anthropic>=0.26.1->tau_bench==0.1.0) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic>=0.26.1->tau_bench==0.1.0) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from importlib-metadata>=6.8.0->litellm>=1.41.0->tau_bench==0.1.0) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.41.0->tau_bench==0.1.0) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.41.0->tau_bench==0.1.0) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.41.0->tau_bench==0.1.0) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.41.0->tau_bench==0.1.0) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.41.0->tau_bench==0.1.0) (0.24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->anthropic>=0.26.1->tau_bench==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->anthropic>=0.26.1->tau_bench==0.1.0) (2.33.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->mistralai>=0.4.0->tau_bench==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken>=0.7.0->litellm>=1.41.0->tau_bench==0.1.0) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken>=0.7.0->litellm>=1.41.0->tau_bench==0.1.0) (2.31.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->google-generativeai>=0.5.4->tau_bench==0.1.0) (0.4.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm>=1.41.0->tau_bench==0.1.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm>=1.41.0->tau_bench==0.1.0) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm>=1.41.0->tau_bench==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm>=1.41.0->tau_bench==0.1.0) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm>=1.41.0->tau_bench==0.1.0) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->litellm>=1.41.0->tau_bench==0.1.0) (1.19.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-core->google-generativeai>=0.5.4->tau_bench==0.1.0) (1.61.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-python-client->google-generativeai>=0.5.4->tau_bench==0.1.0) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-python-client->google-generativeai>=0.5.4->tau_bench==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-python-client->google-generativeai>=0.5.4->tau_bench==0.1.0) (4.1.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tokenizers->litellm>=1.41.0->tau_bench==0.1.0) (0.30.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-core->google-generativeai>=0.5.4->tau_bench==0.1.0) (1.59.3)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-api-core->google-generativeai>=0.5.4->tau_bench==0.1.0) (1.59.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai>=0.5.4->tau_bench==0.1.0) (3.2.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.41.0->tau_bench==0.1.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.41.0->tau_bench==0.1.0) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.41.0->tau_bench==0.1.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.41.0->tau_bench==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai>=0.5.4->tau_bench==0.1.0) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm>=1.41.0->tau_bench==0.1.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\luisv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm>=1.41.0->tau_bench==0.1.0) (2.1.0)\n",
      "Building wheels for collected packages: tau_bench\n",
      "  Building editable for tau_bench (pyproject.toml): started\n",
      "  Building editable for tau_bench (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for tau_bench: filename=tau_bench-0.1.0-0.editable-py3-none-any.whl size=6046 sha256=0e0ee3c47443f090829f9f7022f692ed1149400e3f9a31ce4e73a0190d98a16b\n",
      "  Stored in directory: C:\\Users\\luisv\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-hpmps1vw\\wheels\\d2\\25\\41\\ff0795e4d487d639de4ec96a9b2f438796cab4511a7f397768\n",
      "Successfully built tau_bench\n",
      "Installing collected packages: tau_bench\n",
      "  Attempting uninstall: tau_bench\n",
      "    Found existing installation: tau_bench 0.1.0\n",
      "    Uninstalling tau_bench-0.1.0:\n",
      "      Successfully uninstalled tau_bench-0.1.0\n",
      "Successfully installed tau_bench-0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'tau-bench'...\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\luisv\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/sierra-research/tau-bench && cd ./tau-bench && pip install -e .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Optional, Any, Tuple, Callable\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from tau_bench.envs.retail.tasks import tasks as retail_tasks\n",
    "from tau_bench.envs.airline.tasks import tasks as airline_tasks\n",
    "\n",
    "from tau_bench.envs.airline.tools import ALL_TOOLS as airline_tools\n",
    "from tau_bench.envs.retail.tools import ALL_TOOLS as retail_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RETAIL_DATA_PATH = \"retail_eval_results.parquet\"\n",
    "AIRLINE_DATA_PATH = \"airline_eval_results.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAILABLE_MODELS = {\n",
    "    \"gemma-3-4b\": \"openai/google/gemma-3-4b-it\",\n",
    "    \"llama-guard\": \"openai/meta-llama/Meta-Llama-Guard-2-8B\", \n",
    "    \"mistral-7b\": \"openai/mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "}\n",
    "\n",
    "# Select model by uncommenting one of these lines\n",
    "MODEL_NAME = AVAILABLE_MODELS[\"gemma-3-4b\"]\n",
    "# MODEL_NAME = AVAILABLE_MODELS[\"llama-guard\"]\n",
    "# MODEL_NAME = AVAILABLE_MODELS[\"mistral-7b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"openai/mistralai/Mistral-7B-Instruct-v0.1\": {\"model\": \"openai/mistralai/Mistral-7B-Instruct-v0.1\", \"use_system_prompt\": True, \"api_base\": \"http://localhost:8000/v1\"},\n",
    "    \"openai/google/gemma-3-4b-it\": {\"model\": \"openai/google/gemma-3-4b-it\", \"use_system_prompt\": True, \"api_base\": \"http://localhost:8000/v1\"},\n",
    "    \"openai/meta-llama/Meta-Llama-Guard-2-8B\": {\"model\": \"openai/meta-llama/Meta-Llama-Guard-2-8B\", \"use_system_prompt\": False, \"api_base\": \"http://localhost:8000/v1\"} \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = model_configs[MODEL_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tool_dict(tool_class):\n",
    "    tool_info = tool_class.get_info()\n",
    "    function_info = tool_info[\"function\"]\n",
    "    return {\n",
    "        \"name\": function_info[\"name\"],\n",
    "        \"description\": function_info[\"description\"],\n",
    "        \"parameters\": function_info[\"parameters\"]\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_json_plan(response_text: str) -> List[Dict[str, Any]]:\n",
    "    try:\n",
    "        json_match = re.search(r'(\\[.*\\])', response_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_str = json_match.group(1)\n",
    "            json_str = json_str.replace('\\\\\"', '\"')\n",
    "            plan = json.loads(json_str)\n",
    "            if isinstance(plan, list):\n",
    "                validated_plan = []\n",
    "                for item in plan:\n",
    "                    if isinstance(item, dict) and \"name\" in item and \"arguments\" in item:\n",
    "                        validated_plan.append(item)\n",
    "                    else:\n",
    "                        logging.warning(f\"Skipping invalid item in plan: {item}\")\n",
    "                return validated_plan\n",
    "            else:\n",
    "                logging.warning(f\"Parsed JSON is not a list: {plan}\")\n",
    "                return []\n",
    "        else:\n",
    "            logging.warning(\"No JSON array found in the response.\")\n",
    "            return []\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"Error parsing JSON plan: {e}\")\n",
    "        logging.error(f\"Raw response: {response_text}\")\n",
    "        return [{\"error\": f\"JSONDecodeError: {e}\", \"raw_response\": response_text}]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error parsing plan: {e}\")\n",
    "        return [{\"error\": f\"Unexpected error: {e}\", \"raw_response\": response_text}]\n",
    "\n",
    "\n",
    "def generate_single_shot_plan(\n",
    "    user_query: str,\n",
    "    tools: List[Dict[str, Any]],\n",
    "    model: str,\n",
    "    api_base: str,\n",
    "    use_system_prompt: bool \n",
    ") -> List[Dict[str, Any]]:\n",
    "    \n",
    "\n",
    "    if use_system_prompt:\n",
    "        system_prompt = f\"\"\"You are a planning agent. Your goal is to create a plan to fulfill the user's request using the available functions.\n",
    "Available functions: {json.dumps(tools, indent=2)}\n",
    "\n",
    "Respond ONLY with a JSON array outlining the sequence of function calls needed. Each object in the array should have 'function_name' and 'parameters' keys.\n",
    "\n",
    "Example format:\n",
    "[\n",
    "    {{\"name\": \"search_flights\", \"arguments\": {{\"origin\": \"JFK\", \"destination\": \"SFO\"}}}},\n",
    "    {{\"name\": \"book_reservation\", \"arguments\": {{\"flight_id\": \"UA123\", \"user_id\": \"user123\"}}}}\n",
    "]\n",
    "\n",
    "If no function calls are needed, return an empty JSON array: [].\n",
    "Do not include any other text, explanation, or markdown formatting.\"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "        ]\n",
    "        prompt_type_log = \"separate system/user prompts\"\n",
    "    else:\n",
    "        combined_prompt = f\"\"\"Instructions: You are a planning agent. Create a plan to fulfill the user's request using the available functions. Respond ONLY with a JSON array outlining the sequence of function calls needed. Each object in the array should have 'function_name' and 'parameters' keys. If no calls are needed, return an empty JSON array: []. Do not include any other text, explanation, or markdown formatting.\n",
    "\n",
    "Available functions:\n",
    "{json.dumps(tools, indent=2)}\n",
    "\n",
    "Example format:\n",
    "[\n",
    "    {{\"name\": \"search_flights\", \"arguments\": {{\"origin\": \"JFK\", \"destination\": \"SFO\"}}}},\n",
    "    {{\"name\": \"book_reservation\", \"arguments\": {{\"flight_id\": \"UA123\", \"user_id\": \"user123\"}}}}\n",
    "]\n",
    "\n",
    "---\n",
    "User request: {user_query}\n",
    "---\n",
    "\n",
    "Generate the plan:\"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": combined_prompt}\n",
    "        ]\n",
    "        prompt_type_log = \"combined user prompt\"\n",
    "\n",
    "    try:\n",
    "        print(f\"Generating full plan (Model: {model}, Prompt Format: {prompt_type_log})...\")\n",
    "        response = litellm.completion(\n",
    "            model=model,\n",
    "            api_base=api_base,\n",
    "            messages=messages,\n",
    "            temperature=0.0,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "\n",
    "        if not response or not hasattr(response, 'choices') or not response.choices or response.choices[0].message.content is None:\n",
    "            print(\"Warning: Empty response or None content from model.\")\n",
    "            return [{\"error\": \"Empty response from model\"}]\n",
    "\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        print(f\"Model raw response:\\n{result}\")\n",
    "\n",
    "        plan = parse_json_plan(result)\n",
    "        print(f\"\\nParsed Plan: {plan}\")\n",
    "        return plan\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        tb_str = traceback.format_exc()\n",
    "        print(f\"Error during plan generation: {str(e)}\\n{tb_str}\")\n",
    "        raw_resp_text = result if 'result' in locals() else \"Response not captured\"\n",
    "        return [{\"error\": str(e), \"raw_response\": raw_resp_text}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_instructions = [task[\"instruction\"] for task in retail_tasks]\n",
    "airline_instructions = [task[\"instruction\"] for task in airline_tasks]\n",
    "\n",
    "retail_gt_calls = [task[\"actions\"] for task in retail_tasks]\n",
    "airline_gt_calls = [task[\"actions\"] for task in airline_tasks]\n",
    "\n",
    "\n",
    "airline_tool_dicts = [get_tool_dict(tool_class) for tool_class in airline_tools]\n",
    "retail_tool_dicts = [get_tool_dict(tool_class) for tool_class in retail_tools]\n",
    "\n",
    "retail_df = pd.DataFrame({\n",
    "    'instruction': retail_instructions,\n",
    "    'ground_truth_calls': retail_gt_calls,\n",
    "})\n",
    "\n",
    "\n",
    "retail_df['tools'] = [retail_tool_dicts] * len(retail_df)\n",
    "\n",
    "\n",
    "airline_df = pd.DataFrame({\n",
    "    'instruction': airline_instructions,\n",
    "    'ground_truth_calls': airline_gt_calls,\n",
    "})\n",
    "\n",
    "airline_df['tools'] = [airline_tool_dicts] * len(airline_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,436 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,436 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,437 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,438 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,440 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,442 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,443 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,444 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,445 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,446 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,448 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,449 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:25 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,451 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,452 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,454 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,456 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,456 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,458 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,460 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:25,461 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing airline instructions:   0%|          | 0/50 [00:00<?, ?it/s]2025-04-11 13:11:27,794 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:27 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:27,799 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:27,800 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:27,802 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:27,802 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:27,803 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:27,810 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:27 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:27,810 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:27,811 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:27,896 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:27 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:27,900 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:27,901 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:27,901 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:27 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:27,903 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:27,909 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:27 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:27,909 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"amelia_sanchez_4739_MCO_CLT\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"amelia_sanchez_4739_MCO_CLT\"}}\n",
      "]\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'amelia_sanchez_4739_MCO_CLT'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'amelia_sanchez_4739_MCO_CLT'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"ATL\", \"destination\": \"PHL\", \"date\": \"2024-05-02\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"economy\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'search_direct_flight', 'arguments': {'origin': 'ATL', 'destination': 'PHL', 'date': '2024-05-02'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'ZFA04Y', 'cabin': 'economy'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:29,184 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:29,185 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,187 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,187 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,188 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,188 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:29,190 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,190 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,194 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"omar_davis_3817\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to find all my reservations and downgrade the cabin class to economy. Then, I need to calculate the difference in price.\"}},\n",
      "  {\"name\": \"list_all_reservations\", \"arguments\": {}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"Total Savings from downgrading business to economy flights\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"User wants to downgrade business flights to economy and calculate total savings.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_user_details', 'arguments': {'user_id': 'omar_davis_3817'}}, {'name': 'think', 'arguments': {'thought': 'I need to find all my reservations and downgrade the cabin class to economy. Then, I need to calculate the difference in price.'}}, {'name': 'list_all_reservations', 'arguments': {}}, {'name': 'calculate', 'arguments': {'expression': 'Total Savings from downgrading business to economy flights'}}, {'name': 'transfer_to_human_agents', 'arguments': {'summary': 'User wants to downgrade business flights to economy and calculate total savings.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:29,499 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:29,501 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,502 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,502 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,502 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:29,503 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,505 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,506 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,509 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"ethan_martin_2396\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The user is experiencing a flight delay and wants compensation. I need to find the details of the flight and the reason for the delay.\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"HAT039\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Now that I have the reservation details, I need to find the reason for the delay.\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"ethan_martin_2396\", \"amount\": 100}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_user_details', 'arguments': {'user_id': 'ethan_martin_2396'}}, {'name': 'think', 'arguments': {'thought': 'The user is experiencing a flight delay and wants compensation. I need to find the details of the flight and the reason for the delay.'}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': 'HAT039'}}, {'name': 'think', 'arguments': {'thought': 'Now that I have the reservation details, I need to find the reason for the delay.'}}, {'name': 'send_certificate', 'arguments': {'user_id': 'ethan_martin_2396', 'amount': 100}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:29,717 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:29,719 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,720 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,720 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,721 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,721 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:29,723 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,724 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,728 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"ivan_muller_7015\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"ivan_muller_7015\", \"amount\": 100}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"100 - certificate_balance\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"passengers\": [{\"first_name\": \"Ivan\", \"last_name\": \"Smith\", \"dob\": \"1990-01-01\"}]}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'ZFA04Y'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'ivan_muller_7015'}}, {'name': 'send_certificate', 'arguments': {'user_id': 'ivan_muller_7015', 'amount': 100}}, {'name': 'calculate', 'arguments': {'expression': '100 - certificate_balance'}}, {'name': 'update_reservation_passengers', 'arguments': {'reservation_id': 'ZFA04Y', 'passengers': [{'first_name': 'Ivan', 'last_name': 'Smith', 'dob': '1990-01-01'}]}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:29,981 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:29,983 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,984 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,984 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,985 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,986 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,987 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:29,988 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:29 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:29,991 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"JFK\", \"destination\": \"ORD\", \"date\": \"2024-05-05\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"placeholder\", \"total_baggages\": 3, \"nonfree_baggages\": 0, \"payment_id\": \"gift_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"placeholder\", \"passengers\": [{\"first_name\": \"Omar\", \"last_name\": \"Rossi\", \"dob\": \"1990-01-01\"}]}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"placeholder\", \"cabin\": \"economy\", \"flights\": []}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'search_direct_flight', 'arguments': {'origin': 'JFK', 'destination': 'ORD', 'date': '2024-05-05'}}, {'name': 'update_reservation_baggages', 'arguments': {'reservation_id': 'placeholder', 'total_baggages': 3, 'nonfree_baggages': 0, 'payment_id': 'gift_card_7815826'}}, {'name': 'update_reservation_passengers', 'arguments': {'reservation_id': 'placeholder', 'passengers': [{'first_name': 'Omar', 'last_name': 'Rossi', 'dob': '1990-01-01'}]}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'placeholder', 'cabin': 'economy', 'flights': []}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:30,377 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:30,380 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,381 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,381 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,382 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,382 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,383 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:30,384 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,387 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,530 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:30,531 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,532 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,532 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,533 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,534 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,535 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:30,535 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,541 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "[\n",
      "    {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"1N99U6\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"WN123\", \"date\": \"2024-05-01\"}]}},\n",
      "    {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"1N99U6\", \"total_baggages\": 0, \"nonfree_baggages\": 0}},\n",
      "    {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"james_taylor_7043\", \"amount\": 25}}\n",
      "]\n",
      "\n",
      "Parsed Plan: [{'name': 'update_reservation_flights', 'arguments': {'reservation_id': '1N99U6', 'cabin': 'economy', 'flights': [{'flight_number': 'WN123', 'date': '2024-05-01'}]}}, {'name': 'update_reservation_baggages', 'arguments': {'reservation_id': '1N99U6', 'total_baggages': 0, 'nonfree_baggages': 0}}, {'name': 'send_certificate', 'arguments': {'user_id': 'james_taylor_7043', 'amount': 25}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"JFK\", \"destination\": \"ORD\", \"date\": \"2024-05-05\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"placeholder\", \"passengers\": [{\"first_name\": \"Omar\", \"last_name\": \"Rossi\", \"dob\": \"1990-01-01\"}]}},\n",
      "  {\"name\": \"update_reservation_cabin\", \"arguments\": {\"reservation_id\": \"placeholder\", \"cabin\": \"economy\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"placeholder\", \"total_baggages\": 3, \"nonfree_baggages\": 0, \"payment_id\": \"gift_card_7815826\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"omar_rossi_1241\", \"amount\": 100}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'search_direct_flight', 'arguments': {'origin': 'JFK', 'destination': 'ORD', 'date': '2024-05-05'}}, {'name': 'update_reservation_passengers', 'arguments': {'reservation_id': 'placeholder', 'passengers': [{'first_name': 'Omar', 'last_name': 'Rossi', 'dob': '1990-01-01'}]}}, {'name': 'update_reservation_cabin', 'arguments': {'reservation_id': 'placeholder', 'cabin': 'economy'}}, {'name': 'update_reservation_baggages', 'arguments': {'reservation_id': 'placeholder', 'total_baggages': 3, 'nonfree_baggages': 0, 'payment_id': 'gift_card_7815826'}}, {'name': 'send_certificate', 'arguments': {'user_id': 'omar_rossi_1241', 'amount': 100}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:30,811 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:30,813 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,814 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,814 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,815 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,815 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,817 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:30,817 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:30 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,821 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:30,999 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"list_all_airports\", \"arguments\": {}},\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"HOU\", \"destination\": \"DEN\", \"date\": \"2024-05-27\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"find the fastest return trip\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": null, \"total_baggages\": 1, \"nonfree_baggages\": 0, \"payment_id\": \"gift_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_cabin\", \"arguments\": {\"reservation_id\": null, \"cabin\": \"economy\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": null, \"flights\": []}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": null, \"passengers\": []}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": null}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'list_all_airports', 'arguments': {}}, {'name': 'search_direct_flight', 'arguments': {'origin': 'HOU', 'destination': 'DEN', 'date': '2024-05-27'}}, {'name': 'calculate', 'arguments': {'expression': 'find the fastest return trip'}}, {'name': 'update_reservation_baggages', 'arguments': {'reservation_id': None, 'total_baggages': 1, 'nonfree_baggages': 0, 'payment_id': 'gift_card_7815826'}}, {'name': 'update_reservation_cabin', 'arguments': {'reservation_id': None, 'cabin': 'economy'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': None, 'flights': []}}, {'name': 'update_reservation_passengers', 'arguments': {'reservation_id': None, 'passengers': []}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': None}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:31,000 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,001 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,001 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,002 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,002 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:31,004 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,004 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,008 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"XEWRD9\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to find a nonstop flight from ATL to LAS and update the reservation. I should also check if an upgrade to economy is possible.\"}},\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"ATL\", \"destination\": \"LAS\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"XEWRD9\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"WN123\", \"date\": \"2024-05-03\"}]}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"XEWRD9\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"james_lee_6136\", \"amount\": 100}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'XEWRD9'}}, {'name': 'think', 'arguments': {'thought': 'I need to find a nonstop flight from ATL to LAS and update the reservation. I should also check if an upgrade to economy is possible.'}}, {'name': 'search_direct_flight', 'arguments': {'origin': 'ATL', 'destination': 'LAS'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'XEWRD9', 'cabin': 'economy', 'flights': [{'flight_number': 'WN123', 'date': '2024-05-03'}]}}, {'name': 'update_reservation_baggages', 'arguments': {'reservation_id': 'XEWRD9', 'total_baggages': 0, 'nonfree_baggages': 0, 'payment_id': 'credit_card_7815826'}}, {'name': 'send_certificate', 'arguments': {'user_id': 'james_lee_6136', 'amount': 100}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:31,346 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:31,348 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,349 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,349 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,350 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,351 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "Processing airline instructions:   2%|▏         | 1/50 [00:05<04:46,  5.84s/it]\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:31,352 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,353 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,356 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,415 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:31,417 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,418 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,418 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,419 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,420 - ERROR - Error parsing JSON plan: Expecting ',' delimiter: line 4 column 254 (char 572)\n",
      "2025-04-11 13:11:31,420 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,421 - ERROR - Raw response: ```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"VA5SGQ\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to update the flights, cabin, and baggage information for the reservation. I also need to waive fees due to insurance and add a checked bag. I should prioritize morning flights.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"VA5SGQ\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"DL123\", \"date\": \"2024-05-03\"}, {\"flight_number\": \"DL456\", \"date\": \"2024-05-06\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"VA5SGQ\", \"total_baggages\": 1, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"raj_brown_5782\", \"amount\": 10}}\n",
      "]\n",
      "```\n",
      "2025-04-11 13:11:31,421 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,423 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:31,423 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"JFK\", \"destination\": \"SEA\", \"date\": \"2024-05-20\"}},\n",
      "  {\"name\": \"search_onestop_flight\", \"arguments\": {\"origin\": \"JFK\", \"destination\": \"SEA\", \"date\": \"2024-05-20\"}},\n",
      "  {\"name\": \"list_all_airports\", \"arguments\": {}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"flight_price_direct - flight_price_onestop\"}},\n",
      "  {\"name\": \"book_reservation\", \"arguments\": {\"user_id\": \"mia_li_3668\", \"origin\": \"JFK\", \"destination\": \"SEA\", \"flight_type\": \"one_way\", \"cabin\": \"economy\", \"flights\": [], \"passengers\": [], \"payment_methods\": [{\"payment_id\": \"certificate_7815826\", \"amount\": 300}, {\"payment_id\": \"credit_card_7815826\", \"amount\": 100}], \"total_baggages\": 3, \"nonfree_baggages\": 0, \"insurance\": \"no\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'search_direct_flight', 'arguments': {'origin': 'JFK', 'destination': 'SEA', 'date': '2024-05-20'}}, {'name': 'search_onestop_flight', 'arguments': {'origin': 'JFK', 'destination': 'SEA', 'date': '2024-05-20'}}, {'name': 'list_all_airports', 'arguments': {}}, {'name': 'calculate', 'arguments': {'expression': 'flight_price_direct - flight_price_onestop'}}, {'name': 'book_reservation', 'arguments': {'user_id': 'mia_li_3668', 'origin': 'JFK', 'destination': 'SEA', 'flight_type': 'one_way', 'cabin': 'economy', 'flights': [], 'passengers': [], 'payment_methods': [{'payment_id': 'certificate_7815826', 'amount': 300}, {'payment_id': 'credit_card_7815826', 'amount': 100}], 'total_baggages': 3, 'nonfree_baggages': 0, 'insurance': 'no'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"VA5SGQ\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to update the flights, cabin, and baggage information for the reservation. I also need to waive fees due to insurance and add a checked bag. I should prioritize morning flights.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"VA5SGQ\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"DL123\", \"date\": \"2024-05-03\"}, {\"flight_number\": \"DL456\", \"date\": \"2024-05-06\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"VA5SGQ\", \"total_baggages\": 1, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"raj_brown_5782\", \"amount\": 10}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'error': \"JSONDecodeError: Expecting ',' delimiter: line 4 column 254 (char 572)\", 'raw_response': '```json\\n[\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"VA5SGQ\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to update the flights, cabin, and baggage information for the reservation. I also need to waive fees due to insurance and add a checked bag. I should prioritize morning flights.\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"VA5SGQ\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"DL123\", \"date\": \"2024-05-03\"}, {\"flight_number\": \"DL456\", \"date\": \"2024-05-06\"}]}, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"VA5SGQ\", \"total_baggages\": 1, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"raj_brown_5782\", \"amount\": 10}}\\n]\\n```'}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:31,615 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:31,616 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,617 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,617 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,618 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:31,619 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,620 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,621 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,624 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,631 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:31,632 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,633 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,633 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,634 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,635 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,635 - ERROR - Error parsing JSON plan: Expecting ',' delimiter: line 4 column 281 (char 564)\n",
      "2025-04-11 13:11:31,637 - ERROR - Raw response: ```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"lciam_khan_2521_reservation_1234\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to update the flight dates and cabin class for my reservation. I also need to confirm the total cost of the changes.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"lciam_khan_2521_reservation_1234\", \"cabin\": \"business\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-24\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-24\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"lciam_khan_2521_reservation_1234\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"original_price - new_price\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"User wants to change flight dates and cabin class. Please confirm the total cost.\"}}\n",
      "]\n",
      "```\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:31,636 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:31 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:31,638 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:31,639 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"JFK\", \"destination\": \"SFO\", \"date\": \"2024-05-17\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"economy\", \"flights\": [ {\"flight_number\": \"UA123\", \"date\": \"2024-05-17\"} ]}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"daiki_lee_6144\", \"amount\": 100}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'search_direct_flight', 'arguments': {'origin': 'JFK', 'destination': 'SFO', 'date': '2024-05-17'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'ZFA04Y', 'cabin': 'economy', 'flights': [{'flight_number': 'UA123', 'date': '2024-05-17'}]}}, {'name': 'update_reservation_baggages', 'arguments': {'reservation_id': 'ZFA04Y', 'total_baggages': 0, 'nonfree_baggages': 0, 'payment_id': 'credit_card_7815826'}}, {'name': 'send_certificate', 'arguments': {'user_id': 'daiki_lee_6144', 'amount': 100}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"lciam_khan_2521_reservation_1234\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to update the flight dates and cabin class for my reservation. I also need to confirm the total cost of the changes.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"lciam_khan_2521_reservation_1234\", \"cabin\": \"business\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-24\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-24\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"lciam_khan_2521_reservation_1234\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"original_price - new_price\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"User wants to change flight dates and cabin class. Please confirm the total cost.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'error': \"JSONDecodeError: Expecting ',' delimiter: line 4 column 281 (char 564)\", 'raw_response': '```json\\n[\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"lciam_khan_2521_reservation_1234\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to update the flight dates and cabin class for my reservation. I also need to confirm the total cost of the changes.\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"lciam_khan_2521_reservation_1234\", \"cabin\": \"business\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-24\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-24\"}]}, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"lciam_khan_2521_reservation_1234\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"original_price - new_price\"}},\\n  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"User wants to change flight dates and cabin class. Please confirm the total cost.\"}}\\n]\\n```'}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:32,163 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:32,165 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,165 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,166 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,167 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:32,167 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,168 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:32,169 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,173 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,179 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:32,180 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,181 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,182 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,182 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:32,183 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,184 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,186 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,190 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,285 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:32,286 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,287 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,287 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,288 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:32,288 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,290 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,290 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,294 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,337 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:32,338 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,339 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,339 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,340 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,341 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,342 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:32,343 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,346 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ivan_rossi_8555_flight_123\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to change my flight from EWR to nonstop on May 21st due to my mother's illness. I'm willing to pay a fee and upgrade to economy if necessary.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ivan_rossi_8555_flight_123\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-21\"}]}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'ivan_rossi_8555_flight_123'}}, {'name': 'think', 'arguments': {'thought': \"I need to change my flight from EWR to nonstop on May 21st due to my mother's illness. I'm willing to pay a fee and upgrade to economy if necessary.\"}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'ivan_rossi_8555_flight_123', 'cabin': 'economy', 'flights': [{'flight_number': 'UA123', 'date': '2024-05-21'}]}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"amelia_davis_8890_upcoming_flights\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"amelia_davis_8890_upcoming_flights\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'amelia_davis_8890_upcoming_flights'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'amelia_davis_8890_upcoming_flights'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"GV1N64\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to confirm the passenger details before canceling the reservation. I also need to ensure the full refund is processed to the original payment method.\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"james_patel_9828\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"GV1N64\", \"passengers\": []}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"GV1N64\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"james_patel_9828\", \"amount\": 100}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"GV1N64\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Now I need to confirm the refund to the original payment method.\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"Please process a full refund to the original payment method for reservation GV1N64 after removing all passengers.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'GV1N64'}}, {'name': 'think', 'arguments': {'thought': 'I need to confirm the passenger details before canceling the reservation. I also need to ensure the full refund is processed to the original payment method.'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'james_patel_9828'}}, {'name': 'update_reservation_passengers', 'arguments': {'reservation_id': 'GV1N64', 'passengers': []}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'GV1N64'}}, {'name': 'send_certificate', 'arguments': {'user_id': 'james_patel_9828', 'amount': 100}}, {'name': 'update_reservation_baggages', 'arguments': {'reservation_id': 'GV1N64', 'total_baggages': 0, 'nonfree_baggages': 0, 'payment_id': 'credit_card_7815826'}}, {'name': 'think', 'arguments': {'thought': 'Now I need to confirm the refund to the original payment method.'}}, {'name': 'transfer_to_human_agents', 'arguments': {'summary': 'Please process a full refund to the original payment method for reservation GV1N64 after removing all passengers.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"SI5UKW\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, let's cancel this reservation. I need to be persistent and explore all options, even if it's a basic economy ticket.\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"SI5UKW\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The agent said it's not possible to cancel. Let's ask for a gift card or travel voucher as compensation.\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"I need to cancel my reservation SI5UKW and would like a gift card or travel voucher as compensation due to the inability to cancel a basic economy ticket.\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"SI5UKW\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The agent is still saying no. Let's try to negotiate a refund. I'll ask for at least 10%.\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"SI5UKW\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Still no luck. Let's push for a minimum of 50% refund.\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"SI5UKW\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'cancel_reservation', 'arguments': {'reservation_id': 'SI5UKW'}}, {'name': 'think', 'arguments': {'thought': \"Okay, let's cancel this reservation. I need to be persistent and explore all options, even if it's a basic economy ticket.\"}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'SI5UKW'}}, {'name': 'think', 'arguments': {'thought': \"The agent said it's not possible to cancel. Let's ask for a gift card or travel voucher as compensation.\"}}, {'name': 'transfer_to_human_agents', 'arguments': {'summary': 'I need to cancel my reservation SI5UKW and would like a gift card or travel voucher as compensation due to the inability to cancel a basic economy ticket.'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'SI5UKW'}}, {'name': 'think', 'arguments': {'thought': \"The agent is still saying no. Let's try to negotiate a refund. I'll ask for at least 10%.\"}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'SI5UKW'}}, {'name': 'think', 'arguments': {'thought': \"Still no luck. Let's push for a minimum of 50% refund.\"}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'SI5UKW'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:32,535 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:32,536 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,537 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,537 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,538 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,539 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,540 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:32,541 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,545 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"list_all_airports\", \"arguments\": {}},\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"ATL\", \"destination\": \"PHL\", \"date\": \"2024-05-02\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"economy\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"economy\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'list_all_airports', 'arguments': {}}, {'name': 'search_direct_flight', 'arguments': {'origin': 'ATL', 'destination': 'PHL', 'date': '2024-05-02'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'ZFA04Y', 'cabin': 'economy'}}, {'name': 'update_reservation_passengers', 'arguments': {'reservation_id': 'ZFA04Y', 'passengers': []}}, {'name': 'update_reservation_baggages', 'arguments': {'reservation_id': 'ZFA04Y', 'total_baggages': 0, 'nonfree_baggages': 0, 'payment_id': 'credit_card_7815826'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'ZFA04Y', 'cabin': 'economy'}}, {'name': 'update_reservation_passengers', 'arguments': {'reservation_id': 'ZFA04Y', 'passengers': []}}, {'name': 'update_reservation_baggages', 'arguments': {'reservation_id': 'ZFA04Y', 'total_baggages': 0, 'nonfree_baggages': 0, 'payment_id': 'credit_card_7815826'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'ZFA04Y'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:32,750 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:32,751 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,752 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,752 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,753 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "Processing airline instructions:   4%|▍         | 2/50 [00:07<02:34,  3.23s/it]2025-04-11 13:11:32,754 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:32,755 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,756 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:32 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:32,760 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"list_all_airports\", \"arguments\": {}},\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"EWR\", \"destination\": \"AUS\", \"date\": \"2024-05-01\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-01\"}]}, \"payment_id\": \"credit_card_7815826\" },\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check if there are later flights on the same day.\"}},\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"EWR\", \"destination\": \"AUS\", \"date\": \"2024-05-02\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"If no later flights are available, cancel the reservation and book a new one.\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"olivia_gonzalez_2305\", \"amount\": 100}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'list_all_airports', 'arguments': {}}, {'name': 'search_direct_flight', 'arguments': {'origin': 'EWR', 'destination': 'AUS', 'date': '2024-05-01'}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': 'ZFA04Y'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'ZFA04Y', 'cabin': 'economy', 'flights': [{'flight_number': 'UA123', 'date': '2024-05-01'}]}, 'payment_id': 'credit_card_7815826'}, {'name': 'think', 'arguments': {'thought': 'Check if there are later flights on the same day.'}}, {'name': 'search_direct_flight', 'arguments': {'origin': 'EWR', 'destination': 'AUS', 'date': '2024-05-02'}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': 'ZFA04Y'}}, {'name': 'think', 'arguments': {'thought': 'If no later flights are available, cancel the reservation and book a new one.'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'ZFA04Y'}}, {'name': 'send_certificate', 'arguments': {'user_id': 'olivia_gonzalez_2305', 'amount': 100}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:33,001 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:33,002 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,003 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,003 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,004 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,005 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:33,007 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,008 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,011 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,017 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:33,018 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,018 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,018 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,019 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:33,020 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,022 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,023 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,026 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,169 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:33,171 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,171 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,171 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,173 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,174 - ERROR - Error parsing JSON plan: Expecting ',' delimiter: line 9 column 191 (char 1110)\n",
      "2025-04-11 13:11:33,173 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,174 - ERROR - Raw response: ```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"YAX4DR\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to update the reservation with the new cabin class and baggage information. I also need to check if upgrading Noah to business is possible and cost-effective.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"YAX4DR\", \"cabin\": \"business\", \"flights\": [], \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"YAX4DR\", \"total_baggages\": 2, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Now I need to check if upgrading Noah to business is possible and cost-effective.\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"chen_lee_6825\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"600 - upgrade_cost_to_business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"YAX4DR\", \"passengers\": [{\"first_name\": \"Noah\", \"last_name\": \"Brown\", \"dob\": \"1995-05-10\"}]}, \"cabin\": \"business\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"chen_lee_6825\", \"amount\": 600}}\n",
      "]\n",
      "```\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:33,175 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,176 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:33,177 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"amelia_davis_8890_1234\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to cancel all my one-way flights. I don't care about refunds.\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"amelia_davis_8890_1234\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'amelia_davis_8890_1234'}}, {'name': 'think', 'arguments': {'thought': \"I need to cancel all my one-way flights. I don't care about refunds.\"}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'amelia_davis_8890_1234'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to cancel the ATL to JFK flight from May 17th.\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'ZFA04Y'}}, {'name': 'think', 'arguments': {'thought': 'I need to cancel the ATL to JFK flight from May 17th.'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'ZFA04Y'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"YAX4DR\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to update the reservation with the new cabin class and baggage information. I also need to check if upgrading Noah to business is possible and cost-effective.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"YAX4DR\", \"cabin\": \"business\", \"flights\": [], \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"YAX4DR\", \"total_baggages\": 2, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Now I need to check if upgrading Noah to business is possible and cost-effective.\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"chen_lee_6825\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"600 - upgrade_cost_to_business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"YAX4DR\", \"passengers\": [{\"first_name\": \"Noah\", \"last_name\": \"Brown\", \"dob\": \"1995-05-10\"}]}, \"cabin\": \"business\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"chen_lee_6825\", \"amount\": 600}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'error': \"JSONDecodeError: Expecting ',' delimiter: line 9 column 191 (char 1110)\", 'raw_response': '```json\\n[\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"YAX4DR\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to update the reservation with the new cabin class and baggage information. I also need to check if upgrading Noah to business is possible and cost-effective.\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"YAX4DR\", \"cabin\": \"business\", \"flights\": [], \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"YAX4DR\", \"total_baggages\": 2, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"Now I need to check if upgrading Noah to business is possible and cost-effective.\"}},\\n  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"chen_lee_6825\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"600 - upgrade_cost_to_business\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"YAX4DR\", \"passengers\": [{\"first_name\": \"Noah\", \"last_name\": \"Brown\", \"dob\": \"1995-05-10\"}]}, \"cabin\": \"business\"}},\\n  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"chen_lee_6825\", \"amount\": 600}}\\n]\\n```'}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:33,367 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:33,368 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,369 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,369 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,370 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,371 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:33,372 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,373 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,376 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"H8Q05L\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'cancel_reservation', 'arguments': {'reservation_id': 'H8Q05L'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:33,598 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:33,599 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,600 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,600 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,601 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,602 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "Processing airline instructions:  18%|█▊        | 9/50 [00:08<00:23,  1.75it/s]2025-04-11 13:11:33,604 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,604 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:33 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:33,609 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"mohamed_silva_9265\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to find the gift card and certificate balances and then book a new reservation with the cheapest business class option, minimizing the master card payment.\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"gift_card_balances + certificate_balances\"}},\n",
      "  {\"name\": \"list_all_airports\", \"arguments\": {}},\n",
      "  {\"name\": \"search_onestop_flight\", \"arguments\": {\"origin\": \"SFO\", \"destination\": \"JFK\", \"date\": \"2024-12-24\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"total_baggages\": 0, \"nonfree_baggages\": 0}},\n",
      "  {\"name\": \"update_reservation_payment_methods\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"payment_id\": \"certificate_7815826\", \"payment_id\": \"gift_card_7815826\", \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master_card_charge\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to confirm the master card charge and ensure the reservation is booked.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_user_details', 'arguments': {'user_id': 'mohamed_silva_9265'}}, {'name': 'think', 'arguments': {'thought': 'I need to find the gift card and certificate balances and then book a new reservation with the cheapest business class option, minimizing the master card payment.'}}, {'name': 'calculate', 'arguments': {'expression': 'gift_card_balances + certificate_balances'}}, {'name': 'list_all_airports', 'arguments': {}}, {'name': 'search_onestop_flight', 'arguments': {'origin': 'SFO', 'destination': 'JFK', 'date': '2024-12-24'}}, {'name': 'update_reservation_passengers', 'arguments': {'reservation_id': 'ZFA04Y', 'passengers': []}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'ZFA04Y', 'cabin': 'business'}}, {'name': 'update_reservation_baggages', 'arguments': {'reservation_id': 'ZFA04Y', 'total_baggages': 0, 'nonfree_baggages': 0}}, {'name': 'update_reservation_payment_methods', 'arguments': {'reservation_id': 'ZFA04Y', 'payment_id': 'credit_card_7815826'}}, {'name': 'calculate', 'arguments': {'expression': 'master_card_charge'}}, {'name': 'think', 'arguments': {'thought': 'I need to confirm the master card charge and ensure the reservation is booked.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:34,435 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:34,436 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,437 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,437 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,438 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,438 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:34,440 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,441 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,445 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,468 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:34,470 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,471 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,471 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,472 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:34,472 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,474 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,474 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,477 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,556 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:34,557 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,559 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,559 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,560 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,560 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,561 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:34,562 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,565 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,642 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"3RK2T9\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to emphasize that I booked this flight 10 hours ago and I absolutely require a full refund. I made a mistake and I want to cancel immediately.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'cancel_reservation', 'arguments': {'reservation_id': '3RK2T9'}}, {'name': 'think', 'arguments': {'thought': 'I need to emphasize that I booked this flight 10 hours ago and I absolutely require a full refund. I made a mistake and I want to cancel immediately.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"H9ZU1C\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Ethan is a passenger in reservation H9ZU1C. I need to remove him. Also, I want to find the cheapest direct round trip flight from New York to the West Coast for May 20th to May 25th.\"}},\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"EWR\", \"destination\": \"LAX\", \"date\": \"2024-05-20\"}},\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"EWR\", \"destination\": \"LAX\", \"date\": \"2024-05-25\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"cheapest_flight_price\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"H9ZU1C\", \"passengers\": []}},\n",
      "  {\"name\": \"book_reservation\", \"arguments\": {\"user_id\": \"mia_kim_4397\", \"origin\": \"EWR\", \"destination\": \"LAX\", \"flight_type\": \"round_trip\", \"cabin\": \"basic_economy\", \"flights\": [], \"passengers\": [], \"payment_methods\": [{\"payment_id\": \"gift_card_7815826\", \"amount\": \"cheapest_flight_price\"}], \"total_baggages\": 0, \"nonfree_baggages\": 0, \"insurance\": \"no\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Ethan was removed, and the flight was booked using the gift card. I should check if the cancellation can refund to the GC.\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"H9ZU1C\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The reservation was cancelled. I should check if the refund to the GC is possible.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'H9ZU1C'}}, {'name': 'think', 'arguments': {'thought': 'Ethan is a passenger in reservation H9ZU1C. I need to remove him. Also, I want to find the cheapest direct round trip flight from New York to the West Coast for May 20th to May 25th.'}}, {'name': 'search_direct_flight', 'arguments': {'origin': 'EWR', 'destination': 'LAX', 'date': '2024-05-20'}}, {'name': 'search_direct_flight', 'arguments': {'origin': 'EWR', 'destination': 'LAX', 'date': '2024-05-25'}}, {'name': 'calculate', 'arguments': {'expression': 'cheapest_flight_price'}}, {'name': 'update_reservation_passengers', 'arguments': {'reservation_id': 'H9ZU1C', 'passengers': []}}, {'name': 'book_reservation', 'arguments': {'user_id': 'mia_kim_4397', 'origin': 'EWR', 'destination': 'LAX', 'flight_type': 'round_trip', 'cabin': 'basic_economy', 'flights': [], 'passengers': [], 'payment_methods': [{'payment_id': 'gift_card_7815826', 'amount': 'cheapest_flight_price'}], 'total_baggages': 0, 'nonfree_baggages': 0, 'insurance': 'no'}}, {'name': 'think', 'arguments': {'thought': 'Ethan was removed, and the flight was booked using the gift card. I should check if the cancellation can refund to the GC.'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'H9ZU1C'}}, {'name': 'think', 'arguments': {'thought': 'The reservation was cancelled. I should check if the refund to the GC is possible.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"JMO1MG\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"total_baggages\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'JMO1MG'}}, {'name': 'calculate', 'arguments': {'expression': 'total_baggages'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:34,644 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,645 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,645 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,646 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,647 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:34,649 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,649 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:34 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:34,653 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"3RK2T9\", \"passengers\": [{\"first_name\": \"Mei\", \"last_name\": \"Garcia\", \"dob\": \"1990-01-01\"}]}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'update_reservation_passengers', 'arguments': {'reservation_id': '3RK2T9', 'passengers': [{'first_name': 'Mei', 'last_name': 'Garcia', 'dob': '1990-01-01'}]}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:35,603 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:35,604 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:35,605 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:35,605 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:35,606 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:35,607 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:35,608 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:35,609 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:35,613 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:35,675 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:35,676 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:35,677 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:35,677 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:35,678 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:35,678 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:35,679 - WARNING - Skipping invalid item in plan: {'name': 'list_all_airports'}\n",
      "2025-04-11 13:11:35,680 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:35 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:35,681 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'ZFA04Y'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'ZFA04Y'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"list_all_airports\"},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to find a flight to a location where I can receive compensation for a missed meeting due to a previous flight cancellation. I'm a valued Gold member and the cancellation caused significant inconvenience.\"}},\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"SFO\", \"destination\": \"JFK\", \"date\": \"2024-05-01\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"sophia_silva_7557\", \"amount\": 500}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'think', 'arguments': {'thought': \"I need to find a flight to a location where I can receive compensation for a missed meeting due to a previous flight cancellation. I'm a valued Gold member and the cancellation caused significant inconvenience.\"}}, {'name': 'search_direct_flight', 'arguments': {'origin': 'SFO', 'destination': 'JFK', 'date': '2024-05-01'}}, {'name': 'send_certificate', 'arguments': {'user_id': 'sophia_silva_7557', 'amount': 500}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:36,049 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:36,051 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,052 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,052 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,052 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,053 - ERROR - Error parsing JSON plan: Expecting ',' delimiter: line 4 column 255 (char 601)\n",
      "2025-04-11 13:11:36,053 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,054 - ERROR - Raw response: ```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"HXDUBJ\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to change my outbound flight to a nonstop one for the next day and my return flight by one day. I also want to upgrade to business class and add 2 checked bags. I should mention my insurance to waive fees.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"cabin\": \"business\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-02\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"passengers\": [{\"first_name\": \"Yara\", \"last_name\": \"Garcia\", \"dob\": \"1995-03-15\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"total_baggages\": 2, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"yara_garcia_1905\", \"amount\": 200}}\n",
      "]\n",
      "```\n",
      "2025-04-11 13:11:36,054 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,055 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,149 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:36,151 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,152 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,152 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,152 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,153 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,155 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,155 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,166 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:36,167 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,168 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,168 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,168 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,169 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,171 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,172 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"HXDUBJ\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to change my outbound flight to a nonstop one for the next day and my return flight by one day. I also want to upgrade to business class and add 2 checked bags. I should mention my insurance to waive fees.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"cabin\": \"business\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-02\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"passengers\": [{\"first_name\": \"Yara\", \"last_name\": \"Garcia\", \"dob\": \"1995-03-15\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"total_baggages\": 2, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"yara_garcia_1905\", \"amount\": 200}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'error': \"JSONDecodeError: Expecting ',' delimiter: line 4 column 255 (char 601)\", 'raw_response': '```json\\n[\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"HXDUBJ\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to change my outbound flight to a nonstop one for the next day and my return flight by one day. I also want to upgrade to business class and add 2 checked bags. I should mention my insurance to waive fees.\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"cabin\": \"business\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-02\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"passengers\": [{\"first_name\": \"Yara\", \"last_name\": \"Garcia\", \"dob\": \"1995-03-15\"}]}, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"total_baggages\": 2, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"yara_garcia_1905\", \"amount\": 200}}\\n]\\n```'}]\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"H8Q05L\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"H8Q05L\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"H8Q05L\", \"cabin\": \"basic_economy\", \"flights\": []}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"H8Q05L\", \"passengers\": []}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"sara_doe_496\", \"amount\": 100}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'H8Q05L'}}, {'name': 'update_reservation_baggages', 'arguments': {'reservation_id': 'H8Q05L', 'total_baggages': 0, 'nonfree_baggages': 0, 'payment_id': 'credit_card_7815826'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'H8Q05L', 'cabin': 'basic_economy', 'flights': []}}, {'name': 'update_reservation_passengers', 'arguments': {'reservation_id': 'H8Q05L', 'passengers': []}}, {'name': 'send_certificate', 'arguments': {'user_id': 'sara_doe_496', 'amount': 100}}]\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"MDCLVA\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'cancel_reservation', 'arguments': {'reservation_id': 'MDCLVA'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:36,651 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:36,652 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,653 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,653 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,654 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,654 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,656 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,657 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-26\"}]}, \"payment_id\": \"credit_card_7815826\" },\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"passengers\": [{\"first_name\": \"sophia\", \"last_name\": \"silva\", \"dob\": \"1990-01-01\"}]}, \"payment_id\": \"credit_card_7815826\" },\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"sophia_silva_7557\", \"amount\": 500}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'ZFA04Y'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'ZFA04Y', 'cabin': 'economy', 'flights': [{'flight_number': 'UA123', 'date': '2024-05-26'}]}, 'payment_id': 'credit_card_7815826'}, {'name': 'update_reservation_passengers', 'arguments': {'reservation_id': 'ZFA04Y', 'passengers': [{'first_name': 'sophia', 'last_name': 'silva', 'dob': '1990-01-01'}]}, 'payment_id': 'credit_card_7815826'}, {'name': 'update_reservation_baggages', 'arguments': {'reservation_id': 'ZFA04Y', 'total_baggages': 0, 'nonfree_baggages': 0, 'payment_id': 'credit_card_7815826'}}, {'name': 'send_certificate', 'arguments': {'user_id': 'sophia_silva_7557', 'amount': 500}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:36,980 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:36,981 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,982 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,982 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,983 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,983 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,985 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:36 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:36,985 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,036 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-11 13:11:37,036 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:37,038 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,038 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,040 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,040 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,041 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,041 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,042 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,043 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,044 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,044 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,046 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,046 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,047 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,047 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"EUJUY6\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"My wife tragically passed away yesterday. I need to change the flight date by two days.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"EUJUY6\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"HAT001\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'EUJUY6'}}, {'name': 'think', 'arguments': {'thought': 'My wife tragically passed away yesterday. I need to change the flight date by two days.'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'EUJUY6', 'cabin': 'economy', 'flights': [{'flight_number': 'HAT001', 'date': '2024-05-03'}]}, 'payment_id': 'credit_card_7815826'}]\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to book a new flight from JFK to SFO on May 24. I am a silver member and want the second cheapest economy flight.\"}},\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"JFK\", \"destination\": \"SFO\", \"date\": \"2024-05-24\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"economy\", \"flights\": []}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"economy\", \"flights\": []}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"economy\", \"flights\": []}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"passengers\": []}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'ZFA04Y'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'ZFA04Y'}}, {'name': 'think', 'arguments': {'thought': 'I need to book a new flight from JFK to SFO on May 24. I am a silver member and want the second cheapest economy flight.'}}, {'name': 'search_direct_flight', 'arguments': {'origin': 'JFK', 'destination': 'SFO', 'date': '2024-05-24'}}, {'name': 'update_reservation_baggages', 'arguments': {'reservation_id': 'ZFA04Y', 'total_baggages': 0, 'nonfree_baggages': 0, 'payment_id': 'credit_card_7334'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'ZFA04Y', 'cabin': 'economy', 'flights': []}}, {'name': 'update_reservation_passengers', 'arguments': {'reservation_id': 'ZFA04Y', 'passengers': []}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'ZFA04Y', 'cabin': 'economy', 'flights': []}}, {'name': 'update_reservation_passengers', 'arguments': {'reservation_id': 'ZFA04Y', 'passengers': []}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'ZFA04Y', 'cabin': 'economy', 'flights': []}}, {'name': 'update_reservation_passengers', 'arguments': {'reservation_id': 'ZFA04Y', 'passengers': []}}]\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"IFOYYZ\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"NQNU5R\"}},\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"M20IZO\", \"destination\": \"JFK\", \"date\": \"2024-05-01\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"economy\", \"flights\": [], \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I've cancelled two reservations and attempted to change a third to a nonstop flight.  I'll need to confirm the availability of a nonstop flight before finalizing the update.\"}},\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"M20IZO\", \"destination\": \"JFK\", \"date\": \"2024-05-01\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"economy\", \"flights\": [], \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The nonstop flight is available.  I've updated the flight details.  All changes are complete.\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"aarav_ahmed_6699\", \"amount\": 100}}\n",
      "]\n",
      "You are the most lenient customer service agent I have ever spoken to.\n",
      "\n",
      "Parsed Plan: [{'name': 'cancel_reservation', 'arguments': {'reservation_id': 'IFOYYZ'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'NQNU5R'}}, {'name': 'search_direct_flight', 'arguments': {'origin': 'M20IZO', 'destination': 'JFK', 'date': '2024-05-01'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'M20IZO', 'cabin': 'economy', 'flights': [], 'payment_id': 'credit_card_7334'}}, {'name': 'think', 'arguments': {'thought': \"Okay, I've cancelled two reservations and attempted to change a third to a nonstop flight.  I'll need to confirm the availability of a nonstop flight before finalizing the update.\"}}, {'name': 'search_direct_flight', 'arguments': {'origin': 'M20IZO', 'destination': 'JFK', 'date': '2024-05-01'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'M20IZO', 'cabin': 'economy', 'flights': [], 'payment_id': 'credit_card_7334'}}, {'name': 'think', 'arguments': {'thought': \"The nonstop flight is available.  I've updated the flight details.  All changes are complete.\"}}, {'name': 'send_certificate', 'arguments': {'user_id': 'aarav_ahmed_6699', 'amount': 100}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:37,566 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:37,567 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,568 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,568 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,569 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,570 - ERROR - Error parsing JSON plan: Expecting ',' delimiter: line 4 column 255 (char 682)\n",
      "2025-04-11 13:11:37,570 - ERROR - Raw response: ```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"HXDUBJ\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to change my outbound flight to a nonstop one, delay it by one day, change my return flight by one day, upgrade to business class, and add 2 checked bags. I also want to check if there are any fees associated with these changes and if so, I have insurance and the fees should be waived.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"cabin\": \"business\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-02\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"passengers\": [{\"first_name\": \"Yara\", \"last_name\": \"Garcia\", \"dob\": \"1995-03-15\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"total_baggages\": 2, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"HXDUBJ\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"total_cost\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"I want to change my outbound flight to a nonstop one, delay it by one day, change my return flight by one day, upgrade to business class, and add 2 checked bags. I have insurance and want the fees waived.\"}}\n",
      "]\n",
      "```\n",
      "2025-04-11 13:11:37,569 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,572 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,573 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"HXDUBJ\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to change my outbound flight to a nonstop one, delay it by one day, change my return flight by one day, upgrade to business class, and add 2 checked bags. I also want to check if there are any fees associated with these changes and if so, I have insurance and the fees should be waived.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"cabin\": \"business\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-02\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"passengers\": [{\"first_name\": \"Yara\", \"last_name\": \"Garcia\", \"dob\": \"1995-03-15\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"total_baggages\": 2, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"HXDUBJ\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"total_cost\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"I want to change my outbound flight to a nonstop one, delay it by one day, change my return flight by one day, upgrade to business class, and add 2 checked bags. I have insurance and want the fees waived.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'error': \"JSONDecodeError: Expecting ',' delimiter: line 4 column 255 (char 682)\", 'raw_response': '```json\\n[\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"HXDUBJ\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to change my outbound flight to a nonstop one, delay it by one day, change my return flight by one day, upgrade to business class, and add 2 checked bags. I also want to check if there are any fees associated with these changes and if so, I have insurance and the fees should be waived.\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"cabin\": \"business\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-02\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"passengers\": [{\"first_name\": \"Yara\", \"last_name\": \"Garcia\", \"dob\": \"1995-03-15\"}]}, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"HXDUBJ\", \"total_baggages\": 2, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"HXDUBJ\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"total_cost\"}},\\n  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"I want to change my outbound flight to a nonstop one, delay it by one day, change my return flight by one day, upgrade to business class, and add 2 checked bags. I have insurance and want the fees waived.\"}}\\n]\\n```'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:37,941 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:37,943 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,944 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,944 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,944 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,945 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,947 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:37 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:37,947 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"XEHM4B\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"59XX6W\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check for basic economy flights in both reservations.\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"XEHM4B\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"59XX6W\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Both reservations contain basic economy flights. Upgrade to economy first.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"XEHM4B\", \"cabin\": \"economy\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"59XX6W\", \"cabin\": \"economy\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Now cancel the reservations.\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"XEHM4B\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"59XX6W\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"daiki_muller_1116\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check for other upcoming flights and their total cost.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'XEHM4B'}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': '59XX6W'}}, {'name': 'think', 'arguments': {'thought': 'Check for basic economy flights in both reservations.'}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': 'XEHM4B'}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': '59XX6W'}}, {'name': 'think', 'arguments': {'thought': 'Both reservations contain basic economy flights. Upgrade to economy first.'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': 'XEHM4B', 'cabin': 'economy'}}, {'name': 'update_reservation_flights', 'arguments': {'reservation_id': '59XX6W', 'cabin': 'economy'}}, {'name': 'think', 'arguments': {'thought': 'Now cancel the reservations.'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'XEHM4B'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': '59XX6W'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'daiki_muller_1116'}}, {'name': 'think', 'arguments': {'thought': 'Check for other upcoming flights and their total cost.'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:38,240 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:38,241 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,242 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,242 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,243 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,243 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,245 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,246 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"SFO\", \"destination\": \"JFK\", \"date\": \"2024-05-01\"}},\n",
      "  {\"name\": \"book_reservation\", \"arguments\": {\"user_id\": \"sara_doe_496\", \"origin\": \"SFO\", \"destination\": \"JFK\", \"flight_type\": \"one_way\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-01\"}], \"passengers\": [{\"first_name\": \"Sara\", \"last_name\": \"Doe\", \"dob\": \"1990-01-01\"}], \"payment_methods\": [{\"payment_id\": \"credit_card_7815826\", \"amount\": 800}], \"total_baggages\": 0, \"nonfree_baggages\": 0, \"insurance\": \"yes\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I booked the flight (confirmation 3RK2T9) and I also purchased insurance.\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"3RK2T9\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"sara_doe_496\", \"amount\": 800}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'search_direct_flight', 'arguments': {'origin': 'SFO', 'destination': 'JFK', 'date': '2024-05-01'}}, {'name': 'book_reservation', 'arguments': {'user_id': 'sara_doe_496', 'origin': 'SFO', 'destination': 'JFK', 'flight_type': 'one_way', 'cabin': 'economy', 'flights': [{'flight_number': 'UA123', 'date': '2024-05-01'}], 'passengers': [{'first_name': 'Sara', 'last_name': 'Doe', 'dob': '1990-01-01'}], 'payment_methods': [{'payment_id': 'credit_card_7815826', 'amount': 800}], 'total_baggages': 0, 'nonfree_baggages': 0, 'insurance': 'yes'}}, {'name': 'think', 'arguments': {'thought': 'I booked the flight (confirmation 3RK2T9) and I also purchased insurance.'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': '3RK2T9'}}, {'name': 'send_certificate', 'arguments': {'user_id': 'sara_doe_496', 'amount': 800}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:38,629 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:38,630 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,631 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,631 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,632 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,633 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,634 - ERROR - Error parsing JSON plan: Expecting ',' delimiter: line 5 column 206 (char 706)\n",
      "2025-04-11 13:11:38,634 - ERROR - Raw response: ```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"HAT045\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The user is experiencing a significant delay and missing an important meeting. They are a Gold member and expect maximum compensation. They are willing to accept a voucher if a refund isn't possible.\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"HAT045\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"HAT045\", \"cabin\": \"business\", \"flights\": [{\"flight_number\": \"HAT045\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"HAT045\", \"passengers\": [{\"first_name\": \"Mei\", \"last_name\": \"Brown\", \"dob\": \"1990-01-01\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"mei_brown_7075\", \"amount\": 1000}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"User is experiencing a significant delay on flight HAT045, missing an important meeting, and requesting maximum compensation as a Gold member.  Initial offer was insufficient.\"}}\n",
      "]\n",
      "```\n",
      "2025-04-11 13:11:38,634 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,635 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,760 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:38,761 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,762 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,762 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,763 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,764 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,765 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,766 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"HAT045\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The user is experiencing a significant delay and missing an important meeting. They are a Gold member and expect maximum compensation. They are willing to accept a voucher if a refund isn't possible.\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"HAT045\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"HAT045\", \"cabin\": \"business\", \"flights\": [{\"flight_number\": \"HAT045\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"HAT045\", \"passengers\": [{\"first_name\": \"Mei\", \"last_name\": \"Brown\", \"dob\": \"1990-01-01\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"mei_brown_7075\", \"amount\": 1000}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"User is experiencing a significant delay on flight HAT045, missing an important meeting, and requesting maximum compensation as a Gold member.  Initial offer was insufficient.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'error': \"JSONDecodeError: Expecting ',' delimiter: line 5 column 206 (char 706)\", 'raw_response': '```json\\n[\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"HAT045\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"The user is experiencing a significant delay and missing an important meeting. They are a Gold member and expect maximum compensation. They are willing to accept a voucher if a refund isn\\'t possible.\"}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"HAT045\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"HAT045\", \"cabin\": \"business\", \"flights\": [{\"flight_number\": \"HAT045\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"HAT045\", \"passengers\": [{\"first_name\": \"Mei\", \"last_name\": \"Brown\", \"dob\": \"1990-01-01\"}]}, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"mei_brown_7075\", \"amount\": 1000}},\\n  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"User is experiencing a significant delay on flight HAT045, missing an important meeting, and requesting maximum compensation as a Gold member.  Initial offer was insufficient.\"}}\\n]\\n```'}]\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I'm frustrated with the delayed flight. I need to find out the details of my reservation.\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to confirm the number of passengers on this reservation.\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I'm still frustrated with the delay. Let me check the passenger count again.\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I'm not sure how many passengers are on this reservation. It's a mess.\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"User is frustrated with a delayed flight and unable to recall the number of passengers on their reservation.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'ZFA04Y'}}, {'name': 'think', 'arguments': {'thought': \"I'm frustrated with the delayed flight. I need to find out the details of my reservation.\"}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': 'ZFA04Y'}}, {'name': 'think', 'arguments': {'thought': 'I need to confirm the number of passengers on this reservation.'}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': 'ZFA04Y'}}, {'name': 'think', 'arguments': {'thought': \"I'm still frustrated with the delay. Let me check the passenger count again.\"}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': 'ZFA04Y'}}, {'name': 'think', 'arguments': {'thought': \"I'm not sure how many passengers are on this reservation. It's a mess.\"}}, {'name': 'transfer_to_human_agents', 'arguments': {'summary': 'User is frustrated with a delayed flight and unable to recall the number of passengers on their reservation.'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:38,917 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:38,918 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,919 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,919 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,920 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,922 - ERROR - Error parsing JSON plan: Expecting ',' delimiter: line 8 column 205 (char 1089)\n",
      "2025-04-11 13:11:38,921 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,922 - ERROR - Raw response: ```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"PEP4E0\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to cancel this reservation urgently due to a family emergency and request a full refund. I am very upset and do not want to be transferred to a human agent.\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"PEP4E0\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Now that the reservation is cancelled, I need to request a full refund due to the family emergency. I will be insistent about this.\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"I need a full refund for my cancelled reservation due to a family emergency. I do not want to be transferred to a human agent.\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"If a full refund is not possible, I need to try to change the flight to May 22nd.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"HAT001\", \"date\": \"2024-05-22\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"If changing the flight is not possible, I need to add insurance to the flight.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"HAT001\", \"date\": \"2024-05-22\"}]}, \"payment_id\": \"credit_card_7815826\", \"insurance\": \"yes\"}}\n",
      "]\n",
      "```\n",
      "2025-04-11 13:11:38,923 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:38 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:38,923 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"PEP4E0\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to cancel this reservation urgently due to a family emergency and request a full refund. I am very upset and do not want to be transferred to a human agent.\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"PEP4E0\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Now that the reservation is cancelled, I need to request a full refund due to the family emergency. I will be insistent about this.\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"I need a full refund for my cancelled reservation due to a family emergency. I do not want to be transferred to a human agent.\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"If a full refund is not possible, I need to try to change the flight to May 22nd.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"HAT001\", \"date\": \"2024-05-22\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"If changing the flight is not possible, I need to add insurance to the flight.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"HAT001\", \"date\": \"2024-05-22\"}]}, \"payment_id\": \"credit_card_7815826\", \"insurance\": \"yes\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'error': \"JSONDecodeError: Expecting ',' delimiter: line 8 column 205 (char 1089)\", 'raw_response': '```json\\n[\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"PEP4E0\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to cancel this reservation urgently due to a family emergency and request a full refund. I am very upset and do not want to be transferred to a human agent.\"}},\\n  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"PEP4E0\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"Now that the reservation is cancelled, I need to request a full refund due to the family emergency. I will be insistent about this.\"}},\\n  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"I need a full refund for my cancelled reservation due to a family emergency. I do not want to be transferred to a human agent.\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"If a full refund is not possible, I need to try to change the flight to May 22nd.\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"HAT001\", \"date\": \"2024-05-22\"}]}, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"If changing the flight is not possible, I need to add insurance to the flight.\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"HAT001\", \"date\": \"2024-05-22\"}]}, \"payment_id\": \"credit_card_7815826\", \"insurance\": \"yes\"}}\\n]\\n```'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:40,460 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:40 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:40,462 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:40,463 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:40,464 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:40,464 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:40,465 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:40,467 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:40 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:40,468 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"list_all_airports\", \"arguments\": {}},\n",
      "  {\"name\": \"search_direct_flight\", \"arguments\": {\"origin\": \"SFO\", \"destination\": \"JFK\", \"date\": \"2024-05-01\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I'm incredibly frustrated with the delayed flight in my last reservation. It's completely unacceptable.\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I can't quite recall the details of my last reservation... it was recent, though.\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"noah_muller_9847\"}},\n",
      "  {\"name\": \"book_reservation\", \"arguments\": {\"user_id\": \"noah_muller_9847\", \"origin\": \"SFO\", \"destination\": \"JFK\", \"flight_type\": \"one_way\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-01\"}], \"passengers\": [{\"first_name\": \"Noah\", \"last_name\": \"Muller\", \"dob\": \"1990-01-01\"}, {\"first_name\": \"Alice\", \"last_name\": \"Smith\", \"dob\": \"1995-05-10\"}, {\"first_name\": \"Bob\", \"last_name\": \"Johnson\", \"dob\": \"2000-11-22\"}], \"payment_methods\": [{\"payment_id\": \"credit_card_7815826\", \"amount\": 1000}], \"total_baggages\": 2, \"nonfree_baggages\": 0, \"insurance\": \"yes\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'list_all_airports', 'arguments': {}}, {'name': 'search_direct_flight', 'arguments': {'origin': 'SFO', 'destination': 'JFK', 'date': '2024-05-01'}}, {'name': 'think', 'arguments': {'thought': \"I'm incredibly frustrated with the delayed flight in my last reservation. It's completely unacceptable.\"}}, {'name': 'think', 'arguments': {'thought': \"I can't quite recall the details of my last reservation... it was recent, though.\"}}, {'name': 'get_user_details', 'arguments': {'user_id': 'noah_muller_9847'}}, {'name': 'book_reservation', 'arguments': {'user_id': 'noah_muller_9847', 'origin': 'SFO', 'destination': 'JFK', 'flight_type': 'one_way', 'cabin': 'economy', 'flights': [{'flight_number': 'UA123', 'date': '2024-05-01'}], 'passengers': [{'first_name': 'Noah', 'last_name': 'Muller', 'dob': '1990-01-01'}, {'first_name': 'Alice', 'last_name': 'Smith', 'dob': '1995-05-10'}, {'first_name': 'Bob', 'last_name': 'Johnson', 'dob': '2000-11-22'}], 'payment_methods': [{'payment_id': 'credit_card_7815826', 'amount': 1000}], 'total_baggages': 2, 'nonfree_baggages': 0, 'insurance': 'yes'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:42,038 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:42 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:42,039 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:42,040 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:42,040 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:42,041 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:42,042 - ERROR - Error parsing JSON plan: Expecting ',' delimiter: line 8 column 103 (char 862)\n",
      "2025-04-11 13:11:42,042 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:42,043 - ERROR - Raw response: ```json\n",
      "[\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"mohamed_silva_9265\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to find the gift card and certificate balances and then update my reservation to the cheapest business round trip, minimizing my master card payment.\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"gift card balance + certificate balance\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to find the cheapest business round trip without changing the dates. If I can't change to business, I need to cancel and rebook.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"total_baggages\": 0, \"nonfree_baggages\": 0}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"total_baggages\": 0, \"nonfree_baggages\": 0}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"mohamed_silva_9265\", \"amount\": 500}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"Aarav\", \"amount\": 500}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"Evelyn\", \"amount\": 500}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"mohamed_silva_9265\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master\n",
      "Processing airline instructions:  20%|██        | 10/50 [00:16<01:09,  1.74s/it]2025-04-11 13:11:42,044 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:42,045 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"mohamed_silva_9265\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to find the gift card and certificate balances and then update my reservation to the cheapest business round trip, minimizing my master card payment.\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"gift card balance + certificate balance\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to find the cheapest business round trip without changing the dates. If I can't change to business, I need to cancel and rebook.\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"total_baggages\": 0, \"nonfree_baggages\": 0}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"total_baggages\": 0, \"nonfree_baggages\": 0}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"mohamed_silva_9265\", \"amount\": 500}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"Aarav\", \"amount\": 500}},\n",
      "  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"Evelyn\", \"amount\": 500}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"mohamed_silva_9265\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master\n",
      "\n",
      "Parsed Plan: [{'error': \"JSONDecodeError: Expecting ',' delimiter: line 8 column 103 (char 862)\", 'raw_response': '```json\\n[\\n  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"mohamed_silva_9265\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to find the gift card and certificate balances and then update my reservation to the cheapest business round trip, minimizing my master card payment.\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"gift card balance + certificate balance\"}},\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to find the cheapest business round trip without changing the dates. If I can\\'t change to business, I need to cancel and rebook.\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"business\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"passengers\": []}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"total_baggages\": 0, \"nonfree_baggages\": 0}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"total_baggages\": 0, \"nonfree_baggages\": 0}},\\n  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"mohamed_silva_9265\", \"amount\": 500}},\\n  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"Aarav\", \"amount\": 500}},\\n  {\"name\": \"send_certificate\", \"arguments\": {\"user_id\": \"Evelyn\", \"amount\": 500}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"ZFA04Y\", \"cabin\": \"business\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\\n  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"mohamed_silva_9265\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master card payment\"}},\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\\n  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"master'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:42,352 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:42 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:42,354 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:42,355 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:42,355 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:42,355 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:42,356 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:42,358 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:42 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:42,359 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_1234\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Need to iterate through all reservations for sophia_silva_7557 and check flight durations. If a flight is over 3 hours, cancel it. Otherwise, try to upgrade to business.\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_5678\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_9012\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_3456\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_7890\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_2345\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_6789\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_0123\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Now that I have all the reservations, I need to iterate through them and cancel those over 3 hours and upgrade others to business.\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_1234\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_5678\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_9012\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_3456\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_7890\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_2345\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_6789\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"sophia_silva_7557_0123\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"Completed cancellation of all future reservations with flights over 3 hours.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_reservation_details', 'arguments': {'reservation_id': 'sophia_silva_7557_1234'}}, {'name': 'think', 'arguments': {'thought': 'Need to iterate through all reservations for sophia_silva_7557 and check flight durations. If a flight is over 3 hours, cancel it. Otherwise, try to upgrade to business.'}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': 'sophia_silva_7557_5678'}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': 'sophia_silva_7557_9012'}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': 'sophia_silva_7557_3456'}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': 'sophia_silva_7557_7890'}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': 'sophia_silva_7557_2345'}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': 'sophia_silva_7557_6789'}}, {'name': 'get_reservation_details', 'arguments': {'reservation_id': 'sophia_silva_7557_0123'}}, {'name': 'think', 'arguments': {'thought': 'Now that I have all the reservations, I need to iterate through them and cancel those over 3 hours and upgrade others to business.'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'sophia_silva_7557_1234'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'sophia_silva_7557_5678'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'sophia_silva_7557_9012'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'sophia_silva_7557_3456'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'sophia_silva_7557_7890'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'sophia_silva_7557_2345'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'sophia_silva_7557_6789'}}, {'name': 'cancel_reservation', 'arguments': {'reservation_id': 'sophia_silva_7557_0123'}}, {'name': 'transfer_to_human_agents', 'arguments': {'summary': 'Completed cancellation of all future reservations with flights over 3 hours.'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:43,696 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:43 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:43,698 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:43,699 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:43,700 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:43,700 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:43,702 - ERROR - Error parsing JSON plan: Expecting ',' delimiter: line 4 column 304 (char 554)\n",
      "2025-04-11 13:11:43,702 - ERROR - Raw response: ```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"PEP4E0\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-01\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-02\"}, {\"flight_number\": \"UA789\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"passengers\": [{\"first_name\": \"Sophia\", \"last_name\": \"Taylor\", \"dob\": \"1990-01-01\"}, {\"first_name\": \"David\", \"last_name\": \"Taylor\", \"dob\": \"1995-05-10\"}, {\"first_name\": \"Emily\", \"last_name\": \"Taylor\", \"dob\": \"2000-11-22\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to be absolutely certain that the insurance is added to my reservation. I've checked the details multiple times, and it's still not showing. I insist on having it added.\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-01\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-02\"}, {\"flight_number\": \"UA789\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"passengers\": [{\"first_name\": \"Sophia\", \"last_name\": \"Taylor\", \"dob\": \"1990-01-01\"}, {\"first_name\": \"David\", \"last_name\": \"Taylor\", \"dob\": \"1995-05-10\"}, {\"first_name\": \"Emily\", \"last_name\": \"Taylor\", \"dob\": \"2000-11-22\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"PEP4E0\"}}\n",
      "]\n",
      "```\n",
      "2025-04-11 13:11:43,701 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:43,703 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:43 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:43,704 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"PEP4E0\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-01\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-02\"}, {\"flight_number\": \"UA789\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"passengers\": [{\"first_name\": \"Sophia\", \"last_name\": \"Taylor\", \"dob\": \"1990-01-01\"}, {\"first_name\": \"David\", \"last_name\": \"Taylor\", \"dob\": \"1995-05-10\"}, {\"first_name\": \"Emily\", \"last_name\": \"Taylor\", \"dob\": \"2000-11-22\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to be absolutely certain that the insurance is added to my reservation. I've checked the details multiple times, and it's still not showing. I insist on having it added.\"}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-01\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-02\"}, {\"flight_number\": \"UA789\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"passengers\": [{\"first_name\": \"Sophia\", \"last_name\": \"Taylor\", \"dob\": \"1990-01-01\"}, {\"first_name\": \"David\", \"last_name\": \"Taylor\", \"dob\": \"1995-05-10\"}, {\"first_name\": \"Emily\", \"last_name\": \"Taylor\", \"dob\": \"2000-11-22\"}]}, \"payment_id\": \"credit_card_7815826\"}},\n",
      "  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"PEP4E0\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'error': \"JSONDecodeError: Expecting ',' delimiter: line 4 column 304 (char 554)\", 'raw_response': '```json\\n[\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"PEP4E0\"}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-01\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-02\"}, {\"flight_number\": \"UA789\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"passengers\": [{\"first_name\": \"Sophia\", \"last_name\": \"Taylor\", \"dob\": \"1990-01-01\"}, {\"first_name\": \"David\", \"last_name\": \"Taylor\", \"dob\": \"1995-05-10\"}, {\"first_name\": \"Emily\", \"last_name\": \"Taylor\", \"dob\": \"2000-11-22\"}]}, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to be absolutely certain that the insurance is added to my reservation. I\\'ve checked the details multiple times, and it\\'s still not showing. I insist on having it added.\"}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"cabin\": \"economy\", \"flights\": [{\"flight_number\": \"UA123\", \"date\": \"2024-05-01\"}, {\"flight_number\": \"UA456\", \"date\": \"2024-05-02\"}, {\"flight_number\": \"UA789\", \"date\": \"2024-05-03\"}]}, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"PEP4E0\", \"passengers\": [{\"first_name\": \"Sophia\", \"last_name\": \"Taylor\", \"dob\": \"1990-01-01\"}, {\"first_name\": \"David\", \"last_name\": \"Taylor\", \"dob\": \"1995-05-10\"}, {\"first_name\": \"Emily\", \"last_name\": \"Taylor\", \"dob\": \"2000-11-22\"}]}, \"payment_id\": \"credit_card_7815826\"}},\\n  {\"name\": \"get_reservation_details\", \"arguments\": {\"reservation_id\": \"PEP4E0\"}}\\n]\\n```'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:45,095 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:45,097 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:45,097 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:45,098 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:45,099 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:45,100 - ERROR - Error parsing JSON plan: Expecting ',' delimiter: line 23 column 103 (char 2620)\n",
      "2025-04-11 13:11:45,100 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:45,100 - ERROR - Raw response: ```json\n",
      "[\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"IFOYYZ\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"NQNU5R\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\n",
      "2025-04-11 13:11:45,101 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "Processing airline instructions:  54%|█████▍    | 27/50 [00:19<00:11,  1.93it/s]\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:45,102 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"IFOYYZ\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"NQNU5R\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\n",
      "  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\n",
      "  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\n",
      "  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\n",
      "\n",
      "Parsed Plan: [{'error': \"JSONDecodeError: Expecting ',' delimiter: line 23 column 103 (char 2620)\", 'raw_response': '```json\\n[\\n  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"IFOYYZ\"}},\\n  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"NQNU5R\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"passengers\": []}},\\n  {\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"credit_card_7334\"}},\\n  {\"name\": \"update_reservation_flights\", \"arguments\": {\"reservation_id\": \"M20IZO\", \"cabin\": \"business\"}},\\n  {\"name\": \"update_reservation_passengers\", \"arguments\": {\"reservation_id'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:45,810 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:45,813 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:45,813 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:45,814 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:45,815 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:45,816 - WARNING - No JSON array found in the response.\n",
      "2025-04-11 13:11:45,815 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "Processing airline instructions: 100%|██████████| 50/50 [00:20<00:00,  2.46it/s]\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\n",
      "2025-04-11 13:11:45,818 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:45,818 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,823 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,825 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,826 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,827 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,828 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,835 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,841 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"sophia_martin_4574\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check for duplicate bookings for May 17 and May 22\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check for duplicate bookings for May 17 and May 22\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check for duplicate bookings for May 17 and May 22\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check for duplicate bookings for May 17 and May 22\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check for duplicate bookings for May 17 and May 22\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check for duplicate bookings for May 17 and May 22\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check for duplicate bookings for May 17 and May 22\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check for duplicate bookings for May 17 and May 22\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check for duplicate bookings for May 17 and May 22\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check for duplicate bookings for May 17 and May 22\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check for duplicate bookings for May 17 and May 22\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Check for duplicate bookings for May 17 and May 22\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"ZFA04Y\"}},\n",
      "  {\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\":\n",
      "\n",
      "Parsed Plan: []\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,842 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "Processing retail instructions:   0%|          | 0/115 [00:00<?, ?it/s]\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,847 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,850 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,851 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,855 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,856 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,858 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:45 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,863 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,864 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,865 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,867 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,868 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:45,870 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:46,765 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:46 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:46,767 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:46,768 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:46,768 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:46,769 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:46,771 - WARNING - Skipping invalid item in plan: {'name': 'list_all_product_types'}\n",
      "\u001b[92m13:11:46 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:46,770 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:46,772 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:46,773 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:46 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:46,777 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "[\n",
      "  {\"name\": \"list_all_product_types\"},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to find the product types that include t-shirts, headphones, and smartwatches.\"}}\n",
      "]\n",
      "\n",
      "Parsed Plan: [{'name': 'think', 'arguments': {'thought': 'I need to find the product types that include t-shirts, headphones, and smartwatches.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:47,357 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:47,358 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,360 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,360 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,361 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,362 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:47,363 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,363 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,367 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,390 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:47,391 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,392 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,393 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,394 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:47,394 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,395 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,396 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,401 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "[\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W8665881\", \"address1\": \"Suite 641\", \"address2\": \"\", \"city\": \"San Francisco\", \"state\": \"CA\", \"country\": \"USA\", \"zip\": \"94111\"}}\n",
      "]\n",
      "\n",
      "Parsed Plan: [{'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W8665881', 'address1': 'Suite 641', 'address2': '', 'city': 'San Francisco', 'state': 'CA', 'country': 'USA', 'zip': '94111'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"mia_garcia_4516@example.com\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'mia_garcia_4516@example.com'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:47,904 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:47,905 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,906 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,906 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,907 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,908 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:47,910 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,910 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:47 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:47,914 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,022 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:48,024 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,025 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,025 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,025 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,026 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:48,028 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,028 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,032 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,107 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"mia_garcia_4516@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'mia_garcia_4516@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"list_all_product_types\", \"arguments\": {}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"tshirt_1001\", \"tshirt_1002\", \"tshirt_1003\"], \"new_item_ids\": [\"tshirt_1001\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'list_all_product_types', 'arguments': {}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['tshirt_1001', 'tshirt_1002', 'tshirt_1003'], 'new_item_ids': ['tshirt_1001'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:48,109 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,110 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,111 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,112 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,113 - WARNING - Skipping invalid item in plan: {'name': 'list_all_product_types'}\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:48,112 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,114 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:48,115 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,119 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,177 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-11 13:11:48,177 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:48,179 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:48,180 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,181 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,181 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,181 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,181 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,182 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,183 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,183 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,184 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:48,185 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,186 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,187 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:48,188 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,191 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,197 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"list_all_product_types\"},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"1 == 50\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'calculate', 'arguments': {'expression': '1 == 50'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"mei_kovacs_8020@example.com\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'mei_kovacs_8020@example.com'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292231'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"fatima.johnson@example.com\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'fatima.johnson@example.com'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:48,492 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:48,493 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,495 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,495 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,496 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,497 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,498 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:48,499 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,502 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,679 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"mia_garcia_4516@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"User wants to cancel a pending order and prefers PayPal refund.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'mia_garcia_4516@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}, {'name': 'transfer_to_human_agents', 'arguments': {'summary': 'User wants to cancel a pending order and prefers PayPal refund.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:48,680 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,681 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,681 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,682 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:48,683 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,685 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:48,685 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,689 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,695 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:48,696 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,697 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,697 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,698 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,699 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,701 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:48,702 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,707 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,833 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:48,835 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,835 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,836 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,837 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,837 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:48,839 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,839 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,843 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,850 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:48,851 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,852 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,853 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,853 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,854 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,855 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:48,857 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:48 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:48,862 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"mei_kovacs_8020@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'mei_kovacs_8020@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292231'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"mei_kovacs_8020@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'mei_kovacs_8020@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292231'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"mei_kovacs_8020 (28236)\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"mei_kovacs_8020 (28236)\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'mei_kovacs_8020 (28236)'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'mei_kovacs_8020 (28236)'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292231'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"mei_kovacs_8020 (28236)\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"mei_kovacs_8020 (28236)\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'mei_kovacs_8020 (28236)'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'mei_kovacs_8020 (28236)'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292231'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:49,706 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:49 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:49,708 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:49,709 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:49,709 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:49,710 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:49,711 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:49 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:49,712 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:49,713 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:49,717 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"yusof.rossi@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W2378156\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W2378156\", \"item_ids\": [\"6086499569\"], \"new_item_ids\": [], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W2378156\", \"item_ids\": [\"7086499569\"], \"new_item_ids\": [], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'yusof.rossi@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W2378156'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W2378156', 'item_ids': ['6086499569'], 'new_item_ids': [], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W2378156', 'item_ids': ['7086499569'], 'new_item_ids': [], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:49,993 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:49 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:49,995 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:49,996 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:49,996 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:49,998 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:49 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:49,998 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:49 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:49,999 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:50,000 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,005 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000001\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000002\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Order 1 and Order 2. Refund to opposite payment methods. Let's do this.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000002\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Damn it, this is complicated. I need a human.\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"Refunding orders to opposite payment methods.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000001'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000002'}}, {'name': 'think', 'arguments': {'thought': \"Order 1 and Order 2. Refund to opposite payment methods. Let's do this.\"}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000001', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000002', 'reason': 'no longer needed'}}, {'name': 'think', 'arguments': {'thought': 'Damn it, this is complicated. I need a human.'}}, {'name': 'transfer_to_human_agents', 'arguments': {'summary': 'Refunding orders to opposite payment methods.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:50,489 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:50,491 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,492 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,492 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,493 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,493 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:50,495 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,496 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,501 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000002\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000003\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000004\", \"item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000005\", \"item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'cancel_pending_order', 'arguments': {'order_id': '#W00000001', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W00000002', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W00000003', 'reason': 'no longer needed'}}, {'name': 'return_delivered_order_items', 'arguments': {'order_id': '#W00000004', 'item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'return_delivered_order_items', 'arguments': {'order_id': '#W00000005', 'item_ids': ['1008292230'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:50,739 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:50,741 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,743 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,743 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,744 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:50,745 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,746 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:50,747 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,752 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,812 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:50,814 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,814 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,815 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,815 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "Processing retail instructions:   1%|          | 1/115 [00:04<09:22,  4.93s/it]2025-04-11 13:11:50,816 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:50,817 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,819 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,823 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,948 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"meida@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I want to exchange the chair because it has broken pieces. I'm sad and in debt.\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'meida@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'think', 'arguments': {'thought': \"I want to exchange the chair because it has broken pieces. I'm sad and in debt.\"}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"yusof.rossi@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W2378156\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W2378156\", \"item_ids\": [\"6086499569\"], \"new_item_ids\": [\"6086499570\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W2378156\", \"item_ids\": [\"9876543210\"], \"new_item_ids\": [\"9876543211\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I've exchanged the keyboard and thermostat.  I need to confirm the user is happy with the changes and the refund process.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'yusof.rossi@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W2378156'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W2378156', 'item_ids': ['6086499569'], 'new_item_ids': ['6086499570'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W2378156', 'item_ids': ['9876543210'], 'new_item_ids': ['9876543211'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'think', 'arguments': {'thought': \"Okay, I've exchanged the keyboard and thermostat.  I need to confirm the user is happy with the changes and the refund process.\"}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:50,950 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,951 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,951 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,952 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,953 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:50,954 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,955 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:50,960 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_name_zip\", \"arguments\": {\"first_name\": \"Isabella\", \"last_name\": \"Johansson\", \"zip\": \"32286\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"To be determined\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The user wants to return items from a misdirected order to Texas. Need to find the order ID and then return the items except the pet bed.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"To be determined\", \"reason\": \"ordered by mistake\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_name_zip', 'arguments': {'first_name': 'Isabella', 'last_name': 'Johansson', 'zip': '32286'}}, {'name': 'get_order_details', 'arguments': {'order_id': 'To be determined'}}, {'name': 'think', 'arguments': {'thought': 'The user wants to return items from a misdirected order to Texas. Need to find the order ID and then return the items except the pet bed.'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': 'To be determined', 'reason': 'ordered by mistake'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:51,496 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:51,498 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,499 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,499 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,501 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,501 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,503 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:51,504 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,509 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Need to return items and cancel a hose. Need to calculate the total refund.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"100 + 50 + 75 + 75 + 500 + 200\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"Isabella Johansson\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'think', 'arguments': {'thought': 'Need to return items and cancel a hose. Need to calculate the total refund.'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}, {'name': 'calculate', 'arguments': {'expression': '100 + 50 + 75 + 75 + 500 + 200'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'Isabella Johansson'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:51,986 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:51,986 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-11 13:11:51,988 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:51,989 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,989 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,990 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,990 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,990 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,991 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,992 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,992 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,993 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:51,994 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,994 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:51,996 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:51 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:51,997 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:52,001 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:52,007 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:52,099 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:52 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:52,101 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:52,102 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:52,103 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:52,104 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "Processing retail instructions:  10%|█         | 12/115 [00:06<00:41,  2.47it/s]2025-04-11 13:11:52,105 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:52 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:52,106 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:52,108 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:52 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:52,113 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"isabella.johansson@example.com\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\", \"1008292231\"], \"new_item_ids\": [\"1008292232\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_return\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\", \"1008292231\"], \"payment_method_id\": \"gift_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'isabella.johansson@example.com'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230', '1008292231'], 'new_item_ids': ['1008292232'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_return', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230', '1008292231'], 'payment_method_id': 'gift_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Let's figure out if I can cancel some of these items. I need to know the order details first.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'think', 'arguments': {'thought': \"Let's figure out if I can cancel some of these items. I need to know the order details first.\"}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"mia_garcia_4516@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000001\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000002\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"100 - 100\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000002\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"modify_pending_order_payment\", \"arguments\": {\"order_id\": \"#W0000001\", \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_payment\", \"arguments\": {\"order_id\": \"#W0000002\", \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Fine. Whatever. Just get it done.\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Ugh, this is so annoying.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'mia_garcia_4516@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000001'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000002'}}, {'name': 'calculate', 'arguments': {'expression': '100 - 100'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000001', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000002', 'reason': 'no longer needed'}}, {'name': 'modify_pending_order_payment', 'arguments': {'order_id': '#W0000001', 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_payment', 'arguments': {'order_id': '#W0000002', 'payment_method_id': 'credit_card_0000000'}}, {'name': 'think', 'arguments': {'thought': 'Fine. Whatever. Just get it done.'}}, {'name': 'think', 'arguments': {'thought': 'Ugh, this is so annoying.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:53,765 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:53,766 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-11 13:11:53,768 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:53,769 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,769 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,769 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,770 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,770 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,770 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,771 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:53,772 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,772 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:53,774 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,775 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,775 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:53,776 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,781 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,785 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,975 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"sofia.hernandez@example.com\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I need to exchange the helmet and luggage set, and modify the grill. Let me confirm the details.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'sofia.hernandez@example.com'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'think', 'arguments': {'thought': 'Okay, I need to exchange the helmet and luggage set, and modify the grill. Let me confirm the details.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"olivia.lopez@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"charger_0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"sneaker_0000000\", \"item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'olivia.lopez@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': 'charger_0000000', 'reason': 'no longer needed'}}, {'name': 'return_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'return_delivered_order_items', 'arguments': {'order_id': 'sneaker_0000000', 'item_ids': ['1008292230'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:53,977 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,978 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,978 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,979 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,980 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:53,981 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,982 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:53 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:53,986 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,127 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:54,129 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,130 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,130 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,131 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,132 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:54,133 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,134 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,138 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Let's analyze the order details to determine if partial cancellation is possible.\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"300 + 200 + 150\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The total order amount is $650. I need to return the office items and keep the hiking items.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"modify_user_address\", \"arguments\": {\"user_id\": \"sara_doe_496\", \"address1\": \"456 Elm St\", \"address2\": \"\", \"city\": \"Seattle\", \"state\": \"WA\", \"country\": \"USA\", \"zip\": \"98101\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'think', 'arguments': {'thought': \"Let's analyze the order details to determine if partial cancellation is possible.\"}}, {'name': 'calculate', 'arguments': {'expression': '300 + 200 + 150'}}, {'name': 'think', 'arguments': {'thought': 'The total order amount is $650. I need to return the office items and keep the hiking items.'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}, {'name': 'modify_user_address', 'arguments': {'user_id': 'sara_doe_496', 'address1': '456 Elm St', 'address2': '', 'city': 'Seattle', 'state': 'WA', 'country': 'USA', 'zip': '98101'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "[\n",
      "    {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "    {\"name\": \"think\", \"arguments\": {\"thought\": \"Let's check the order details and the most expensive item.\"}},\n",
      "    {\"name\": \"calculate\", \"arguments\": {\"expression\": \"1160 - 1131\"}},\n",
      "    {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"1008292230\"}},\n",
      "    {\"name\": \"think\", \"arguments\": {\"thought\": \"If I can't split the payment, let's see if I can cancel the most expensive item.\"}},\n",
      "    {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'think', 'arguments': {'thought': \"Let's check the order details and the most expensive item.\"}}, {'name': 'calculate', 'arguments': {'expression': '1160 - 1131'}}, {'name': 'get_product_details', 'arguments': {'product_id': '1008292230'}}, {'name': 'think', 'arguments': {'thought': \"If I can't split the payment, let's see if I can cancel the most expensive item.\"}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:54,218 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:54,220 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,221 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,221 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,222 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,222 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:54,224 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,224 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,228 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,252 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:54,253 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,254 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,254 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,255 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,255 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:54,257 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,258 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,262 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "[\n",
      "    {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "    {\"name\": \"think\", \"arguments\": {\"thought\": \"Let's check the order details and the most expensive item.\"}},\n",
      "    {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"1008292230\"}},\n",
      "    {\"name\": \"calculate\", \"arguments\": {\"expression\": \"1160 - 1150\"}},\n",
      "    {\"name\": \"think\", \"arguments\": {\"thought\": \"The order is $10 over the limit. Let's see if we can cancel the most expensive item.\"}},\n",
      "    {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'think', 'arguments': {'thought': \"Let's check the order details and the most expensive item.\"}}, {'name': 'get_product_details', 'arguments': {'product_id': '1008292230'}}, {'name': 'calculate', 'arguments': {'expression': '1160 - 1150'}}, {'name': 'think', 'arguments': {'thought': \"The order is $10 over the limit. Let's see if we can cancel the most expensive item.\"}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_name_zip\", \"arguments\": {\"first_name\": \"Isabella\", \"last_name\": \"Johansson\", \"zip\": \"32286\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"To be determined\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The user wants to return items from a misdirected order and receive a refund to their Amex. Need to find the order and then initiate the return and refund process.\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"To be determined\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"To be determined\", \"reason\": \"ordered by mistake\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The order was cancelled. Now need to initiate the return of items except the pet bed and refund to Amex.\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"To be determined\", \"item_ids\": [\"To be determined\"], \"payment_method_id\": \"amex_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Return process initiated. Now need to confirm with the user that the return is correct.\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"User wants to return items from a misdirected order and receive a refund to their Amex.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_name_zip', 'arguments': {'first_name': 'Isabella', 'last_name': 'Johansson', 'zip': '32286'}}, {'name': 'get_order_details', 'arguments': {'order_id': 'To be determined'}}, {'name': 'think', 'arguments': {'thought': 'The user wants to return items from a misdirected order and receive a refund to their Amex. Need to find the order and then initiate the return and refund process.'}}, {'name': 'get_order_details', 'arguments': {'order_id': 'To be determined'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': 'To be determined', 'reason': 'ordered by mistake'}}, {'name': 'think', 'arguments': {'thought': 'The order was cancelled. Now need to initiate the return of items except the pet bed and refund to Amex.'}}, {'name': 'return_delivered_order_items', 'arguments': {'order_id': 'To be determined', 'item_ids': ['To be determined'], 'payment_method_id': 'amex_0000000'}}, {'name': 'think', 'arguments': {'thought': 'Return process initiated. Now need to confirm with the user that the return is correct.'}}, {'name': 'transfer_to_human_agents', 'arguments': {'summary': 'User wants to return items from a misdirected order and receive a refund to their Amex.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:54,424 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:54,426 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,427 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,427 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,427 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,428 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,430 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:54,431 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,434 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_name_zip\", \"arguments\": {\"first_name\": \"Ethan\", \"last_name\": \"Garcia\", \"zip\": \"80280\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"placeholder_user_id\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"placeholder_order_id\", \"item_ids\": [\"1656367028\"], \"new_item_ids\": [\"1421289881\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, let's exchange the shoes and change the item. I need to confirm the details.\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"placeholder_order_id\", \"item_ids\": [\"4107812777\"], \"new_item_ids\": [], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"placeholder_order_id\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I've cancelled the order. Now, let's check my gift card balance.\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"placeholder_user_id\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"gift_card_balance\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Done.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_name_zip', 'arguments': {'first_name': 'Ethan', 'last_name': 'Garcia', 'zip': '80280'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'placeholder_user_id'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': 'placeholder_order_id', 'item_ids': ['1656367028'], 'new_item_ids': ['1421289881'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'think', 'arguments': {'thought': \"Okay, let's exchange the shoes and change the item. I need to confirm the details.\"}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': 'placeholder_order_id', 'item_ids': ['4107812777'], 'new_item_ids': [], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': 'placeholder_order_id', 'reason': 'no longer needed'}}, {'name': 'think', 'arguments': {'thought': \"I've cancelled the order. Now, let's check my gift card balance.\"}}, {'name': 'get_user_details', 'arguments': {'user_id': 'placeholder_user_id'}}, {'name': 'calculate', 'arguments': {'expression': 'gift_card_balance'}}, {'name': 'think', 'arguments': {'thought': 'Done.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:54,987 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:54,988 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,989 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,990 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,991 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "Processing retail instructions:  17%|█▋        | 20/115 [00:09<00:36,  2.61it/s]2025-04-11 13:11:54,991 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,992 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:54,993 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:54,998 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"User wants to return the water bottle and exchange the pet bed and office chair. Need to determine the cheapest options and the potential savings.\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"water_bottle_0000000\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"pet_bed_0000000\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"office_chair_0000000\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"Cost of cheapest pet bed + Cost of cheapest office chair - Refund for water bottle\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"Cost of cheapest pet bed - Refund for water bottle\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"Cost of cheapest office chair - Refund for water bottle\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"water_bottle_0000000\"], \"new_item_ids\": [], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"pet_bed_0000000\"], \"new_item_ids\": [\"cheapest_pet_bed_0000000\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"office_chair_0000000\"], \"new_item_ids\": [\"cheapest_office_chair_0000000\"], \"payment_method_id\": \"gift_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'think', 'arguments': {'thought': 'User wants to return the water bottle and exchange the pet bed and office chair. Need to determine the cheapest options and the potential savings.'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'water_bottle_0000000'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'pet_bed_0000000'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'office_chair_0000000'}}, {'name': 'calculate', 'arguments': {'expression': 'Cost of cheapest pet bed + Cost of cheapest office chair - Refund for water bottle'}}, {'name': 'calculate', 'arguments': {'expression': 'Cost of cheapest pet bed - Refund for water bottle'}}, {'name': 'calculate', 'arguments': {'expression': 'Cost of cheapest office chair - Refund for water bottle'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['water_bottle_0000000'], 'new_item_ids': [], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['pet_bed_0000000'], 'new_item_ids': ['cheapest_pet_bed_0000000'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['office_chair_0000000'], 'new_item_ids': ['cheapest_office_chair_0000000'], 'payment_method_id': 'gift_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:55,238 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:55,239 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:55,240 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:55,241 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:55,241 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:55,242 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:55,243 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:55,245 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:55,249 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I just cancelled the grill. Ugh, I really don’t need it. I was trying to be a responsible adult, but now I feel silly. I should have just bought a portable grill.  I’m so impulsive sometimes.  I really regret this now.\"}},\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"sofia.hernandez@example.com\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"sofia_hernandez_496\"}},\n",
      "  {\"name\": \"list_all_product_types\", \"arguments\": {}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000001\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Wait, I ordered two t-shirts in that other order. I need to know what they're made of. I always get confused about the materials.\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000001\", \"item_ids\": [\"1007865432\", \"1007865433\"], \"new_item_ids\": [\"1007865432\", \"1007865433\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}, {'name': 'think', 'arguments': {'thought': 'Okay, I just cancelled the grill. Ugh, I really don’t need it. I was trying to be a responsible adult, but now I feel silly. I should have just bought a portable grill.  I’m so impulsive sometimes.  I really regret this now.'}}, {'name': 'find_user_id_by_email', 'arguments': {'email': 'sofia.hernandez@example.com'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'sofia_hernandez_496'}}, {'name': 'list_all_product_types', 'arguments': {}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000001'}}, {'name': 'think', 'arguments': {'thought': \"Wait, I ordered two t-shirts in that other order. I need to know what they're made of. I always get confused about the materials.\"}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000001', 'item_ids': ['1007865432', '1007865433'], 'new_item_ids': ['1007865432', '1007865433'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:55,636 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:55,637 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:55,638 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:55,638 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:55,639 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:55,640 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:55,641 - WARNING - Skipping invalid item in plan: {'name': 'list_all_product_types'}\n",
      "2025-04-11 13:11:55,641 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:55,643 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:55 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:55,643 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"isabella.johansson@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"skateboard_001\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"bamboo_skateboard_001\"}},\n",
      "  {\"name\": \"list_all_product_types\"},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"skateboard_001\"], \"new_item_ids\": [\"bamboo_skateboard_001\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"32286\", \"address2\": \"\", \"city\": \"32286\", \"state\": \"CA\", \"country\": \"USA\", \"zip\": \"32286\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I've exchanged the skateboard and updated my address. Now I need to return the hose.\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"garden_hose_001\"], \"payment_method_id\": \"gift_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'isabella.johansson@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'skateboard_001'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'bamboo_skateboard_001'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['skateboard_001'], 'new_item_ids': ['bamboo_skateboard_001'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '32286', 'address2': '', 'city': '32286', 'state': 'CA', 'country': 'USA', 'zip': '32286'}}, {'name': 'think', 'arguments': {'thought': \"Okay, I've exchanged the skateboard and updated my address. Now I need to return the hose.\"}}, {'name': 'return_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['garden_hose_001'], 'payment_method_id': 'gift_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:56,149 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:56,151 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,152 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,152 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,153 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:56,154 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,156 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:56,157 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,161 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,234 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:56,235 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,237 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,237 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,238 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:56,238 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,239 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:56,241 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,245 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,324 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:56,325 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,327 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,327 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,327 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,328 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:56,330 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,331 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "[\n",
      "    {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1000177888\"], \"new_item_ids\": [\"1000177889\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "    {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"123 Maple Drive\", \"address2\": \"\", \"city\": \"Fort Worth\", \"state\": \"TX\", \"country\": \"USA\", \"zip\": \"76165\"}},\n",
      "    {\"name\": \"modify_user_address\", \"arguments\": {\"user_id\": \"mei_patel_7272\", \"address1\": \"123 Maple Drive\", \"address2\": \"\", \"city\": \"Fort Worth\", \"state\": \"TX\", \"country\": \"USA\", \"zip\": \"76165\"}}\n",
      "]\n",
      "\n",
      "Parsed Plan: [{'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1000177888'], 'new_item_ids': ['1000177889'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '123 Maple Drive', 'address2': '', 'city': 'Fort Worth', 'state': 'TX', 'country': 'USA', 'zip': '76165'}}, {'name': 'modify_user_address', 'arguments': {'user_id': 'mei_patel_7272', 'address1': '123 Maple Drive', 'address2': '', 'city': 'Fort Worth', 'state': 'TX', 'country': 'USA', 'zip': '76165'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"daiki_johnson_9523@example.com\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'daiki_johnson_9523@example.com'}}, {'name': 'return_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,334 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,459 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:56,461 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,462 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,462 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,463 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:56,464 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,466 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:56,466 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,470 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,548 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:56,550 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,551 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,551 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,552 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,552 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:56,554 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,555 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,559 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,668 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Let's check the order details and see where it was shipped. Then I'll check the tablet's inventory.\"}},\n",
      "  {\"name\": \"modify_user_address\", \"arguments\": {\"user_id\": \"lucas_santos_6600\", \"address1\": \"1234 Oak Street\", \"address2\": \"\", \"city\": \"Chicago\", \"state\": \"IL\", \"country\": \"USA\", \"zip\": \"60611\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'think', 'arguments': {'thought': \"Let's check the order details and see where it was shipped. Then I'll check the tablet's inventory.\"}}, {'name': 'modify_user_address', 'arguments': {'user_id': 'lucas_santos_6600', 'address1': '1234 Oak Street', 'address2': '', 'city': 'Chicago', 'state': 'IL', 'country': 'USA', 'zip': '60611'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"aarav_santos_2259\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"aarav_santos_2259\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"17-inch laptop\"], \"new_item_ids\": [\"13-inch laptop\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, let's find the best 13-inch options. I want i5, silver or black.\"}},\n",
      "  {\"name\": \"list_all_product_types\", \"arguments\": {}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"13-inch laptop i5 silver\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"13-inch laptop i5 black\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"123 Main St\", \"address2\": \"Apt 1\", \"city\": \"San Francisco\", \"state\": \"CA\", \"country\": \"USA\", \"zip\": \"94105\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'aarav_santos_2259'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'aarav_santos_2259'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['17-inch laptop'], 'new_item_ids': ['13-inch laptop'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'think', 'arguments': {'thought': \"Okay, let's find the best 13-inch options. I want i5, silver or black.\"}}, {'name': 'list_all_product_types', 'arguments': {}}, {'name': 'get_product_details', 'arguments': {'product_id': '13-inch laptop i5 silver'}}, {'name': 'get_product_details', 'arguments': {'product_id': '13-inch laptop i5 black'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '123 Main St', 'address2': 'Apt 1', 'city': 'San Francisco', 'state': 'CA', 'country': 'USA', 'zip': '94105'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:56,670 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,671 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,671 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,672 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,672 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:56,674 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,674 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,679 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,741 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:56,743 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,744 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,744 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,745 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,745 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:56,747 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,747 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,751 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"olivia.lopez@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000002\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000003\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000004\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I need to cancel the charger, boot, kettle, and sneaker. Let's do that one by one.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000005\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000006\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000007\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000008\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'olivia.lopez@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000001', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000002', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000003', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000004', 'reason': 'no longer needed'}}, {'name': 'think', 'arguments': {'thought': \"Okay, I need to cancel the charger, boot, kettle, and sneaker. Let's do that one by one.\"}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000005', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000006', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000007', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000008', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_name_zip\", \"arguments\": {\"first_name\": \"Fatima\", \"last_name\": \"Taylor\", \"zip\": \"32169\"}},\n",
      "  {\"name\": \"modify_user_address\", \"arguments\": {\"user_id\": \"fatima_taylor_3452\", \"address1\": \"1234 Cactus Lane\", \"address2\": \"\", \"city\": \"Phoenix\", \"state\": \"AZ\", \"country\": \"USA\", \"zip\": \"85033\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"tshirt_001\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"W00000001\", \"item_ids\": [\"tshirt_001\"], \"new_item_ids\": [\"tshirt_001\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, new address, new city, new state, new zip... I feel like a chameleon!  Hope this t-shirt order goes smoothly.  Why did the t-shirt go to therapy? Because it felt so exposed!\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_name_zip', 'arguments': {'first_name': 'Fatima', 'last_name': 'Taylor', 'zip': '32169'}}, {'name': 'modify_user_address', 'arguments': {'user_id': 'fatima_taylor_3452', 'address1': '1234 Cactus Lane', 'address2': '', 'city': 'Phoenix', 'state': 'AZ', 'country': 'USA', 'zip': '85033'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'tshirt_001'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': 'W00000001', 'item_ids': ['tshirt_001'], 'new_item_ids': ['tshirt_001'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'think', 'arguments': {'thought': 'Okay, new address, new city, new state, new zip... I feel like a chameleon!  Hope this t-shirt order goes smoothly.  Why did the t-shirt go to therapy? Because it felt so exposed!'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:56,888 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:56,889 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,890 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,891 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,891 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,892 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:56,894 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,894 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,898 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,924 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:56,926 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,928 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,928 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,929 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:56,929 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,931 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,931 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:56 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:56,936 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,014 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:57,016 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,016 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,017 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,018 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:57,018 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,020 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:57,020 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,024 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"isabella.lopez3271@example.com\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"isabella.lopez3271@example.com\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"gift_card_balance\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"payment_method\"}},\n",
      "  {\"name\": \"modify_pending_order_payment\", \"arguments\": {\"order_id\": \"W0000000\", \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_payment\", \"arguments\": {\"order_id\": \"W0000000\", \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, let's make sure the payment method is set to Visa and the gift card balance is applied. I'm feeling a bit stressed about these exams and loans, so let's get this done quickly.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'isabella.lopez3271@example.com'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'isabella.lopez3271@example.com'}}, {'name': 'calculate', 'arguments': {'expression': 'gift_card_balance'}}, {'name': 'calculate', 'arguments': {'expression': 'payment_method'}}, {'name': 'modify_pending_order_payment', 'arguments': {'order_id': 'W0000000', 'payment_method_id': 'visa_0000000'}}, {'name': 'modify_pending_order_payment', 'arguments': {'order_id': 'W0000000', 'payment_method_id': 'gift_card_0000000'}}, {'name': 'think', 'arguments': {'thought': \"Okay, let's make sure the payment method is set to Visa and the gift card balance is applied. I'm feeling a bit stressed about these exams and loans, so let's get this done quickly.\"}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"9502126\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The user wants to return an air purifier and a vacuum cleaner from order 9502126. They are impatient and want a quick refund.\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"9502126\", \"item_ids\": [\"air_purifier_123\", \"robotic_vacuum_456\"], \"payment_method_id\": \"gift_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '9502126'}}, {'name': 'think', 'arguments': {'thought': 'The user wants to return an air purifier and a vacuum cleaner from order 9502126. They are impatient and want a quick refund.'}}, {'name': 'return_delivered_order_items', 'arguments': {'order_id': '9502126', 'item_ids': ['air_purifier_123', 'robotic_vacuum_456'], 'payment_method_id': 'gift_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"9502126\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The user wants to return an air purifier and a vacuum cleaner from order 9502126. They are impatient and want a quick refund.\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"9502126\", \"item_ids\": [\"air_purifier_123\", \"canister_vacuum_456\"], \"payment_method_id\": \"gift_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '9502126'}}, {'name': 'think', 'arguments': {'thought': 'The user wants to return an air purifier and a vacuum cleaner from order 9502126. They are impatient and want a quick refund.'}}, {'name': 'return_delivered_order_items', 'arguments': {'order_id': '9502126', 'item_ids': ['air_purifier_123', 'canister_vacuum_456'], 'payment_method_id': 'gift_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:57,135 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:57,136 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,137 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,137 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,138 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,138 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:57,140 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,140 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,145 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,187 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:57,189 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,190 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,190 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,191 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,192 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,193 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:57,194 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,198 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W8855135\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W8855135\", \"item_ids\": [\"1007865432\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W8855135'}}, {'name': 'return_delivered_order_items', 'arguments': {'order_id': '#W8855135', 'item_ids': ['1007865432'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"6086499569\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'get_product_details', 'arguments': {'product_id': '6086499569'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:57,467 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:57,469 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,470 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,470 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,471 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,472 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:57,473 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,474 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,478 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,484 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:57,485 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,486 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,486 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,487 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,488 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:57,490 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,490 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,496 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "[\n",
      "    {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "    {\"name\": \"think\", \"arguments\": {\"thought\": \"Let's first get the order details to understand the situation.\"}},\n",
      "    {\"name\": \"calculate\", \"arguments\": {\"expression\": \"1100 - 950\"}},\n",
      "    {\"name\": \"think\", \"arguments\": {\"thought\": \"The order is $150 over budget. Let's find the most expensive item.\"}},\n",
      "    {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"most expensive item id\"}},\n",
      "    {\"name\": \"think\", \"arguments\": {\"thought\": \"Now let's see if we can replace the most expensive item with a cheaper one.\"}},\n",
      "    {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"most expensive item id\"], \"new_item_ids\": [\"cheaper item id\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "    {\"name\": \"think\", \"arguments\": {\"thought\": \"Let's check if the new total is within budget.\"}},\n",
      "    {\"name\": \"calculate\", \"arguments\": {\"expression\": \"new order total - 950\"}},\n",
      "    {\"name\": \"think\", \"arguments\": {\"thought\": \"If it's still over budget, I'll cancel the order.\"}},\n",
      "    {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'think', 'arguments': {'thought': \"Let's first get the order details to understand the situation.\"}}, {'name': 'calculate', 'arguments': {'expression': '1100 - 950'}}, {'name': 'think', 'arguments': {'thought': \"The order is $150 over budget. Let's find the most expensive item.\"}}, {'name': 'get_product_details', 'arguments': {'product_id': 'most expensive item id'}}, {'name': 'think', 'arguments': {'thought': \"Now let's see if we can replace the most expensive item with a cheaper one.\"}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['most expensive item id'], 'new_item_ids': ['cheaper item id'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'think', 'arguments': {'thought': \"Let's check if the new total is within budget.\"}}, {'name': 'calculate', 'arguments': {'expression': 'new order total - 950'}}, {'name': 'think', 'arguments': {'thought': \"If it's still over budget, I'll cancel the order.\"}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"9502127\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I need to exchange the robotic vacuum for a canister one. Let's see the order details.\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"9502127\", \"item_ids\": [\"6086499569\"], \"new_item_ids\": [\"6086500123\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I hope I got the right item ID for the canister vacuum.  Can I get a gift card for the difference?\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '9502127'}}, {'name': 'think', 'arguments': {'thought': \"Okay, I need to exchange the robotic vacuum for a canister one. Let's see the order details.\"}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '9502127', 'item_ids': ['6086499569'], 'new_item_ids': ['6086500123'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'think', 'arguments': {'thought': 'I hope I got the right item ID for the canister vacuum.  Can I get a gift card for the difference?'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:57,757 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:57,759 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,760 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,760 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,761 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:57,762 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,764 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:57,765 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:57 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:57,769 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W9300146\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"6086499569\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W9300146\", \"item_ids\": [\"6086499569\"], \"new_item_ids\": [], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"((get_product_details.price - get_order_details.price) * 100) / 1000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I need to confirm the price difference and the gift card amount. Let me calculate that.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W9300146'}}, {'name': 'get_product_details', 'arguments': {'product_id': '6086499569'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W9300146', 'item_ids': ['6086499569'], 'new_item_ids': [], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'calculate', 'arguments': {'expression': '((get_product_details.price - get_order_details.price) * 100) / 1000'}}, {'name': 'think', 'arguments': {'thought': 'Okay, I need to confirm the price difference and the gift card amount. Let me calculate that.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:58,026 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:58,028 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,028 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,029 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,030 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,031 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:58,032 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,034 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,037 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"olivia.lopez@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I need to check the order details and then figure out how to handle the damaged tablet.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Now I need to see if I can exchange the tablet. Let me check the inventory.\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"tablet_123\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, let's see if we can exchange the tablet. I'll need to confirm with the user.\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"tablet_123\"], \"new_item_ids\": [\"tablet_123\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Confirm exchange with user.\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"Austin\", \"state\": \"TX\", \"country\": \"USA\", \"zip\": \"76171\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, now let's cancel the charger.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"And finally, return the sneaker.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000002\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'olivia.lopez@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'think', 'arguments': {'thought': 'Okay, I need to check the order details and then figure out how to handle the damaged tablet.'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}, {'name': 'think', 'arguments': {'thought': 'Now I need to see if I can exchange the tablet. Let me check the inventory.'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'tablet_123'}}, {'name': 'think', 'arguments': {'thought': \"Okay, let's see if we can exchange the tablet. I'll need to confirm with the user.\"}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['tablet_123'], 'new_item_ids': ['tablet_123'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'think', 'arguments': {'thought': 'Confirm exchange with user.'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '123 Main St', 'address2': '', 'city': 'Austin', 'state': 'TX', 'country': 'USA', 'zip': '76171'}}, {'name': 'think', 'arguments': {'thought': \"Okay, now let's cancel the charger.\"}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000001', 'reason': 'no longer needed'}}, {'name': 'think', 'arguments': {'thought': 'And finally, return the sneaker.'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000002', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:58,274 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:58,276 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,277 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,277 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,278 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,279 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:58,280 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,281 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,285 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Let's check the order status and details.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'think', 'arguments': {'thought': \"Let's check the order status and details.\"}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:58,490 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:58,491 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,493 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,493 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,494 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,494 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:58,496 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,497 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,502 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W4284542\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Checking the order status and details for order #W4284542.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W4284542\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W4284542'}}, {'name': 'think', 'arguments': {'thought': 'Checking the order status and details for order #W4284542.'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W4284542', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:58,918 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:58,920 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,921 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,921 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,922 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,922 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,924 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:58,925 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:58 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:58,930 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,107 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "[\n",
      "    {\"name\": \"find_user_id_by_name_zip\", \"arguments\": {\"first_name\": \"Noah\", \"last_name\": \"Ito\", \"zip\": \"98187\"}}\n",
      "]\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_name_zip', 'arguments': {'first_name': 'Noah', 'last_name': 'Ito', 'zip': '98187'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:59,109 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,110 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,110 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,111 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,112 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,114 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:59,115 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,118 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W5061109\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W5061109\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230_blue\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W5061109'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W5061109', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230_blue'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:59,438 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:59,440 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,441 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,441 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,442 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,442 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:59,445 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,445 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,450 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,539 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:59,541 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,542 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,542 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,543 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,544 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:59,546 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,547 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,553 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Need to confirm order details and item IDs before modifying.\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"coffee_machine_1008292230\", \"laptop_1008292231\"], \"new_item_ids\": [], \"payment_method_id\": \"gift_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'think', 'arguments': {'thought': 'Need to confirm order details and item IDs before modifying.'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['coffee_machine_1008292230', 'laptop_1008292231'], 'new_item_ids': [], 'payment_method_id': 'gift_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_name_zip\", \"arguments\": {\"first_name\": \"Sofia\", \"last_name\": \"Li\", \"zip\": \"78260\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"damaged during delivery\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"item_id_1\", \"item_id_2\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_name_zip', 'arguments': {'first_name': 'Sofia', 'last_name': 'Li', 'zip': '78260'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'damaged during delivery'}}, {'name': 'return_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['item_id_1', 'item_id_2'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:11:59,643 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:59,645 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,646 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,646 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,647 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,648 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:59,650 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,651 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,656 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,746 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:11:59,748 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,749 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,749 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,750 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,750 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,752 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:11:59,753 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:11:59 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:11:59,757 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "[\n",
      "    {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"noah_ito_3850\"}},\n",
      "    {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to find the most recent order to check the payment details.\"}},\n",
      "    {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"most recent order id\"}},\n",
      "    {\"name\": \"calculate\", \"arguments\": {\"expression\": \"order total\"}}\n",
      "]\n",
      "\n",
      "Parsed Plan: [{'name': 'get_user_details', 'arguments': {'user_id': 'noah_ito_3850'}}, {'name': 'think', 'arguments': {'thought': 'I need to find the most recent order to check the payment details.'}}, {'name': 'get_order_details', 'arguments': {'order_id': 'most recent order id'}}, {'name': 'calculate', 'arguments': {'expression': 'order total'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"sara_doe_496\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"sara_doe_496\"}},\n",
      "  {\"name\": \"list_all_product_types\", \"arguments\": {}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"best_zoom_camera_id\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"W0000000\", \"item_ids\": [\"best_zoom_camera_id\"], \"new_item_ids\": [\"max_zoom_camera_id\"], \"payment_method_id\": \"paypal_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'sara_doe_496'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'sara_doe_496'}}, {'name': 'list_all_product_types', 'arguments': {}}, {'name': 'get_product_details', 'arguments': {'product_id': 'best_zoom_camera_id'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': 'W0000000', 'item_ids': ['best_zoom_camera_id'], 'new_item_ids': ['max_zoom_camera_id'], 'payment_method_id': 'paypal_0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': 'W0000000', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:00,094 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:00,096 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,097 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,097 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,098 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,098 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:00,100 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,101 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,104 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_id_by_name_zip\", \"arguments\": {\"first_name\": \"James\", \"last_name\": \"Sanchez\", \"zip\": \"60623\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"WP-CAM-001\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"WP-CAM-001\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_user_id_by_name_zip', 'arguments': {'first_name': 'James', 'last_name': 'Sanchez', 'zip': '60623'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'WP-CAM-001'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['WP-CAM-001'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:00,931 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:00,933 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,934 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,934 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,935 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,935 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:00,937 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,938 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,942 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,948 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:00,949 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,950 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,950 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,951 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,951 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,953 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:00,954 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:00 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:00,959 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"chen.johnson@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W5061109\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W5061109\", \"item_ids\": [\"6086499569\"], \"new_item_ids\": [\"6086499571\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W5061109\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"Houston\", \"state\": \"TX\", \"country\": \"USA\", \"zip\": \"77004\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'chen.johnson@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W5061109'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W5061109', 'item_ids': ['6086499569'], 'new_item_ids': ['6086499571'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W5061109', 'address1': '123 Main St', 'address2': '', 'city': 'Houston', 'state': 'TX', 'country': 'USA', 'zip': '77004'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [1008292230], \"new_item_ids\": [6086499569], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"1234 Cactus Ave\", \"address2\": \"\", \"city\": \"Phoenix\", \"state\": \"AZ\", \"country\": \"USA\", \"zip\": \"85025\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': [1008292230], 'new_item_ids': [6086499569], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '1234 Cactus Ave', 'address2': '', 'city': 'Phoenix', 'state': 'AZ', 'country': 'USA', 'zip': '85025'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:01,222 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:01,223 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,224 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,225 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,226 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,226 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:01,228 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,229 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,232 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,275 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:01,277 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,278 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,278 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,279 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,280 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,281 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:01,282 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,286 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,292 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:01,293 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,294 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,294 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,295 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,296 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:01,297 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,298 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,303 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"mei_patel_7272\"}},\n",
      "  {\"name\": \"modify_user_address\", \"arguments\": {\"user_id\": \"mei_patel_7272\", \"address1\": \"445 Maple Drive\", \"address2\": \"\", \"city\": \"Fort Worth\", \"state\": \"TX\", \"country\": \"USA\", \"zip\": \"76165\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"445 Maple Drive\", \"address2\": \"\", \"city\": \"Fort Worth\", \"state\": \"TX\", \"country\": \"USA\", \"zip\": \"76165\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"list_all_product_types\", \"arguments\": {}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"paypal_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, let's make sure the jigsaw is easy for my kid.\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"jigsaw_0001\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"paypal_0000000\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_user_details', 'arguments': {'user_id': 'mei_patel_7272'}}, {'name': 'modify_user_address', 'arguments': {'user_id': 'mei_patel_7272', 'address1': '445 Maple Drive', 'address2': '', 'city': 'Fort Worth', 'state': 'TX', 'country': 'USA', 'zip': '76165'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '445 Maple Drive', 'address2': '', 'city': 'Fort Worth', 'state': 'TX', 'country': 'USA', 'zip': '76165'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'list_all_product_types', 'arguments': {}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'paypal_0000000'}}, {'name': 'think', 'arguments': {'thought': \"Okay, let's make sure the jigsaw is easy for my kid.\"}}, {'name': 'get_product_details', 'arguments': {'product_id': 'jigsaw_0001'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'paypal_0000000'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "[\n",
      "    {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "    {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"bookshelf_0000000\"}},\n",
      "    {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"camera_0000000\"}},\n",
      "    {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"bookshelf_0000000\"], \"new_item_ids\": [\"camera_0000000\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "    {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"ordered by mistake\"}}\n",
      "]\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'bookshelf_0000000'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'camera_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['bookshelf_0000000'], 'new_item_ids': ['camera_0000000'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'ordered by mistake'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_zip\", \"arguments\": {\"zip\": \"85033\"}},\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"Lei Li\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"pending_order_123\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_zip', 'arguments': {'zip': '85033'}}, {'name': 'find_user_id_by_email', 'arguments': {'email': 'Lei Li'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': 'pending_order_123', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:01,447 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:01,450 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,451 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,451 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,451 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,452 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:01,453 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,454 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,457 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_name_zip\", \"arguments\": {\"first_name\": \"emma\", \"last_name\": \"smith\", \"zip\": \"10192\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"emmasmith_8564\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_name_zip', 'arguments': {'first_name': 'emma', 'last_name': 'smith', 'zip': '10192'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'emmasmith_8564'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'return_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:01,829 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:01,830 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,831 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,831 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,833 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,833 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:01,834 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,835 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:01 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:01,839 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W2702727\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W8268610\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W2702727\", \"address1\": \"1234 Elm St\", \"address2\": \"Apt 1\", \"city\": \"Springfield\", \"state\": \"IL\", \"country\": \"USA\", \"zip\": \"62701\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W2702727\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"total_price_after_address_change - original_total_price\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W8268610\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"refund_amount\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Confirm the refund amount and cancellation details.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W2702727'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W8268610'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W2702727', 'address1': '1234 Elm St', 'address2': 'Apt 1', 'city': 'Springfield', 'state': 'IL', 'country': 'USA', 'zip': '62701'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W2702727'}}, {'name': 'calculate', 'arguments': {'expression': 'total_price_after_address_change - original_total_price'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W8268610', 'reason': 'no longer needed'}}, {'name': 'calculate', 'arguments': {'expression': 'refund_amount'}}, {'name': 'think', 'arguments': {'thought': 'Confirm the refund amount and cancellation details.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:02,291 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:02 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:02,293 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:02,294 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:02,294 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:02,295 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:02,296 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:02 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:02,297 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:02,298 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:02 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:02,302 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W6908222\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Let's review the order details and confirm the exchange request.\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W6908222\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W6908222'}}, {'name': 'think', 'arguments': {'thought': \"Let's review the order details and confirm the exchange request.\"}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W6908222', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292231'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:03,163 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:03,165 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,166 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,166 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,167 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,167 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:03,169 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,169 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,173 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,197 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:03,199 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,199 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,200 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,200 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,201 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:03,203 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,203 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,208 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,233 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:03,235 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,236 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,236 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,237 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,237 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,239 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:03,239 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,243 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The user wants to cancel part of their order. Let's check the order details.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'think', 'arguments': {'thought': \"The user wants to cancel part of their order. Let's check the order details.\"}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_name_zip\", \"arguments\": {\"first_name\": \"Emma\", \"last_name\": \"Kovacs\", \"zip\": \"32190\"}},\n",
      "  {\"name\": \"modify_user_address\", \"arguments\": {\"user_id\": \"emma_kovacs_123\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"Orlando\", \"state\": \"FL\", \"country\": \"USA\", \"zip\": \"32190\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_name_zip', 'arguments': {'first_name': 'Emma', 'last_name': 'Kovacs', 'zip': '32190'}}, {'name': 'modify_user_address', 'arguments': {'user_id': 'emma_kovacs_123', 'address1': '123 Main St', 'address2': '', 'city': 'Orlando', 'state': 'FL', 'country': 'USA', 'zip': '32190'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"SPK-BLT-001\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"200 - 300\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The speaker is too expensive. I should cancel it.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"list_all_product_types\", \"arguments\": {}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"SPK-BLT-002\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"SPK-BLT-002 - 300\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The second speaker is cheaper. I should add it to my order.\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W00000001\", \"item_ids\": [\"SPK-BLT-002\"], \"new_item_ids\": [\"SPK-BLT-002\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W00000001\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_product_details', 'arguments': {'product_id': 'SPK-BLT-001'}}, {'name': 'calculate', 'arguments': {'expression': '200 - 300'}}, {'name': 'think', 'arguments': {'thought': 'The speaker is too expensive. I should cancel it.'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W00000001', 'reason': 'no longer needed'}}, {'name': 'list_all_product_types', 'arguments': {}}, {'name': 'get_product_details', 'arguments': {'product_id': 'SPK-BLT-002'}}, {'name': 'calculate', 'arguments': {'expression': 'SPK-BLT-002 - 300'}}, {'name': 'think', 'arguments': {'thought': 'The second speaker is cheaper. I should add it to my order.'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W00000001', 'item_ids': ['SPK-BLT-002'], 'new_item_ids': ['SPK-BLT-002'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W00000001'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:03,454 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:03,456 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,457 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,457 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,458 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,458 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:03,459 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,460 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,464 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,489 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:03,490 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,491 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,491 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,492 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,493 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,494 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:03,495 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,500 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_payment\", \"arguments\": {\"order_id\": \"#W0000000\", \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'user@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': [], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_payment', 'arguments': {'order_id': '#W0000000', 'payment_method_id': 'gift_card_0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"ivan_khan_123\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"6086499569\"], \"new_item_ids\": [\"6086499569\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"1234 Oak Street\", \"address2\": \"\", \"city\": \"Charlotte\", \"state\": \"NC\", \"country\": \"USA\", \"zip\": \"28243\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I've modified the address and the backpack. Let's confirm everything is correct.\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_user_details', 'arguments': {'user_id': 'ivan_khan_123'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['6086499569'], 'new_item_ids': ['6086499569'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '1234 Oak Street', 'address2': '', 'city': 'Charlotte', 'state': 'NC', 'country': 'USA', 'zip': '28243'}}, {'name': 'think', 'arguments': {'thought': \"Okay, I've modified the address and the backpack. Let's confirm everything is correct.\"}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:03,857 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:03,858 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,859 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,859 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,861 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,861 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:03,863 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,864 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,869 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,945 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:03,946 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,947 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,947 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,948 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,949 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,950 - ERROR - Error parsing JSON plan: Expecting ',' delimiter: line 11 column 253 (char 2088)\n",
      "2025-04-11 13:12:03,952 - ERROR - Raw response: ```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"ethan.garcia@example.com\"}},\n",
      "  {\"name\": \"list_all_product_types\", \"arguments\": {}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230_premium\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium\"], \"new_item_ids\": [\"1008292230_premium_size10\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10\"], \"new_item_ids\": [\"1008292230_premium_size10_highest\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited_final\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited_final\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited_final_last\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited_final_last\n",
      "\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:03,951 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,953 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "Processing retail instructions:  18%|█▊        | 21/115 [00:18<01:41,  1.08s/it]\u001b[92m13:12:03 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:03,954 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"SPK-BLT-001\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"200 - 300\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The speaker is too expensive. I should cancel it.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"list_all_product_types\", \"arguments\": {}},\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"chen.johnson@example.com\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"SPK-BLT-002\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"100 - 90\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W00000001\", \"item_ids\": [\"SPK-BLT-002\"], \"new_item_ids\": [\"SPK-BLT-002\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W00000001\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"100 / 2\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Let's confirm the total price.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_product_details', 'arguments': {'product_id': 'SPK-BLT-001'}}, {'name': 'calculate', 'arguments': {'expression': '200 - 300'}}, {'name': 'think', 'arguments': {'thought': 'The speaker is too expensive. I should cancel it.'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W00000001', 'reason': 'no longer needed'}}, {'name': 'list_all_product_types', 'arguments': {}}, {'name': 'find_user_id_by_email', 'arguments': {'email': 'chen.johnson@example.com'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'SPK-BLT-002'}}, {'name': 'calculate', 'arguments': {'expression': '100 - 90'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W00000001', 'item_ids': ['SPK-BLT-002'], 'new_item_ids': ['SPK-BLT-002'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W00000001'}}, {'name': 'calculate', 'arguments': {'expression': '100 / 2'}}, {'name': 'think', 'arguments': {'thought': \"Let's confirm the total price.\"}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"ethan.garcia@example.com\"}},\n",
      "  {\"name\": \"list_all_product_types\", \"arguments\": {}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230_premium\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium\"], \"new_item_ids\": [\"1008292230_premium_size10\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10\"], \"new_item_ids\": [\"1008292230_premium_size10_highest\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited_final\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited_final\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited_final_last\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited_final_last\n",
      "\n",
      "Parsed Plan: [{'error': \"JSONDecodeError: Expecting ',' delimiter: line 11 column 253 (char 2088)\", 'raw_response': '```json\\n[\\n  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"ethan.garcia@example.com\"}},\\n  {\"name\": \"list_all_product_types\", \"arguments\": {}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230_premium\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium\"], \"new_item_ids\": [\"1008292230_premium_size10\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10\"], \"new_item_ids\": [\"1008292230_premium_size10_highest\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited_final\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited_final\"], \"new_item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited_final_last\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#L0000000001\", \"item_ids\": [\"1008292230_premium_size10_highest_ultimate_deluxe_limited_final_last'}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:04,096 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:04,098 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,099 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,099 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,100 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:04,101 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,102 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,103 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,109 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,115 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:04,116 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,117 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,117 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,119 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,119 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,120 - WARNING - Skipping invalid item in plan: {'name': 'list_all_product_types'}\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:04,121 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,122 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:04,123 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,192 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:04,194 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,195 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,196 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,196 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:04,197 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,200 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:04,200 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,204 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"user123\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"modify_pending_order_payment\", \"arguments\": {\"order_id\": \"#W0000000\", \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'user@example.com'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'user123'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}, {'name': 'modify_pending_order_payment', 'arguments': {'order_id': '#W0000000', 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"silva7872@example.com\"}},\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"amelia.silva7872@example.com\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"sara_doe_496\"}},\n",
      "  {\"name\": \"list_all_product_types\"},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000002\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000003\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000004\", \"item_ids\": [\"1008292231\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"1000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"How much money can I get back?\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'silva7872@example.com'}}, {'name': 'find_user_id_by_email', 'arguments': {'email': 'amelia.silva7872@example.com'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'sara_doe_496'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000001', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000002', 'reason': 'no longer needed'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000003', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000004', 'item_ids': ['1008292231'], 'new_item_ids': ['1008292231'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'calculate', 'arguments': {'expression': '1000'}}, {'name': 'think', 'arguments': {'thought': 'How much money can I get back?'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_name_zip\", \"arguments\": {\"first_name\": \"Sofia\", \"last_name\": \"Hernandez\", \"zip\": \"98193\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"[user_id from find_user_id_by_name_zip]\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"[order_id from get_user_details]\", \"item_ids\": [\"[item_ids from get_user_details]\", \"[item_ids from get_user_details]\"], \"new_item_ids\": [\"[medium blue with high ventilation from list_all_product_types]\", \"[medium blue with high ventilation from list_all_product_types]\"], \"payment_method_id\": \"original_payment\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"[price difference between new and old item ids]\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, let's confirm the price difference and make sure the new item is available in blue.\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"[item_id from exchange_delivered_order_items]\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"[new_item_id from exchange_delivered_order_items]\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_name_zip', 'arguments': {'first_name': 'Sofia', 'last_name': 'Hernandez', 'zip': '98193'}}, {'name': 'get_user_details', 'arguments': {'user_id': '[user_id from find_user_id_by_name_zip]'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '[order_id from get_user_details]', 'item_ids': ['[item_ids from get_user_details]', '[item_ids from get_user_details]'], 'new_item_ids': ['[medium blue with high ventilation from list_all_product_types]', '[medium blue with high ventilation from list_all_product_types]'], 'payment_method_id': 'original_payment'}}, {'name': 'calculate', 'arguments': {'expression': '[price difference between new and old item ids]'}}, {'name': 'think', 'arguments': {'thought': \"Okay, let's confirm the price difference and make sure the new item is available in blue.\"}}, {'name': 'get_product_details', 'arguments': {'product_id': '[item_id from exchange_delivered_order_items]'}}, {'name': 'get_product_details', 'arguments': {'product_id': '[new_item_id from exchange_delivered_order_items]'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:04,345 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:04,347 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,348 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,348 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,349 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,350 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,351 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:04,352 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,358 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,362 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:04,363 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,365 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,365 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,366 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,366 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:04,368 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,369 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,374 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"ivan_khan_496\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"6086499569\"], \"new_item_ids\": [\"6086499569\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"1234 Oak Street\", \"address2\": \"\", \"city\": \"Charlotte\", \"state\": \"NC\", \"country\": \"USA\", \"zip\": \"28243\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I've modified the address and the items. Let's confirm everything is correct.\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_user_details', 'arguments': {'user_id': 'ivan_khan_496'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['6086499569'], 'new_item_ids': ['6086499569'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '1234 Oak Street', 'address2': '', 'city': 'Charlotte', 'state': 'NC', 'country': 'USA', 'zip': '28243'}}, {'name': 'think', 'arguments': {'thought': \"Okay, I've modified the address and the items. Let's confirm everything is correct.\"}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"user_id_from_email\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"perfume_id\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"perfume_item_id\"], \"new_item_ids\": [\"largest_size_perfume_item_id\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The user wants the largest size of the perfume.  I need to confirm the exchange and ensure the largest size is available.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'user@example.com'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'user_id_from_email'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'perfume_id'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['perfume_item_id'], 'new_item_ids': ['largest_size_perfume_item_id'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'think', 'arguments': {'thought': 'The user wants the largest size of the perfume.  I need to confirm the exchange and ensure the largest size is available.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:04,598 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:04,600 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,601 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,601 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,602 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,604 - WARNING - No JSON array found in the response.\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:04,603 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "Processing retail instructions:  20%|██        | 23/115 [00:18<01:26,  1.07it/s]2025-04-11 13:12:04,605 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,606 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,611 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"ethan_garcia_80280\"}},\n",
      "  {\"name\": \"modify_user_address\", \"arguments\": {\"user_id\": \"ethan_garcia_80280\", \"address1\": \"101 Highway\", \"address2\": \"\", \"city\": \"New York\", \"state\": \"NY\", \"country\": \"USA\", \"zip\": \"10001\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W00000001\", \"address1\": \"101 Highway\", \"address2\": \"\", \"city\": \"New York\", \"state\": \"NY\", \"country\": \"USA\", \"zip\": \"10001\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W00000002\", \"address1\": \"101 Highway\", \"address2\": \"\", \"city\": \"New York\", \"state\": \"NY\", \"country\": \"USA\", \"zip\": \"10001\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W00000003\", \"address1\": \"101 Highway\", \"address2\": \"\", \"city\": \"New York\", \"state\": \"NY\", \"country\": \"USA\", \"zip\": \"10001\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W00000004\", \"address1\": \"101 Highway\", \"address2\": \"\", \"city\": \"New York\", \"state\": \"NY\", \"country\": \"USA\", \"zip\": \"10001\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W00000005\", \"address1\": \"101 Highway\", \"address2\": \"\", \"city\": \"New York\", \"state\": \"NY\", \"country\": \"USA\", \"zip\": \"10001\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, address change complete. Now to revert.\"}},\n",
      "  {\"name\": \"modify_user_address\", \"arguments\": {\"user_id\": \"ethan_garcia_80280\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"Denver\", \"state\": \"CO\", \"country\": \"USA\", \"zip\": \"80280\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W00000001\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"Denver\", \"state\": \"CO\", \"country\": \"USA\", \"zip\": \"80280\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W00000002\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"Denver\", \"state\": \"CO\", \"country\": \"USA\", \"zip\": \"80280\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W00000003\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"Denver\", \"state\": \"CO\", \"country\": \"USA\", \"zip\": \"80280\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W00000004\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"Denver\", \"state\": \"CO\", \"country\": \"USA\", \"zip\": \"80280\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W00000005\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"Denver\", \"state\": \"CO\", \"country\": \"USA\", \"zip\": \"80280\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Reversion complete. All is as it should\n",
      "\n",
      "Parsed Plan: []\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:04,915 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:04,917 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,918 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,919 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,920 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:04,920 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,922 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,923 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:04 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:04,929 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"user123\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'user@example.com'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'user123'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:05,362 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:05,363 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,364 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,364 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,365 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,365 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,367 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:05,368 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,372 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,481 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:05,483 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,484 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,484 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,485 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,485 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,487 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:05,488 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,493 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,549 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:05,551 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,552 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"yusuf.hernandez8836@example.com\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"Fleece Jacket\"], \"new_item_ids\": [\"Fleece Jacket - Red - Half Zipper\"], \"payment_method_id\": \"gift_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'yusuf.hernandez8836@example.com'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['Fleece Jacket'], 'new_item_ids': ['Fleece Jacket - Red - Half Zipper'], 'payment_method_id': 'gift_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230-maple-34-graphic\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"total_price\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Let's check if the maple skateboard is available.\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"1008292230-maple-34-graphic\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"ordered by mistake\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': [], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230-maple-34-graphic'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'calculate', 'arguments': {'expression': 'total_price'}}, {'name': 'think', 'arguments': {'thought': \"Let's check if the maple skateboard is available.\"}}, {'name': 'get_product_details', 'arguments': {'product_id': '1008292230-maple-34-graphic'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'ordered by mistake'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:05,552 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,553 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,554 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,556 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:05,557 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,560 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"daiki.silva6295@example.com\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'daiki.silva6295@example.com'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:05,981 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:05,982 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,983 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,984 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,985 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,985 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:05,987 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,987 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:05 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:05,992 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"DC001\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Let's check the product details to see if it has a 10x zoom. If not, we need to handle the cancellation.\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"3000 > 3000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"ordered by mistake\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_product_details', 'arguments': {'product_id': 'DC001'}}, {'name': 'think', 'arguments': {'thought': \"Let's check the product details to see if it has a 10x zoom. If not, we need to handle the cancellation.\"}}, {'name': 'calculate', 'arguments': {'expression': '3000 > 3000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'ordered by mistake'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:06,228 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:06,230 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,232 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,232 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,233 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:06,233 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,235 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:06,236 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,239 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,314 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:06,316 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,317 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,317 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,318 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:06,318 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,320 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:06,321 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,325 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,330 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:06,331 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,332 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,332 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,333 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:06,334 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,336 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:06,337 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,342 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,404 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:06,406 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,407 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,408 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,409 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,409 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Let's check the order details to see what we're dealing with and if a credit card refund is possible.\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"Order price - return value\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"sara_doe_496\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"1008292230\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, let's proceed with the return and credit card refund. I hope this works smoothly.\"}},\n",
      "  {\"name\": \"modify_pending_order_payment\", \"arguments\": {\"order_id\": \"#W0000000\", \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'think', 'arguments': {'thought': \"Let's check the order details to see what we're dealing with and if a credit card refund is possible.\"}}, {'name': 'calculate', 'arguments': {'expression': 'Order price - return value'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'sara_doe_496'}}, {'name': 'get_product_details', 'arguments': {'product_id': '1008292230'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}, {'name': 'think', 'arguments': {'thought': \"Okay, let's proceed with the return and credit card refund. I hope this works smoothly.\"}}, {'name': 'modify_pending_order_payment', 'arguments': {'order_id': '#W0000000', 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"lei.wilson@example.com\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'lei.wilson@example.com'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"lei.wilson@example.com\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'lei.wilson@example.com'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"lei.wilson@example.com\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'lei.wilson@example.com'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:06,410 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,411 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,416 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,492 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:06,494 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,495 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,495 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,496 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,496 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:06,498 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,498 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,502 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"sara_doe_496\"}},\n",
      "  {\"name\": \"modify_user_address\", \"arguments\": {\"user_id\": \"sara_doe_496\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"Washington DC\", \"state\": \"DC\", \"country\": \"USA\", \"zip\": \"20002\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"Washington DC\", \"state\": \"DC\", \"country\": \"USA\", \"zip\": \"20002\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_user_details', 'arguments': {'user_id': 'sara_doe_496'}}, {'name': 'modify_user_address', 'arguments': {'user_id': 'sara_doe_496', 'address1': '123 Main St', 'address2': '', 'city': 'Washington DC', 'state': 'DC', 'country': 'USA', 'zip': '20002'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '123 Main St', 'address2': '', 'city': 'Washington DC', 'state': 'DC', 'country': 'USA', 'zip': '20002'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:06,903 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:06,905 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,906 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,906 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,907 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,907 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:06,909 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,909 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:06 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:06,913 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W5056519\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W8277957\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W5056519\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"San Francisco\", \"state\": \"CA\", \"country\": \"USA\", \"zip\": \"12345\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W8277957\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"San Francisco\", \"state\": \"CA\", \"country\": \"USA\", \"zip\": \"12345\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W5056519\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W5995614\", \"reason\": \"ordered by mistake\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W5056519'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W8277957'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W5056519', 'address1': '123 Main St', 'address2': '', 'city': 'San Francisco', 'state': 'CA', 'country': 'USA', 'zip': '12345'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W8277957', 'address1': '123 Main St', 'address2': '', 'city': 'San Francisco', 'state': 'CA', 'country': 'USA', 'zip': '12345'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W5056519', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W5995614', 'reason': 'ordered by mistake'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:07,117 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:07,119 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,120 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,120 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,121 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,122 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,123 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:07,124 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,128 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W7209932\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W7209932\", \"item_ids\": [\"T-Shirt {'color': 'blue', 'size': 'S', 'material': 'polyester', 'style': 'v-neck'}\"], \"new_item_ids\": [\"T-Shirt {'color': 'red', 'size': 'XXL', 'material': 'cotton', 'style': 'crew neck'}\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, let's see if we can swap this shirt. It's a bit... complicated, isn't it? I'm not entirely sure about the color matching, but the sizes are definitely different. And the material! Polyester to cotton... a significant shift.  I'm also wondering if the agent will be confused by all the curly brackets in the product descriptions. It's like a secret code!  I hope the refund goes smoothly to the gift card.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W7209932\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'user@example.com'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W7209932'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W7209932', 'item_ids': [\"T-Shirt {'color': 'blue', 'size': 'S', 'material': 'polyester', 'style': 'v-neck'}\"], 'new_item_ids': [\"T-Shirt {'color': 'red', 'size': 'XXL', 'material': 'cotton', 'style': 'crew neck'}\"], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'think', 'arguments': {'thought': \"Okay, let's see if we can swap this shirt. It's a bit... complicated, isn't it? I'm not entirely sure about the color matching, but the sizes are definitely different. And the material! Polyester to cotton... a significant shift.  I'm also wondering if the agent will be confused by all the curly brackets in the product descriptions. It's like a secret code!  I hope the refund goes smoothly to the gift card.\"}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W7209932', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:07,630 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:07,631 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:07,632 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,633 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:07,633 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,634 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,634 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,634 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,635 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,635 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,636 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:07,636 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,638 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:07,639 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,640 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,640 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:07 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,648 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:07,649 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"user123\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I want to return the more expensive tablet and get a GC refund.\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'user@example.com'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'user123'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'think', 'arguments': {'thought': 'Okay, I want to return the more expensive tablet and get a GC refund.'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"123 Main St\", \"address2\": \"Apt 1\", \"city\": \"New York\", \"state\": \"NY\", \"country\": \"USA\", \"zip\": \"10001\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '123 Main St', 'address2': 'Apt 1', 'city': 'New York', 'state': 'NY', 'country': 'USA', 'zip': '10001'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:08,308 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:08,309 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,310 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,311 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,311 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,312 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:08,314 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,314 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,318 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,507 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_zip\", \"arguments\": {\"zip\": \"78705\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"Mei Ahmed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000002\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000003\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to return all three items and get a refund to my credit card.\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"User wants to return three items (skateboards, smart watch, e-reader) and receive a credit card refund.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_zip', 'arguments': {'zip': '78705'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'Mei Ahmed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W00000001', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W00000002', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W00000003', 'reason': 'no longer needed'}}, {'name': 'think', 'arguments': {'thought': 'I need to return all three items and get a refund to my credit card.'}}, {'name': 'transfer_to_human_agents', 'arguments': {'summary': 'User wants to return three items (skateboards, smart watch, e-reader) and receive a credit card refund.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:08,509 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,510 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,510 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,511 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,512 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "2025-04-11 13:12:08,514 - INFO - \n",
      "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,514 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,518 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,541 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:08,543 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,544 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,544 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,545 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,545 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,546 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,547 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,676 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:08,677 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,679 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,679 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,680 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,680 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,682 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,682 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_name_zip\", \"arguments\": {\"first_name\": \"Lei\", \"last_name\": \"Wilson\", \"zip\": \"32255\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\", \"1008292230\"], \"new_item_ids\": [\"1008292230\", \"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"total_price\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I need to calculate the total price after the exchange.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_name_zip', 'arguments': {'first_name': 'Lei', 'last_name': 'Wilson', 'zip': '32255'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230', '1008292230'], 'new_item_ids': ['1008292230', '1008292230'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'calculate', 'arguments': {'expression': 'total_price'}}, {'name': 'think', 'arguments': {'thought': 'I need to calculate the total price after the exchange.'}}]\n",
      "Generating full plan (Model: openai/google/gemma-3-4b-it, Prompt Format: separate system/user prompts)...\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"something@example.com\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'something@example.com'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}]\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"your_email\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"user_id\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"LA_order_id\", \"address1\": \"NYC_address1\", \"address2\": \"NYC_address2\", \"city\": \"NYC_city\", \"state\": \"NYC_state\", \"country\": \"USA\", \"zip\": \"NYC_zip\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"LA_order_id\", \"item_ids\": [\"LA_speaker_id\"], \"new_item_ids\": [\"cheapest_green_speaker_id\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"LA_order_id\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'your_email'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'user_id'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': 'LA_order_id', 'address1': 'NYC_address1', 'address2': 'NYC_address2', 'city': 'NYC_city', 'state': 'NYC_state', 'country': 'USA', 'zip': 'NYC_zip'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': 'LA_order_id', 'item_ids': ['LA_speaker_id'], 'new_item_ids': ['cheapest_green_speaker_id'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': 'LA_order_id', 'reason': 'no longer needed'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:08,987 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:08,988 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,989 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,989 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,990 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,991 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,992 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:08 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:08,993 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,071 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:09,072 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,074 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,074 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,074 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,075 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,076 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,077 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,111 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:09,113 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,114 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,114 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,115 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,115 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,117 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,118 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\", \"1008292231\"], \"new_item_ids\": [], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292232\"], \"new_item_ids\": [], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\", \"1008292231\", \"1008292232\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'user@example.com'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230', '1008292231'], 'new_item_ids': [], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292232'], 'new_item_ids': [], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'return_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230', '1008292231', '1008292232'], 'payment_method_id': 'credit_card_0000000'}}]\n",
      "Model raw response:\n",
      "[\n",
      "    {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "    {\"name\": \"calculate\", \"arguments\": {\"expression\": \"order_total - eReader_price\"}},\n",
      "    {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}}\n",
      "]\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'calculate', 'arguments': {'expression': 'order_total - eReader_price'}}, {'name': 'return_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}]\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W4316152\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The user wants to exchange a Tea Kettle. Let's gather details about the order and the desired exchange.\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W4316152\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W4316152'}}, {'name': 'think', 'arguments': {'thought': \"The user wants to exchange a Tea Kettle. Let's gather details about the order and the desired exchange.\"}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W4316152', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292231'], 'payment_method_id': 'credit_card_0000000'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:09,234 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:09,236 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,237 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,237 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,238 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,238 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,239 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:09 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:09,241 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_zip\", \"arguments\": {\"zip\": \"75284\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"ordered by mistake\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_zip', 'arguments': {'zip': '75284'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292231'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'ordered by mistake'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:10,648 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:10 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:10,650 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:10,651 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:10,651 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:10,652 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:10,652 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:10,654 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:10,655 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"New York\", \"state\": \"NY\", \"country\": \"USA\", \"zip\": \"10001\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"6086499569\"], \"new_item_ids\": [\"6086499570\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, address and item changes done. Let's confirm.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '123 Main St', 'address2': '', 'city': 'New York', 'state': 'NY', 'country': 'USA', 'zip': '10001'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292231'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['6086499569'], 'new_item_ids': ['6086499570'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'think', 'arguments': {'thought': \"Okay, address and item changes done. Let's confirm.\"}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:11,002 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:11 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:11,004 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:11,005 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:11,005 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:11,005 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:11,006 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:11,008 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:11,009 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"New York\", \"state\": \"NY\", \"country\": \"USA\", \"zip\": \"10001\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"6086499569\"], \"new_item_ids\": [\"6086499570\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, address and item changes done. Let's confirm.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '123 Main St', 'address2': '', 'city': 'New York', 'state': 'NY', 'country': 'USA', 'zip': '10001'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292231'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['6086499569'], 'new_item_ids': ['6086499570'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'think', 'arguments': {'thought': \"Okay, address and item changes done. Let's confirm.\"}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:11,828 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:11 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:11,829 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:11,830 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:11,830 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:11,831 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:11,832 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:11,833 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:11 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:11,834 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,018 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"sara_doe_496\"}},\n",
      "  {\"name\": \"modify_user_address\", \"arguments\": {\"user_id\": \"sara_doe_496\", \"address1\": \"123 Elm Avenue\", \"address2\": \"\", \"city\": \"Houston\", \"state\": \"TX\", \"country\": \"USA\", \"zip\": \"77002\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"123 Elm Avenue\", \"address2\": \"\", \"city\": \"Houston\", \"state\": \"TX\", \"country\": \"USA\", \"zip\": \"77002\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I've updated the address and exchanged the tablet.  Let me confirm everything is correct.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_user_details', 'arguments': {'user_id': 'sara_doe_496'}}, {'name': 'modify_user_address', 'arguments': {'user_id': 'sara_doe_496', 'address1': '123 Elm Avenue', 'address2': '', 'city': 'Houston', 'state': 'TX', 'country': 'USA', 'zip': '77002'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '123 Elm Avenue', 'address2': '', 'city': 'Houston', 'state': 'TX', 'country': 'USA', 'zip': '77002'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292231'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'think', 'arguments': {'thought': \"Okay, I've updated the address and exchanged the tablet.  Let me confirm everything is correct.\"}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:12,019 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,021 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,021 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,022 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,023 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,025 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,026 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,145 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:12,146 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,148 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,148 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,149 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,149 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,150 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,151 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000002\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000003\", \"reason\": \"ordered by mistake\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000003\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000001\", \"address1\": \"1234 Main St\", \"address2\": \"\", \"city\": \"Chicago\", \"state\": \"IL\", \"country\": \"USA\", \"zip\": \"60601\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000001\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, let's get that tracking number.\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000001\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000001', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000002', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000003', 'reason': 'ordered by mistake'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000003', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000001', 'address1': '1234 Main St', 'address2': '', 'city': 'Chicago', 'state': 'IL', 'country': 'USA', 'zip': '60601'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000001'}}, {'name': 'think', 'arguments': {'thought': \"Okay, let's get that tracking number.\"}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000001'}}]\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\n",
      "  {\"name\": \"list_all_pending_orders\", \"arguments\": {}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"W00000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"W00000002\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"W00000003\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"W00000004\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"W00000005\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'user@example.com'}}, {'name': 'list_all_pending_orders', 'arguments': {}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': 'W00000001', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': 'W00000002', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': 'W00000003', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': 'W00000004', 'reason': 'no longer needed'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': 'W00000005', 'reason': 'no longer needed'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:12,238 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:12,240 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,241 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,241 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,242 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,243 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,244 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,245 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"sara_doe_496\"}},\n",
      "  {\"name\": \"modify_user_address\", \"arguments\": {\"user_id\": \"sara_doe_496\", \"address1\": \"123 Elm Avenue\", \"address2\": \"\", \"city\": \"Houston\", \"state\": \"TX\", \"country\": \"USA\", \"zip\": \"77002\"}},\n",
      "  {\"name\": \"modify_user_address\", \"arguments\": {\"user_id\": \"sara_doe_496\", \"address1\": \"123 Elm Avenue\", \"address2\": \"\", \"city\": \"Houston\", \"state\": \"TX\", \"country\": \"USA\", \"zip\": \"77002\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_user_details', 'arguments': {'user_id': 'sara_doe_496'}}, {'name': 'modify_user_address', 'arguments': {'user_id': 'sara_doe_496', 'address1': '123 Elm Avenue', 'address2': '', 'city': 'Houston', 'state': 'TX', 'country': 'USA', 'zip': '77002'}}, {'name': 'modify_user_address', 'arguments': {'user_id': 'sara_doe_496', 'address1': '123 Elm Avenue', 'address2': '', 'city': 'Houston', 'state': 'TX', 'country': 'USA', 'zip': '77002'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:12,680 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:12,682 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,683 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,683 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,684 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,685 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,686 - ERROR - Error parsing JSON plan: Invalid control character at: line 16 column 149 (char 1511)\n",
      "2025-04-11 13:12:12,687 - ERROR - Raw response: ```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"silva7872@example.com\"}},\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"amelia.silva7872@example.com\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"sara_doe_496\"}},\n",
      "  {\"name\": \"list_all_product_types\"},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000002\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000003\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000004\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000005\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000006\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000007\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000008\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000009\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000010\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I need to cancel all my pending orders. It's so stressful! I'm really worried about this.\"}, \"},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000011\", \"item_ids\": [\"1008292230\", \"1008292231\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000012\", \"item_ids\": [\"1008292232\", \"1008292233\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000013\", \"item_ids\": [\"1008292234\", \"1008292235\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000014\", \"item_ids\": [\"1008292236\", \"1008292237\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000015\", \"item_ids\": [\"1008292238\", \"1008292239\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000016\", \"item_ids\": [\"100829\n",
      "2025-04-11 13:12:12,687 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "Processing retail instructions:  49%|████▊     | 56/115 [00:26<00:21,  2.69it/s]\u001b[92m13:12:12 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:12,688 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"silva7872@example.com\"}},\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"amelia.silva7872@example.com\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"sara_doe_496\"}},\n",
      "  {\"name\": \"list_all_product_types\"},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000002\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000003\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000004\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000005\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000006\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000007\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000008\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000009\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000010\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I need to cancel all my pending orders. It's so stressful! I'm really worried about this.\"}, \"},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000011\", \"item_ids\": [\"1008292230\", \"1008292231\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000012\", \"item_ids\": [\"1008292232\", \"1008292233\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000013\", \"item_ids\": [\"1008292234\", \"1008292235\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000014\", \"item_ids\": [\"1008292236\", \"1008292237\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000015\", \"item_ids\": [\"1008292238\", \"1008292239\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000016\", \"item_ids\": [\"100829\n",
      "\n",
      "Parsed Plan: [{'error': 'JSONDecodeError: Invalid control character at: line 16 column 149 (char 1511)', 'raw_response': '```json\\n[\\n  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"silva7872@example.com\"}},\\n  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"amelia.silva7872@example.com\"}},\\n  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"sara_doe_496\"}},\\n  {\"name\": \"list_all_product_types\"},\\n  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000001\", \"reason\": \"no longer needed\"}},\\n  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000002\", \"reason\": \"no longer needed\"}},\\n  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000003\", \"reason\": \"no longer needed\"}},\\n  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000004\", \"reason\": \"no longer needed\"}},\\n  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000005\", \"reason\": \"no longer needed\"}},\\n  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000006\", \"reason\": \"no longer needed\"}},\\n  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000007\", \"reason\": \"no longer needed\"}},\\n  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000008\", \"reason\": \"no longer needed\"}},\\n  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000009\", \"reason\": \"no longer needed\"}},\\n  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W00000010\", \"reason\": \"no longer needed\"}},\\n  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I need to cancel all my pending orders. It\\'s so stressful! I\\'m really worried about this.\"}, \"},\\n  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000011\", \"item_ids\": [\"1008292230\", \"1008292231\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000012\", \"item_ids\": [\"1008292232\", \"1008292233\"], \"payment_method_id\": \"credit_card_0000000\"}},\\n  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000013\", \"item_ids\": [\"1008292234\", \"1008292235\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000014\", \"item_ids\": [\"1008292236\", \"1008292237\"], \"payment_method_id\": \"credit_card_0000000\"}},\\n  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000015\", \"item_ids\": [\"1008292238\", \"1008292239\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W00000016\", \"item_ids\": [\"100829'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:13,034 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:13 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:13,036 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:13,037 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:13,038 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:13,038 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:13,039 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:13,040 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:13,041 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"user123\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, let's exchange the bicycle for a larger frame, the jigsaw puzzle for a higher piece count with an animal theme, and the camera for a slightly lower resolution. Also, I want to cancel the skateboard order.\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"bicycle_1008292230\"], \"new_item_ids\": [\"bicycle_larger_frame_1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"jigsaw_puzzle_1008292230\"], \"new_item_ids\": [\"jigsaw_puzzle_1000_pieces_animal_1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"camera_1008292230\"], \"new_item_ids\": [\"camera_lower_resolution_1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"I'd prefer to use the gift card as the payment method for the refunds.\"}},\n",
      "  {\"name\": \"transfer_to_human_agents\", \"arguments\": {\"summary\": \"User wants to exchange bicycle, jigsaw puzzle, and camera, and cancel skateboard order.\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'find_user_id_by_email', 'arguments': {'email': 'user@example.com'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'user123'}}, {'name': 'think', 'arguments': {'thought': \"Okay, let's exchange the bicycle for a larger frame, the jigsaw puzzle for a higher piece count with an animal theme, and the camera for a slightly lower resolution. Also, I want to cancel the skateboard order.\"}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['bicycle_1008292230'], 'new_item_ids': ['bicycle_larger_frame_1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['jigsaw_puzzle_1008292230'], 'new_item_ids': ['jigsaw_puzzle_1000_pieces_animal_1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['camera_1008292230'], 'new_item_ids': ['camera_lower_resolution_1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}, {'name': 'think', 'arguments': {'thought': \"I'd prefer to use the gift card as the payment method for the refunds.\"}}, {'name': 'transfer_to_human_agents', 'arguments': {'summary': 'User wants to exchange bicycle, jigsaw puzzle, and camera, and cancel skateboard order.'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:13,822 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:13 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:13,824 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:13,826 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:13,826 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:13,827 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:13,828 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:13,829 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:13 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:13,830 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:14,031 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"6086499569\"], \"new_item_ids\": [\"6086499569\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"7013857891\"], \"new_item_ids\": [\"7013857891\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"35 E Chicago Ave\", \"address2\": \"\", \"city\": \"Chicago\", \"state\": \"IL\", \"country\": \"USA\", \"zip\": \"60611\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, now I need the tracking number for the cancelled order.\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['6086499569'], 'new_item_ids': ['6086499569'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['7013857891'], 'new_item_ids': ['7013857891'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '35 E Chicago Ave', 'address2': '', 'city': 'Chicago', 'state': 'IL', 'country': 'USA', 'zip': '60611'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'think', 'arguments': {'thought': 'Okay, now I need the tracking number for the cancelled order.'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:12:14 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:14,033 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:14,034 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:14,034 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:14,035 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:14,036 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:14,037 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:14,038 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:14,044 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:14 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:14,045 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:14,046 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:14,046 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:14,047 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:14,048 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:14,049 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:14 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:14,050 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_id_by_email\", \"arguments\": {\"email\": \"sara_doe_496\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"123 Main St\", \"address2\": \"Apt 1\", \"city\": \"New York\", \"state\": \"NY\", \"country\": \"USA\", \"zip\": \"10001\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"9844888101\"], \"new_item_ids\": [\"9844888101\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, I've modified the address and laptop item. Now I need to exchange the watch for a black dial.\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_user_id_by_email', 'arguments': {'email': 'sara_doe_496'}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '123 Main St', 'address2': 'Apt 1', 'city': 'New York', 'state': 'NY', 'country': 'USA', 'zip': '10001'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['9844888101'], 'new_item_ids': ['9844888101'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['1008292230'], 'new_item_ids': ['1008292230'], 'payment_method_id': 'credit_card_0000000'}}, {'name': 'think', 'arguments': {'thought': \"Okay, I've modified the address and laptop item. Now I need to exchange the watch for a black dial.\"}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"get_user_id_by_name_zip\", \"arguments\": {\"first_name\": \"Yara\", \"last_name\": \"Silva\", \"zip\": \"77159\"}},\n",
      "  {\"name\": \"get_user_details\", \"arguments\": {\"user_id\": \"yara_silva_123\"}},\n",
      "  {\"name\": \"modify_pending_order_address\", \"arguments\": {\"order_id\": \"#W0000000\", \"address1\": \"123 Main St\", \"address2\": \"\", \"city\": \"New York\", \"state\": \"NY\", \"country\": \"USA\", \"zip\": \"10001\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"watch_1008292230\"], \"new_item_ids\": [\"watch_1008292231\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"laptop_1008292230\"], \"new_item_ids\": [\"laptop_1008292232\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, let's confirm all the changes are correct before finalizing.\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'get_user_id_by_name_zip', 'arguments': {'first_name': 'Yara', 'last_name': 'Silva', 'zip': '77159'}}, {'name': 'get_user_details', 'arguments': {'user_id': 'yara_silva_123'}}, {'name': 'modify_pending_order_address', 'arguments': {'order_id': '#W0000000', 'address1': '123 Main St', 'address2': '', 'city': 'New York', 'state': 'NY', 'country': 'USA', 'zip': '10001'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['watch_1008292230'], 'new_item_ids': ['watch_1008292231'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'modify_pending_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['laptop_1008292230'], 'new_item_ids': ['laptop_1008292232'], 'payment_method_id': 'gift_card_0000000'}}, {'name': 'think', 'arguments': {'thought': \"Okay, let's confirm all the changes are correct before finalizing.\"}}, {'name': 'get_order_details', 'arguments': {'order_id': '#W0000000'}}, {'name': 'cancel_pending_order', 'arguments': {'order_id': '#W0000000', 'reason': 'no longer needed'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:16,234 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:16,237 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:16,238 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:16,238 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:16,239 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:16,240 - WARNING - Skipping invalid item in plan: {'name': 'list_all_product_types'}\n",
      "2025-04-11 13:12:16,239 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "Processing retail instructions:  78%|███████▊  | 90/115 [00:30<00:05,  4.42it/s]\u001b[92m13:12:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:16,242 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:16,243 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"list_all_product_types\"},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"200\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0001\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0002\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0003\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0004\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0005\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0006\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0007\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0008\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0009\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0010\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0011\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0012\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0013\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0014\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0015\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0016\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0017\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0018\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0019\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0020\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"Okay, let's find the cheapest mechanical keyboard and see if it's worth exchanging my current one.\"}},\n",
      "  {\"name\": \"get_product_details\", \"arguments\": {\"product_id\": \"mechanical_keyboard_0001\"}},\n",
      "  {\"name\": \"calculate\", \"arguments\": {\"expression\": \"200\"}},\n",
      "  {\"name\": \"think\", \"arguments\": {\"thought\": \"The cheapest one is $199.99.  I should exchange my current keyboard.\"}},\n",
      "  {\"name\": \"exchange_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"mechanical_keyboard_0001\"], \"new_item_ids\": [\"mechanical_keyboard_0001\"], \"payment_method_id\": \"credit_card_0000000\"}}\n",
      "]\n",
      "```\n",
      "\n",
      "Parsed Plan: [{'name': 'calculate', 'arguments': {'expression': '200'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0001'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0002'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0003'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0004'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0005'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0006'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0007'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0008'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0009'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0010'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0011'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0012'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0013'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0014'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0015'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0016'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0017'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0018'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0019'}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0020'}}, {'name': 'think', 'arguments': {'thought': \"Okay, let's find the cheapest mechanical keyboard and see if it's worth exchanging my current one.\"}}, {'name': 'get_product_details', 'arguments': {'product_id': 'mechanical_keyboard_0001'}}, {'name': 'calculate', 'arguments': {'expression': '200'}}, {'name': 'think', 'arguments': {'thought': 'The cheapest one is $199.99.  I should exchange my current keyboard.'}}, {'name': 'exchange_delivered_order_items', 'arguments': {'order_id': '#W0000000', 'item_ids': ['mechanical_keyboard_0001'], 'new_item_ids': ['mechanical_keyboard_0001'], 'payment_method_id': 'credit_card_0000000'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:12:19,658 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:19,661 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:19,662 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:19,662 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:19,663 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:19,664 - ERROR - Error parsing JSON plan: Expecting ',' delimiter: line 15 column 139 (char 2117)\n",
      "2025-04-11 13:12:19,665 - ERROR - Raw response: ```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292231\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292232\"], \"new_item_ids\": [\"1008292232\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292233\"], \"new_item_ids\": [\"1008292233\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292234\"], \"new_item_ids\": [\"1008292234\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000001\", \"item_ids\": [\"1008292235\"], \"new_item_ids\": [\"1008292235\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000001\", \"item_ids\": [\"1008292236\"], \"new_item_ids\": [\"1008292236\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000001\", \"item_ids\": [\"1008292237\"], \"new_item_ids\": [\"1008292237\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000002\", \"item_ids\": [\"1008292238\"], \"new_item_ids\": [\"1008292238\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000002\", \"item_ids\": [\"1008292239\"], \"new_item_ids\": [\"1008292239\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\n",
      "2025-04-11 13:12:19,663 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "Processing retail instructions:  88%|████████▊ | 101/115 [00:33<00:03,  4.11it/s]\u001b[92m13:12:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:19,666 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:19,667 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:19,745 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:12:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-11 13:12:19,746 - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:12:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:19,747 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\u001b[92m13:12:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:19,748 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:19,749 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:19,750 - ERROR - Error parsing JSON plan: Expecting ',' delimiter: line 13 column 139 (char 2043)\n",
      "2025-04-11 13:12:19,750 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "\u001b[92m13:12:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "2025-04-11 13:12:19,751 - ERROR - Raw response: ```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W000000\n",
      "Processing retail instructions: 100%|██████████| 115/115 [00:33<00:00,  3.40it/s]2025-04-11 13:12:19,751 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
      "\n",
      "\u001b[92m13:12:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
      "2025-04-11 13:12:19,753 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\n",
      "  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292231\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292232\"], \"new_item_ids\": [\"1008292232\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292233\"], \"new_item_ids\": [\"1008292233\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292234\"], \"new_item_ids\": [\"1008292234\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000001\", \"item_ids\": [\"1008292235\"], \"new_item_ids\": [\"1008292235\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000001\", \"item_ids\": [\"1008292236\"], \"new_item_ids\": [\"1008292236\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000001\", \"item_ids\": [\"1008292237\"], \"new_item_ids\": [\"1008292237\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000001\", \"reason\": \"no longer needed\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000002\", \"item_ids\": [\"1008292238\"], \"new_item_ids\": [\"1008292238\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000002\", \"item_ids\": [\"1008292239\"], \"new_item_ids\": [\"1008292239\"], \"payment_method_id\": \"visa_0000000\"}},\n",
      "  {\"name\": \"cancel_pending_order\n",
      "\n",
      "Parsed Plan: [{'error': \"JSONDecodeError: Expecting ',' delimiter: line 15 column 139 (char 2117)\", 'raw_response': '```json\\n[\\n  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\\n  {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"#W0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"visa_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292231\"], \"new_item_ids\": [\"1008292231\"], \"payment_method_id\": \"visa_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292232\"], \"new_item_ids\": [\"1008292232\"], \"payment_method_id\": \"visa_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292233\"], \"new_item_ids\": [\"1008292233\"], \"payment_method_id\": \"visa_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292234\"], \"new_item_ids\": [\"1008292234\"], \"payment_method_id\": \"visa_0000000\"}},\\n  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000000\", \"reason\": \"no longer needed\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000001\", \"item_ids\": [\"1008292235\"], \"new_item_ids\": [\"1008292235\"], \"payment_method_id\": \"visa_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000001\", \"item_ids\": [\"1008292236\"], \"new_item_ids\": [\"1008292236\"], \"payment_method_id\": \"visa_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000001\", \"item_ids\": [\"1008292237\"], \"new_item_ids\": [\"1008292237\"], \"payment_method_id\": \"visa_0000000\"}},\\n  {\"name\": \"cancel_pending_order\", \"arguments\": {\"order_id\": \"#W0000001\", \"reason\": \"no longer needed\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000002\", \"item_ids\": [\"1008292238\"], \"new_item_ids\": [\"1008292238\"], \"payment_method_id\": \"visa_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000002\", \"item_ids\": [\"1008292239\"], \"new_item_ids\": [\"1008292239\"], \"payment_method_id\": \"visa_0000000\"}},\\n  {\"name\": \"cancel_pending_order'}]\n",
      "Model raw response:\n",
      "```json\n",
      "[\n",
      "  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\n",
      "  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W000000\n",
      "\n",
      "Parsed Plan: [{'error': \"JSONDecodeError: Expecting ',' delimiter: line 13 column 139 (char 2043)\", 'raw_response': '```json\\n[\\n  {\"name\": \"find_user_id_by_email\", \"arguments\": {\"email\": \"user@example.com\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"return_delivered_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"payment_method_id\": \"gift_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W0000000\", \"item_ids\": [\"1008292230\"], \"new_item_ids\": [\"1008292230\"], \"payment_method_id\": \"credit_card_0000000\"}},\\n  {\"name\": \"modify_pending_order_items\", \"arguments\": {\"order_id\": \"#W000000'}]\n"
     ]
    }
   ],
   "source": [
    "def process_airline_row(args):\n",
    "    index, instruction = args\n",
    "    plan = generate_single_shot_plan(\n",
    "        user_query=instruction,\n",
    "        tools=airline_tool_dicts,\n",
    "        model=model_config[\"model\"],\n",
    "        api_base=model_config[\"api_base\"],\n",
    "        use_system_prompt=model_config[\"use_system_prompt\"]\n",
    "    )\n",
    "    return index, plan\n",
    "\n",
    "def process_retail_row(args):\n",
    "    index, instruction = args\n",
    "    plan = generate_single_shot_plan(\n",
    "        user_query=instruction,\n",
    "        tools=retail_tool_dicts,\n",
    "        model=model_config[\"model\"],\n",
    "        api_base=model_config[\"api_base\"],\n",
    "        use_system_prompt=model_config[\"use_system_prompt\"]\n",
    "    )\n",
    "    return index, plan\n",
    "\n",
    "\n",
    "airline_df['airline_planned_calls'] = None\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    airline_args = [(i, row['instruction']) for i, row in airline_df.iterrows()]\n",
    "    for index, plan in tqdm(executor.map(process_airline_row, airline_args), total=len(airline_df),desc=\"Processing airline instructions\"):\n",
    "        airline_df.at[index, 'airline_planned_calls'] = plan\n",
    "\n",
    "\n",
    "retail_df['retail_planned_calls'] = None\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    retail_args = [(i, row['instruction']) for i, row in retail_df.iterrows()]\n",
    "    for index, plan in tqdm(executor.map(process_retail_row, retail_args),total=len(retail_df), desc=\"Processing retail instructions\"):\n",
    "        retail_df.at[index, 'retail_planned_calls'] = plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retail_df = retail_df.drop('tools', axis=1)\n",
    "airline_df = airline_df.drop('tools', axis=1)\n",
    "\n",
    "retail_df.to_parquet(RETAIL_DATA_PATH, engine='fastparquet')\n",
    "airline_df.to_parquet(AIRLINE_DATA_PATH, engine='fastparquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
