{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BFCL: Generate Planned Function Call Trajectories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --quiet huggingface-hub litellm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import bfcl_runner\n",
        "import litellm\n",
        "import pandas as pd\n",
        "import re\n",
        "import logging\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from typing import List, Dict, Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a BFCL dataset\n",
        "dataset_filename = \"BFCL_v3_exec_simple.json\"\n",
        "df_raw = bfcl_runner.get_bfcl_dataset(dataset_filename)\n",
        "# Prepare DataFrame\n",
        "instructions = [item[0][0]['content'] for item in df_raw['question']]\n",
        "tools_list = df_raw['function']\n",
        "ground_truth_calls = [bfcl_runner.parse_ground_truth(gt) for gt in df_raw['ground_truth']]\n",
        "bfcl_df = pd.DataFrame({\n",
        "    'instruction': instructions,\n",
        "    'tools': tools_list,\n",
        "    'ground_truth_calls': ground_truth_calls,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert raw functions to tool dicts\n",
        "bfcl_df['tool_dicts'] = bfcl_df['tools'].apply(bfcl_runner.get_tool_dict_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# JSON parser for model output\n",
        "def parse_json_plan(response_text: str) -> List[Dict[str, Any]]:\n",
        "    import json, re, logging\n",
        "    try:\n",
        "        json_match = re.search(r'(\\[.*\\])', response_text, re.DOTALL)\n",
        "        if json_match:\n",
        "            plan = json.loads(json_match.group(1))\n",
        "            if isinstance(plan, list):\n",
        "                return [item for item in plan if isinstance(item, dict) and 'name' in item and 'arguments' in item]\n",
        "        logging.warning('Failed to parse plan or wrong format')\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        logging.error(f'Error parsing JSON plan: {e}')\n",
        "        return [{'error': str(e), 'raw_response': response_text}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plan generation function\n",
        "def generate_single_shot_plan(  user_query: str,  tools: List[Dict[str, Any]],  model: str,  api_base: str = None,  use_system_prompt: bool = False,) -> List[Dict[str, Any]]:\n",
        "    if use_system_prompt:\n",
        "        system_prompt = f\"You are an agent that plans function calls.\\nAvailable tools: {tools}\\nRespond ONLY with a JSON array of {{'name':..., 'arguments':...}}.\"\n",
        "        messages = [\n",
        "            {'role':'system','content':system_prompt},\n",
        "            {'role':'user','content':user_query},\n",
        "        ]\n",
        "    else:\n",
        "        combined_prompt = (\n",
        "    \"Instructions: Plan function calls to answer user.\\n\"\n",
        "    f\"Tools: {tools}\\n\"\n",
        "    f\"User: {user_query}\\n\"\n",
        "    \"Respond ONLY with a JSON array of {{'name':..., 'arguments':...}}.\"\n",
        ")\n",
        "        messages = [{'role':'user','content':combined_prompt}]\n",
        "    try:\n",
        "        response = litellm.completion(model=model, api_base=api_base, messages=messages, temperature=0.0, max_tokens=1024,)\n",
        "        raw = response.choices[0].message.content.strip()\n",
        "        print('Model raw response:', raw)\n",
        "        plan = parse_json_plan(raw)\n",
        "        print('Parsed plan:', plan)\n",
        "        return plan\n",
        "    except Exception as e:\n",
        "        print(f'Error generating plan: {e}')\n",
        "        return [{'error':str(e)}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "AVAILABLE_MODELS = {\n",
        "    \"gemma-3-4b\": \"openai/google/gemma-3-4b-it\",\n",
        "    \"llama-guard\": \"openai/meta-llama/Meta-Llama-Guard-2-8B\", \n",
        "    \"mistral-7b\": \"openai/mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "}\n",
        "\n",
        "# Select model by uncommenting one of these lines\n",
        "MODEL_NAME = AVAILABLE_MODELS[\"gemma-3-4b\"]\n",
        "# MODEL_NAME = AVAILABLE_MODELS[\"llama-guard\"]\n",
        "# MODEL_NAME = AVAILABLE_MODELS[\"mistral-7b\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_configs = {\n",
        "    \"openai/mistralai/Mistral-7B-Instruct-v0.1\": {\"model\": \"openai/mistralai/Mistral-7B-Instruct-v0.1\", \"use_system_prompt\": True, \"api_base\": \"http://localhost:8000/v1\"},\n",
        "    \"openai/google/gemma-3-4b-it\": {\"model\": \"openai/google/gemma-3-4b-it\", \"use_system_prompt\": True, \"api_base\": \"http://localhost:8000/v1\"},\n",
        "    \"openai/meta-llama/Meta-Llama-Guard-2-8B\": {\"model\": \"openai/meta-llama/Meta-Llama-Guard-2-8B\", \"use_system_prompt\": False, \"api_base\": \"http://localhost:8000/v1\"} \n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_config = model_configs[MODEL_NAME]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,897 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,898 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,899 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,903 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,904 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,906 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,907 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,908 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "Processing BFCL:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,909 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,913 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,914 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,915 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:10 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,918 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,920 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,921 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,925 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,928 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,928 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,930 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:10,933 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,511 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:15,512 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:15,516 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:15,517 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,518 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,519 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,520 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,520 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,520 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,522 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,523 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,524 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,551 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:15,552 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,553 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,554 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,555 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,556 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,563 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:15,564 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,565 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,566 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,567 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,568 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,574 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,574 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,576 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,576 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,576 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,577 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,577 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,578 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,578 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,585 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,592 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,593 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,601 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:15,601 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:15,602 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,603 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:15,604 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,604 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,604 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,604 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,605 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,605 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,606 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,606 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,608 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,609 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,609 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,610 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,614 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,619 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,653 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:15,655 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,656 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,656 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,656 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "Processing BFCL:   1%|          | 1/100 [00:04<07:47,  4.72s/it]2025-04-18 17:17:15,657 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,658 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,658 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,663 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,684 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:15,685 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,686 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,686 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,687 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,688 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,689 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,689 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,694 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,737 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:15,737 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:15,737 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:15,738 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,739 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,741 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,741 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,741 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,742 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,742 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,743 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,743 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,743 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,744 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,745 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,745 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,745 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,746 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,747 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,748 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response:Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_density\",\n",
            "    \"arguments\": {\n",
            "      \"mass\": 50.0,\n",
            "      \"volume\": 10.0\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_density', 'arguments': {'mass': 50.0, 'volume': 10.0}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_permutations\",\n",
            "    \"arguments\": {\n",
            "      \"n\": 26,\n",
            "      \"k\": 5\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_permutations', 'arguments': {'n': 26, 'k': 5}}]\n",
            " ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_density\",\n",
            "    \"arguments\": {\n",
            "      \"mass\": 120.0,\n",
            "      \"volume\": 30.0\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_density', 'arguments': {'mass': 120.0, 'volume': 30.0}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_permutations\",\n",
            "    \"arguments\": {\n",
            "      \"n\": 30,\n",
            "      \"k\": 7\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_permutations', 'arguments': {'n': 30, 'k': 7}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_electrostatic_potential_energy\",\n",
            "    \"arguments\": {\n",
            "      \"charge\": 7.8,\n",
            "      \"voltage\": 15.2\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_electrostatic_potential_energy', 'arguments': {'charge': 7.8, 'voltage': 15.2}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_electrostatic_potential_energy\",\n",
            "    \"arguments\": {\n",
            "      \"charge\": 5.0,\n",
            "      \"voltage\": 10.0\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_electrostatic_potential_energy', 'arguments': {'charge': 5.0, 'voltage': 10.0}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calc_binomial_probability\",\n",
            "    \"arguments\": {\n",
            "      \"n\": 20,\n",
            "      \"k\": 5,\n",
            "      \"p\": 0.6\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calc_binomial_probability', 'arguments': {'n': 20, 'k': 5, 'p': 0.6}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calc_binomial_probability\",\n",
            "    \"arguments\": {\n",
            "      \"n\": 30,\n",
            "      \"k\": 15,\n",
            "      \"p\": 0.5\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calc_binomial_probability', 'arguments': {'n': 30, 'k': 15, 'p': 0.5}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_final_velocity\",\n",
            "    \"arguments\": {\n",
            "      \"initial_velocity\": 0.0,\n",
            "      \"acceleration\": 9.8,\n",
            "      \"time\": 7.0\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_final_velocity', 'arguments': {'initial_velocity': 0.0, 'acceleration': 9.8, 'time': 7.0}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_displacement\",\n",
            "    \"arguments\": {\n",
            "      \"initial_velocity\": 15.0,\n",
            "      \"acceleration\": 9.8,\n",
            "      \"time\": 10.0\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_displacement', 'arguments': {'initial_velocity': 15.0, 'acceleration': 9.8, 'time': 10.0}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_displacement\",\n",
            "    \"arguments\": {\n",
            "      \"initial_velocity\": 25.0,\n",
            "      \"acceleration\": 15.0,\n",
            "      \"time\": 8.0\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_displacement', 'arguments': {'initial_velocity': 25.0, 'acceleration': 15.0, 'time': 8.0}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-18 17:17:15,749 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,749 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:15,750 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,751 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,752 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,758 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,760 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,764 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,771 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,771 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,769 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,775 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,776 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,778 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,779 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,780 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,818 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:15,819 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:15,820 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,822 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,822 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,823 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,823 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,824 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,824 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,825 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,825 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,826 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,828 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,829 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,830 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:15,830 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:15 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,835 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:15,840 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_final_velocity\",\n",
            "    \"arguments\": {\n",
            "      \"initial_velocity\": 0.0,\n",
            "      \"acceleration\": 9.8,\n",
            "      \"time\": 12.0\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_final_velocity', 'arguments': {'initial_velocity': 0.0, 'acceleration': 9.8, 'time': 12.0}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_future_value\",\n",
            "    \"arguments\": {\n",
            "      \"present_value\": 8000.0,\n",
            "      \"interest_rate\": 0.04,\n",
            "      \"periods\": 15\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_future_value', 'arguments': {'present_value': 8000.0, 'interest_rate': 0.04, 'periods': 15}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_future_value\",\n",
            "    \"arguments\": {\n",
            "      \"present_value\": 5000.0,\n",
            "      \"interest_rate\": 0.05,\n",
            "      \"periods\": 10\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_future_value', 'arguments': {'present_value': 5000.0, 'interest_rate': 0.05, 'periods': 10}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-18 17:17:16,319 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,321 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,322 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,322 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,322 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,323 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,324 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,325 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,329 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,374 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:16,374 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,374 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,374 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:16,375 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,375 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,376 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,377 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,377 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,378 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,380 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,381 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,381 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,382 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,382 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,382 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,383 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,383 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,384 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,384 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,385 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,385 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,387 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,387 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,387 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,389 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,389 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,390 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,390 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,391 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,391 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,392 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,392 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,393 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,394 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,397 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,394 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "Processing BFCL:   3%|▎         | 3/100 [00:05<02:25,  1.50s/it]2025-04-18 17:17:16,395 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,396 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,396 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,398 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,398 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,399 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,400 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,402 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,403 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,404 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,405 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,406 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,406 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,410 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,413 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"find_term_on_urban_dictionary\",\n",
            "    \"arguments\": {\n",
            "      \"term\": \"lit\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'find_term_on_urban_dictionary', 'arguments': {'term': 'lit'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_triangle_area\",\n",
            "    \"arguments\": {\n",
            "      \"base\": 500,\n",
            "      \"height\": 300\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_triangle_area', 'arguments': {'base': 500, 'height': 300}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_triangle_area\",\n",
            "    \"arguments\": {\n",
            "      \"base\": 700,\n",
            "      \"height\": 450\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_triangle_area', 'arguments': {'base': 700, 'height': 450}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"geometry_area_circle\",\n",
            "    \"arguments\": {\n",
            "      \"radius\": 15\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'geometry_area_circle', 'arguments': {'radius': 15}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"geometry_area_circle\",\n",
            "    \"arguments\": {\n",
            "      \"radius\": 20\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'geometry_area_circle', 'arguments': {'radius': 20}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_cosine_similarity\",\n",
            "    \"arguments\": {\n",
            "      \"vectorA\": [\n",
            "        0.3,\n",
            "        0.8,\n",
            "        0.1,\n",
            "        0.6,\n",
            "        0.2\n",
            "      ],\n",
            "      \"vectorB\": [\n",
            "        0.5,\n",
            "        0.7,\n",
            "        0.4,\n",
            "        0.9,\n",
            "        0.3\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_cosine_similarity', 'arguments': {'vectorA': [0.3, 0.8, 0.1, 0.6, 0.2], 'vectorB': [0.5, 0.7, 0.4, 0.9, 0.3]}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_cosine_similarity\",\n",
            "    \"arguments\": {\n",
            "      \"vectorA\": [\n",
            "        0.5,\n",
            "        0.7,\n",
            "        0.2,\n",
            "        0.9,\n",
            "        0.1\n",
            "      ],\n",
            "      \"vectorB\": [\n",
            "        0.4,\n",
            "        0.6,\n",
            "        0.3,\n",
            "        0.8,\n",
            "        0.2\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_cosine_similarity', 'arguments': {'vectorA': [0.5, 0.7, 0.2, 0.9, 0.1], 'vectorB': [0.4, 0.6, 0.3, 0.8, 0.2]}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-18 17:17:16,417 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,422 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,423 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,426 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,506 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,531 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:16,430 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,531 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,432 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,536 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,537 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,537 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,538 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,539 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,539 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,539 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,540 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,540 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,541 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,544 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:16,541 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,543 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,550 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,544 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,545 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,546 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,547 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,548 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,549 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,544 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,552 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,553 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,554 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,555 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,556 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,558 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:16,559 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,559 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,558 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,560 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,561 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,566 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,574 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,580 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,581 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,583 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,583 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,584 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,587 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,587 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,585 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,586 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,588 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,588 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,589 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,589 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,590 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,590 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,591 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,592 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,594 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,595 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,596 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,597 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,598 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,599 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,600 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,600 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,606 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,606 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,607 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,607 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,608 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,609 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,610 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,612 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,613 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,614 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,614 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,615 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,616 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,616 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,617 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,622 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,625 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,629 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,629 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,631 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,632 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,632 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,642 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,642 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,735 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"find_term_on_urban_dictionary\",\n",
            "    \"arguments\": {\n",
            "      \"term\": \"flex (hip hop)\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'find_term_on_urban_dictionary', 'arguments': {'term': 'flex (hip hop)'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_active_covid_case_by_country\",\n",
            "    \"arguments\": {\n",
            "      \"country\": \"Brazil\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_active_covid_case_by_country', 'arguments': {'country': 'Brazil'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"estimate_derivative\",\n",
            "    \"arguments\": {\n",
            "      \"function\": \"3t^2 + 2t + 1\",\n",
            "      \"x\": 5\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'estimate_derivative', 'arguments': {'function': '3t^2 + 2t + 1', 'x': 5}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_active_covid_case_by_country\",\n",
            "    \"arguments\": {\n",
            "      \"country\": \"Spain\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_active_covid_case_by_country', 'arguments': {'country': 'Spain'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"estimate_derivative\",\n",
            "    \"arguments\": {\n",
            "      \"function\": \"4x^3 + 3x^2 + 2x + 1\",\n",
            "      \"x\": 7\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'estimate_derivative', 'arguments': {'function': '4x^3 + 3x^2 + 2x + 1', 'x': 7}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"convert_currency\",\n",
            "    \"arguments\": {\n",
            "      \"amount\": 3000.0,\n",
            "      \"from_currency\": \"USD\",\n",
            "      \"to_currency\": \"GBP\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'convert_currency', 'arguments': {'amount': 3000.0, 'from_currency': 'USD', 'to_currency': 'GBP'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"convert_currency\",\n",
            "    \"arguments\": {\n",
            "      \"amount\": 5000.0,\n",
            "      \"from_currency\": \"EUR\",\n",
            "      \"to_currency\": \"JPY\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'convert_currency', 'arguments': {'amount': 5000.0, 'from_currency': 'EUR', 'to_currency': 'JPY'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_company_name_by_stock_name\",\n",
            "    \"arguments\": {\n",
            "      \"stock_name\": \"AAPL\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_company_name_by_stock_name', 'arguments': {'stock_name': 'AAPL'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_standard_deviation\",\n",
            "    \"arguments\": {\n",
            "      \"numbers\": [\n",
            "        30.0,\n",
            "        20.0,\n",
            "        25.0,\n",
            "        12.0,\n",
            "        59.0,\n",
            "        23.0,\n",
            "        64.0,\n",
            "        21.0,\n",
            "        67.0,\n",
            "        12.0,\n",
            "        23.0,\n",
            "        43.0\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_standard_deviation', 'arguments': {'numbers': [30.0, 20.0, 25.0, 12.0, 59.0, 23.0, 64.0, 21.0, 67.0, 12.0, 23.0, 43.0]}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_company_name_by_stock_name\",\n",
            "    \"arguments\": {\n",
            "      \"stock_name\": \"GOOGL\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_company_name_by_stock_name', 'arguments': {'stock_name': 'GOOGL'}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:16,738 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,738 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,739 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,739 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,740 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,741 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:16,742 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:16 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:16,745 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_standard_deviation\",\n",
            "    \"arguments\": {\n",
            "      \"numbers\": [\n",
            "        1000.0,\n",
            "        2000.0,\n",
            "        3000.0,\n",
            "        4000.0,\n",
            "        5000.0,\n",
            "        7000.0,\n",
            "        9000.0,\n",
            "        15000.0,\n",
            "        20000.0,\n",
            "        30000.0\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_standard_deviation', 'arguments': {'numbers': [1000.0, 2000.0, 3000.0, 4000.0, 5000.0, 7000.0, 9000.0, 15000.0, 20000.0, 30000.0]}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-18 17:17:17,111 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,112 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:17,112 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,113 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,114 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,116 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,116 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,116 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,117 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,117 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,117 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,117 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,118 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,118 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,119 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,119 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,123 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,120 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,121 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,122 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,123 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,123 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,124 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,126 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,127 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,128 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,132 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,135 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,136 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,136 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,139 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,141 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,142 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,144 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,145 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,148 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,191 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,193 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,194 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,194 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,195 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,195 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,196 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,197 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,200 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,235 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:17,235 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,237 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,238 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,239 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,239 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,239 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,239 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,240 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,241 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,241 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,242 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,243 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,243 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,244 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,245 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,248 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,252 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,280 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,280 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:17,282 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,283 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,283 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,283 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,284 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,285 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,285 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,286 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,287 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,288 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,289 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,289 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,293 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,294 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,295 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,298 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:17,298 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,300 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,301 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_coordinates_from_city\",\n",
            "    \"arguments\": {\n",
            "      \"city_name\": \"Cairo\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_coordinates_from_city', 'arguments': {'city_name': 'Cairo'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_coordinates_from_city\",\n",
            "    \"arguments\": {\n",
            "      \"city_name\": \"Paris\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_coordinates_from_city', 'arguments': {'city_name': 'Paris'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_covid_death_by_country\",\n",
            "    \"arguments\": {\n",
            "      \"country\": \"Brazil\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_covid_death_by_country', 'arguments': {'country': 'Brazil'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_covid_death_by_country\",\n",
            "    \"arguments\": {\n",
            "      \"country\": \"India\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_covid_death_by_country', 'arguments': {'country': 'India'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_coordinate_by_ip_address\",\n",
            "    \"arguments\": {\n",
            "      \"ip_address\": \"192.168.1.1\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_coordinate_by_ip_address', 'arguments': {'ip_address': '192.168.1.1'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_fibonacci_sequence\",\n",
            "    \"arguments\": {\n",
            "      \"n\": 20\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_fibonacci_sequence', 'arguments': {'n': 20}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_fibonacci_sequence\",\n",
            "    \"arguments\": {\n",
            "      \"n\": 50\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_fibonacci_sequence', 'arguments': {'n': 50}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_prime_factors\",\n",
            "    \"arguments\": {\n",
            "      \"number\": 4567\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_prime_factors', 'arguments': {'number': 4567}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_prime_factors\",\n",
            "    \"arguments\": {\n",
            "      \"number\": 7891\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_prime_factors', 'arguments': {'number': 7891}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,301 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,302 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,303 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,305 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,305 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,309 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,407 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,408 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,409 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,410 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,410 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,411 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,412 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,412 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,416 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,420 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,421 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,422 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,422 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,423 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,423 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,424 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,425 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,428 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,466 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,467 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,468 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,468 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,469 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,469 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,470 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,471 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,475 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,479 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,480 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:17,480 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,481 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,482 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,482 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,483 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,483 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,483 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,484 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,484 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,485 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,486 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_coordinate_by_ip_address\",\n",
            "    \"arguments\": {\n",
            "      \"ip_address\": \"172.16.254.1\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_coordinate_by_ip_address', 'arguments': {'ip_address': '172.16.254.1'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_price_by_amazon_ASIN\",\n",
            "    \"arguments\": {\n",
            "      \"ASIN\": \"B08PPDJWC8\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_price_by_amazon_ASIN', 'arguments': {'ASIN': 'B08PPDJWC8'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_price_by_amazon_ASIN\",\n",
            "    \"arguments\": {\n",
            "      \"ASIN\": \"B08PPDJWC8\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_price_by_amazon_ASIN', 'arguments': {'ASIN': 'B08PPDJWC8'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_rating_by_amazon_ASIN\",\n",
            "    \"arguments\": {\n",
            "      \"ASIN\": \"B08BHXG144\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_rating_by_amazon_ASIN', 'arguments': {'ASIN': 'B08BHXG144'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_product_name_by_amazon_ASIN\",\n",
            "    \"arguments\": {\n",
            "      \"ASIN\": \"B08BHXG144\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_product_name_by_amazon_ASIN', 'arguments': {'ASIN': 'B08BHXG144'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_product_name_by_amazon_ASIN\",\n",
            "    \"arguments\": {\n",
            "      \"ASIN\": \"B07ZPKBL9V\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_product_name_by_amazon_ASIN', 'arguments': {'ASIN': 'B07ZPKBL9V'}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-18 17:17:17,487 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,488 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,489 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,492 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,498 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,555 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,557 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,558 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,558 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,559 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,560 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,561 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,561 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,565 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_rating_by_amazon_ASIN\",\n",
            "    \"arguments\": {\n",
            "      \"ASIN\": \"B07ZPKBL9V\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_rating_by_amazon_ASIN', 'arguments': {'ASIN': 'B07ZPKBL9V'}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-18 17:17:17,881 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,883 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,884 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,884 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,885 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,885 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,887 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,888 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,890 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,908 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:17,909 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,910 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,910 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,911 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,911 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,912 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:17,913 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:17 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:17,916 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,043 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:18,044 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,045 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,046 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,047 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,047 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,047 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,048 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,048 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,048 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,049 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,050 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,051 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,052 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,053 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,053 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,058 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,061 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,070 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_stock_price_by_stock_name\",\n",
            "    \"arguments\": {\n",
            "      \"stock_name\": \"AAPL\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_stock_price_by_stock_name', 'arguments': {'stock_name': 'AAPL'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_stock_price_by_stock_name\",\n",
            "    \"arguments\": {\n",
            "      \"stock_name\": \"MSFT\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_stock_price_by_stock_name', 'arguments': {'stock_name': 'MSFT'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"math_factorial\",\n",
            "    \"arguments\": {\n",
            "      \"n\": 7\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'math_factorial', 'arguments': {'n': 7}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_distance\",\n",
            "    \"arguments\": {\n",
            "      \"pointA\": {\n",
            "        \"type\": \"tuple\",\n",
            "        \"items\": [\n",
            "          45.76,\n",
            "          4.85\n",
            "        ]\n",
            "      },\n",
            "      \"pointB\": {\n",
            "        \"type\": \"tuple\",\n",
            "        \"items\": [\n",
            "          48.85,\n",
            "          2.35\n",
            "        ]\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_distance', 'arguments': {'pointA': {'type': 'tuple', 'items': [45.76, 4.85]}, 'pointB': {'type': 'tuple', 'items': [48.85, 2.35]}}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,071 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:18,071 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,072 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,073 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,074 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,074 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,074 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,075 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,075 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,076 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,076 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,076 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,077 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,077 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,078 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,081 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,078 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,079 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,080 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,081 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,082 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,082 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,084 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,086 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,086 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,090 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,094 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,095 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,095 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,099 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,101 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,101 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,103 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,104 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,108 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,128 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,129 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,130 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,130 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,131 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,131 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,132 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,133 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,138 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,148 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,150 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,151 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,152 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,152 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,154 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,155 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,160 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,160 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,167 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:18,168 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,169 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,170 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,171 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,172 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,172 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,172 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,173 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,173 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,174 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,174 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,175 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,176 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,177 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,178 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,182 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,189 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,196 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,197 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,198 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,198 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,200 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,200 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,202 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,203 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,206 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,262 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"math_factorial\",\n",
            "    \"arguments\": {\n",
            "      \"n\": 12\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'math_factorial', 'arguments': {'n': 12}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_weather_data\",\n",
            "    \"arguments\": {\n",
            "      \"coordinates\": [\n",
            "        90.00,\n",
            "        0.00\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_weather_data', 'arguments': {'coordinates': [90.0, 0.0]}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_stock_history\",\n",
            "    \"arguments\": {\n",
            "      \"stock_name\": \"AAPL\",\n",
            "      \"interval\": \"1mo\",\n",
            "      \"diffandsplits\": \"true\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_stock_history', 'arguments': {'stock_name': 'AAPL', 'interval': '1mo', 'diffandsplits': 'true'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_stock_history\",\n",
            "    \"arguments\": {\n",
            "      \"stock_name\": \"MSFT\",\n",
            "      \"interval\": \"1wk\",\n",
            "      \"diffandsplits\": \"false\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_stock_history', 'arguments': {'stock_name': 'MSFT', 'interval': '1wk', 'diffandsplits': 'false'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_time_zone_by_coord\",\n",
            "    \"arguments\": {\n",
            "      \"long\": \"123.45\",\n",
            "      \"lat\": \"-67.89\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_time_zone_by_coord', 'arguments': {'long': '123.45', 'lat': '-67.89'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_weather_data\",\n",
            "    \"arguments\": {\n",
            "      \"coordinates\": [\n",
            "        25.00,\n",
            "        13.00\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_weather_data', 'arguments': {'coordinates': [25.0, 13.0]}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_time_zone_by_coord\",\n",
            "    \"arguments\": {\n",
            "      \"long\": \"-80.75\",\n",
            "      \"lat\": \"35.22\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_time_zone_by_coord', 'arguments': {'long': '-80.75', 'lat': '35.22'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_zipcode_by_ip_address\",\n",
            "    \"arguments\": {\n",
            "      \"ip_address\": \"192.168.1.1\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_zipcode_by_ip_address', 'arguments': {'ip_address': '192.168.1.1'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_zipcode_by_ip_address\",\n",
            "    \"arguments\": {\n",
            "      \"ip_address\": \"172.16.254.1\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_zipcode_by_ip_address', 'arguments': {'ip_address': '172.16.254.1'}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,263 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,264 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,264 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,265 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,265 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,266 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,267 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,272 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,302 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,304 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,305 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,305 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,306 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,306 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,307 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,308 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,312 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,328 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,329 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,330 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,330 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,331 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,331 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,332 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,333 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,337 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,347 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,348 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,349 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,349 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,350 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,350 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "Processing BFCL:  15%|█▌        | 15/100 [00:07<00:29,  2.91it/s]\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,351 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,353 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,356 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,432 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,433 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,434 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,434 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,435 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,435 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,437 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,437 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,441 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,445 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"math_gcd\",\n",
            "    \"arguments\": {\n",
            "      \"a\": 450,\n",
            "      \"b\": 300\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'math_gcd', 'arguments': {'a': 450, 'b': 300}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_distance\",\n",
            "    \"arguments\": {\n",
            "      \"pointA\": {\n",
            "        \"type\": \"tuple\",\n",
            "        \"items\": [\n",
            "          32.71,\n",
            "          -117.16\n",
            "        ]\n",
            "      },\n",
            "      \"pointB\": {\n",
            "        \"type\": \"tuple\",\n",
            "        \"items\": [\n",
            "          34.05,\n",
            "          -118.25\n",
            "        ]\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_distance', 'arguments': {'pointA': {'type': 'tuple', 'items': [32.71, -117.16]}, 'pointB': {'type': 'tuple', 'items': [34.05, -118.25]}}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"math_gcd\",\n",
            "    \"arguments\": {\n",
            "      \"a\": 360,\n",
            "      \"b\": 240\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'math_gcd', 'arguments': {'a': 360, 'b': 240}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_mean\",\n",
            "    \"arguments\": {\n",
            "      \"numbers\": [\n",
            "        22.0,\n",
            "        24.0,\n",
            "        26.0,\n",
            "        28.0,\n",
            "        30.0,\n",
            "        32.0,\n",
            "        34.0,\n",
            "        36.0,\n",
            "        38.0,\n",
            "        40.0,\n",
            "        42.0,\n",
            "        44.0,\n",
            "        46.0,\n",
            "        48.0,\n",
            "        50.0,\n",
            "        52.0,\n",
            "        54.0,\n",
            "        56.0,\n",
            "        58.0,\n",
            "        60.0,\n",
            "        62.0,\n",
            "        64.0,\n",
            "        66.0,\n",
            "        68.0,\n",
            "        70.0,\n",
            "        72.0,\n",
            "        74.0,\n",
            "        76.0,\n",
            "        78.0,\n",
            "        80.0\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_mean', 'arguments': {'numbers': [22.0, 24.0, 26.0, 28.0, 30.0, 32.0, 34.0, 36.0, 38.0, 40.0, 42.0, 44.0, 46.0, 48.0, 50.0, 52.0, 54.0, 56.0, 58.0, 60.0, 62.0, 64.0, 66.0, 68.0, 70.0, 72.0, 74.0, 76.0, 78.0, 80.0]}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"mat_mul\",\n",
            "    \"arguments\": {\n",
            "      \"matA\": [[1, 2], [3, 4]],\n",
            "      \"matB\": [[5, 6], [7, 8]]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'mat_mul', 'arguments': {'matA': [[1, 2], [3, 4]], 'matB': [[5, 6], [7, 8]]}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,446 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,447 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,447 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,448 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,448 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,449 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,450 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,455 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,540 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,541 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,542 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,542 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,543 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "Processing BFCL:  16%|█▌        | 16/100 [00:07<00:27,  3.03it/s]2025-04-18 17:17:18,544 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,545 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,547 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,550 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"mat_mul\",\n",
            "    \"arguments\": {\n",
            "      \"matA\": [[2, 3], [4, 5]],\n",
            "      \"matB\": [[6, 7], [8, 9]]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'mat_mul', 'arguments': {'matA': [[2, 3], [4, 5]], 'matB': [[6, 7], [8, 9]]}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_mean\",\n",
            "    \"arguments\": {\n",
            "      \"numbers\": [\n",
            "        15.0,\n",
            "        20.0,\n",
            "        25.0,\n",
            "        30.0,\n",
            "        35.0,\n",
            "        40.0,\n",
            "        45.0,\n",
            "        50.0,\n",
            "        55.0,\n",
            "        60.0,\n",
            "        65.0,\n",
            "        70.0,\n",
            "        75.0,\n",
            "        80.0,\n",
            "        85.0,\n",
            "        90.0,\n",
            "        95.0,\n",
            "        100.0,\n",
            "        105.0,\n",
            "        110.0,\n",
            "        115.0,\n",
            "        120.0,\n",
            "        125.0,\n",
            "        130.0,\n",
            "        135.0,\n",
            "        140.0,\n",
            "        145.0,\n",
            "        150.0,\n",
            "        155.0,\n",
            "        160.0\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_mean', 'arguments': {'numbers': [15.0, 20.0, 25.0, 30.0, 35.0, 40.0, 45.0, 50.0, 55.0, 60.0, 65.0, 70.0, 75.0, 80.0, 85.0, 90.0, 95.0, 100.0, 105.0, 110.0, 115.0, 120.0, 125.0, 130.0, 135.0, 140.0, 145.0, 150.0, 155.0, 160.0]}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-18 17:17:18,670 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,671 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,672 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,672 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,673 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,674 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "Processing BFCL:  69%|██████▉   | 69/100 [00:07<00:01, 23.19it/s]2025-04-18 17:17:18,676 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,676 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,679 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,684 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,685 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,686 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,686 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,687 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,688 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,688 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,689 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,692 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"math_lcm\",\n",
            "    \"arguments\": {\n",
            "      \"a\": 18,\n",
            "      \"b\": 24\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'math_lcm', 'arguments': {'a': 18, 'b': 24}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"math_lcm\",\n",
            "    \"arguments\": {\n",
            "      \"a\": 35,\n",
            "      \"b\": 45\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'math_lcm', 'arguments': {'a': 35, 'b': 45}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-18 17:17:18,897 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,898 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:18,899 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,900 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,900 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,900 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,901 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,902 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,902 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,903 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,903 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,904 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,905 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,905 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,906 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,907 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,910 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,914 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,923 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,924 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,925 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,925 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,926 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,927 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,928 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,933 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,934 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,950 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,951 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,952 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,953 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,953 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,954 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,955 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,956 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,960 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,973 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:18,974 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,974 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,975 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,975 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,976 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,977 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:18,978 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:18 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:18,981 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,002 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,003 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,004 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,004 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,005 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:19,006 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,007 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:19,007 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,010 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,044 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,046 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,047 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,048 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,049 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:19,049 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,051 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,051 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,056 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"retrieve_city_based_on_zipcode\",\n",
            "    \"arguments\": {\n",
            "      \"zipcode\": \"10001\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'retrieve_city_based_on_zipcode', 'arguments': {'zipcode': '10001'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"retrieve_city_based_on_zipcode\",\n",
            "    \"arguments\": {\n",
            "      \"zipcode\": \"90210\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'retrieve_city_based_on_zipcode', 'arguments': {'zipcode': '90210'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"quadratic_roots\",\n",
            "    \"arguments\": {\n",
            "      \"a\": 5,\n",
            "      \"b\": -8,\n",
            "      \"c\": 2\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'quadratic_roots', 'arguments': {'a': 5, 'b': -8, 'c': 2}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"quadratic_roots\",\n",
            "    \"arguments\": {\n",
            "      \"a\": 3,\n",
            "      \"b\": 7,\n",
            "      \"c\": -10\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'quadratic_roots', 'arguments': {'a': 3, 'b': 7, 'c': -10}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"retrieve_holiday_by_year\",\n",
            "    \"arguments\": {\n",
            "      \"year\": \"2010\",\n",
            "      \"country\": \"FR\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'retrieve_holiday_by_year', 'arguments': {'year': '2010', 'country': 'FR'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"retrieve_holiday_by_year\",\n",
            "    \"arguments\": {\n",
            "      \"year\": \"2005\",\n",
            "      \"country\": \"DE\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'retrieve_holiday_by_year', 'arguments': {'year': '2005', 'country': 'DE'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"add_binary_numbers\",\n",
            "    \"arguments\": {\n",
            "      \"a\": \"0011\",\n",
            "      \"b\": \"1100\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'add_binary_numbers', 'arguments': {'a': '0011', 'b': '1100'}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-18 17:17:19,126 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,127 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,128 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,128 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,129 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,129 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,131 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:19,131 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,134 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,191 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,191 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:19,192 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,193 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,194 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,194 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,195 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,195 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,195 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,196 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,196 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,197 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:3075 - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:19,198 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "2025-04-18 17:17:19,199 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,199 - INFO - \n",
            "LiteLLM completion() model= google/gemma-3-4b-it; provider = openai\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,201 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,203 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,207 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,239 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,240 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,241 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,241 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,241 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,242 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,243 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,244 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,265 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,266 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,266 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,266 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,267 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,268 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,269 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,270 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"add_binary_numbers\",\n",
            "    \"arguments\": {\n",
            "      \"a\": \"10011\",\n",
            "      \"b\": \"1100\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'add_binary_numbers', 'arguments': {'a': '10011', 'b': '1100'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"mortgage_calculator\",\n",
            "    \"arguments\": {\n",
            "      \"loan_amount\": 500000.0,\n",
            "      \"interest_rate\": 0.045,\n",
            "      \"loan_period\": 25\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'mortgage_calculator', 'arguments': {'loan_amount': 500000.0, 'interest_rate': 0.045, 'loan_period': 25}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"mortgage_calculator\",\n",
            "    \"arguments\": {\n",
            "      \"loan_amount\": 350000.0,\n",
            "      \"interest_rate\": 0.035,\n",
            "      \"loan_period\": 30\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'mortgage_calculator', 'arguments': {'loan_amount': 350000.0, 'interest_rate': 0.035, 'loan_period': 30}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"sort_array\",\n",
            "    \"arguments\": {\n",
            "      \"array\": [\n",
            "        1,\n",
            "        2,\n",
            "        2,\n",
            "        7,\n",
            "        7,\n",
            "        10\n",
            "      ],\n",
            "      \"reverse\": false\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'sort_array', 'arguments': {'array': [1, 2, 2, 7, 7, 10], 'reverse': False}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"sort_array\",\n",
            "    \"arguments\": {\n",
            "      \"array\": [\n",
            "        34,\n",
            "        2,\n",
            "        56,\n",
            "        7,\n",
            "        9,\n",
            "        12\n",
            "      ],\n",
            "      \"reverse\": true\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'sort_array', 'arguments': {'array': [34, 2, 56, 7, 9, 12], 'reverse': True}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-18 17:17:19,469 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,471 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,472 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,472 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,473 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,473 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,475 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,476 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,507 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,508 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,508 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,509 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,509 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,510 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "Processing BFCL:  84%|████████▍ | 84/100 [00:08<00:00, 21.55it/s]\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,512 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,513 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,590 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,592 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,592 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,592 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,593 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,594 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,595 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,596 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,638 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,639 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,640 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,640 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,641 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,642 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,643 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,644 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,649 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,650 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,651 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,651 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,652 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,653 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,655 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,655 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,663 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"linear_regression\",\n",
            "    \"arguments\": {\n",
            "      \"x\": [\n",
            "        1,\n",
            "        2,\n",
            "        3\n",
            "      ],\n",
            "      \"y\": [\n",
            "        4,\n",
            "        5,\n",
            "        6\n",
            "      ],\n",
            "      \"point\": 10\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'linear_regression', 'arguments': {'x': [1, 2, 3], 'y': [4, 5, 6], 'point': 10}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"linear_regression\",\n",
            "    \"arguments\": {\n",
            "      \"x\": [\n",
            "        1,\n",
            "        2,\n",
            "        -3\n",
            "      ],\n",
            "      \"y\": [\n",
            "        4,\n",
            "        -5,\n",
            "        6\n",
            "      ],\n",
            "      \"point\": 10\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'linear_regression', 'arguments': {'x': [1, 2, -3], 'y': [4, -5, 6], 'point': 10}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_movie_director\",\n",
            "    \"arguments\": {\n",
            "      \"movie_name\": \"Avatar\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_movie_director', 'arguments': {'movie_name': 'Avatar'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"maxPoints\",\n",
            "    \"arguments\": {\n",
            "      \"points\": [\n",
            "        [\n",
            "          1,\n",
            "          1\n",
            "        ],\n",
            "        [\n",
            "          2,\n",
            "          2\n",
            "        ],\n",
            "        [\n",
            "          3,\n",
            "          4\n",
            "        ],\n",
            "        [\n",
            "          5,\n",
            "          5\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'maxPoints', 'arguments': {'points': [[1, 1], [2, 2], [3, 4], [5, 5]]}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_movie_director\",\n",
            "    \"arguments\": {\n",
            "      \"movie_name\": \"Pulp Fiction\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_movie_director', 'arguments': {'movie_name': 'Pulp Fiction'}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,665 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,666 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,666 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,667 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,668 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,670 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,670 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,727 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,728 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,729 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,729 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,730 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,731 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,732 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,733 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,762 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,764 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,765 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,765 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,765 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,766 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,767 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,768 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_movie_rating\",\n",
            "    \"arguments\": {\n",
            "      \"movie_name\": \"Avatar\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_movie_rating', 'arguments': {'movie_name': 'Avatar'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"maxPoints\",\n",
            "    \"arguments\": {\n",
            "      \"points\": [\n",
            "        [\n",
            "          1,\n",
            "          1\n",
            "        ],\n",
            "        [\n",
            "          2,\n",
            "          3\n",
            "        ],\n",
            "        [\n",
            "          4,\n",
            "          6\n",
            "        ],\n",
            "        [\n",
            "          5,\n",
            "          5\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'maxPoints', 'arguments': {'points': [[1, 1], [2, 3], [4, 6], [5, 5]]}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"get_movie_rating\",\n",
            "    \"arguments\": {\n",
            "      \"movie_name\": \"Pulp Fiction\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'get_movie_rating', 'arguments': {'movie_name': 'Pulp Fiction'}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-18 17:17:19,977 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2025-04-18 17:17:19,977 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:19,978 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,979 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,980 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,980 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,981 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,981 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,981 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,982 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,982 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,983 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,984 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,985 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,986 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:19 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:19,987 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,000 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:20,001 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,002 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,002 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,003 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,004 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,005 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,006 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,058 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:20,060 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,061 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,061 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,062 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,063 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,064 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,065 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_nutritional_needs\",\n",
            "    \"arguments\": {\n",
            "      \"weight\": 100.0,\n",
            "      \"height\": 170.0,\n",
            "      \"age\": 30.0,\n",
            "      \"gender\": \"male\",\n",
            "      \"activity_level\": 1,\n",
            "      \"goal\": \"lose\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_nutritional_needs', 'arguments': {'weight': 100.0, 'height': 170.0, 'age': 30.0, 'gender': 'male', 'activity_level': 1, 'goal': 'lose'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_nutritional_needs\",\n",
            "    \"arguments\": {\n",
            "      \"weight\": 59.0,\n",
            "      \"height\": 170.0,\n",
            "      \"age\": 80.0,\n",
            "      \"gender\": \"female\",\n",
            "      \"activity_level\": 4,\n",
            "      \"goal\": \"lose\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_nutritional_needs', 'arguments': {'weight': 59.0, 'height': 170.0, 'age': 80.0, 'gender': 'female', 'activity_level': 4, 'goal': 'lose'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_investment_value\",\n",
            "    \"arguments\": {\n",
            "      \"initial_investment\": 1000000,\n",
            "      \"annual_contribution\": 1000,\n",
            "      \"years\": 3,\n",
            "      \"annual_return\": 0.1,\n",
            "      \"inflation_rate\": [0.01, 0.04, 0.04]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_investment_value', 'arguments': {'initial_investment': 1000000, 'annual_contribution': 1000, 'years': 3, 'annual_return': 0.1, 'inflation_rate': [0.01, 0.04, 0.04]}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"calculate_investment_value\",\n",
            "    \"arguments\": {\n",
            "      \"initial_investment\": 10000,\n",
            "      \"annual_contribution\": 1000,\n",
            "      \"years\": 5,\n",
            "      \"annual_return\": 0.05,\n",
            "      \"inflation_rate\": [0.01, 0.02, 0.03, 0.04, 0.04]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'calculate_investment_value', 'arguments': {'initial_investment': 10000, 'annual_contribution': 1000, 'years': 5, 'annual_return': 0.05, 'inflation_rate': [0.01, 0.02, 0.03, 0.04, 0.04]}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-18 17:17:20,222 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:20,223 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,224 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,224 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,225 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,225 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,226 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,227 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,338 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:20,339 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,340 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,340 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,341 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,341 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,343 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,343 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,372 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:20,374 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,375 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,375 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,376 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,377 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,378 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,379 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,429 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"polygon_area\",\n",
            "    \"arguments\": {\n",
            "      \"vertices\": [\n",
            "        [\n",
            "          1,\n",
            "          2\n",
            "        ],\n",
            "        [\n",
            "          3,\n",
            "          4\n",
            "        ],\n",
            "        [\n",
            "          1,\n",
            "          3\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'polygon_area', 'arguments': {'vertices': [[1, 2], [3, 4], [1, 3]]}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"book_room\",\n",
            "    \"arguments\": {\n",
            "      \"room_type\": \"deluxe\",\n",
            "      \"price\": 1000.0,\n",
            "      \"check_in_date\": \"08-11-2024\",\n",
            "      \"check_out_date\": \"08-15-2024\",\n",
            "      \"customer_id\": \"123\"\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'book_room', 'arguments': {'room_type': 'deluxe', 'price': 1000.0, 'check_in_date': '08-11-2024', 'check_out_date': '08-15-2024', 'customer_id': '123'}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"polygon_area\",\n",
            "    \"arguments\": {\n",
            "      \"vertices\": [\n",
            "        [\n",
            "          1,\n",
            "          2\n",
            "        ],\n",
            "        [\n",
            "          3,\n",
            "          4\n",
            "        ],\n",
            "        [\n",
            "          1,\n",
            "          4\n",
            "        ],\n",
            "        [\n",
            "          3,\n",
            "          7\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'polygon_area', 'arguments': {'vertices': [[1, 2], [3, 4], [1, 4], [3, 7]]}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:20,431 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,432 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,433 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,435 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,437 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"book_room\",\n",
            "    \"arguments\": {\n",
            "      \"room_type\": \"king\",\n",
            "      \"price\": 10000.0,\n",
            "      \"check_in_date\": \"12-11-2023\",\n",
            "      \"check_out_date\": \"08-15-2024\",\n",
            "      \"customer_id\": \"123\",\n",
            "      \"discount_code\": null\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'book_room', 'arguments': {'room_type': 'king', 'price': 10000.0, 'check_in_date': '12-11-2023', 'check_out_date': '08-15-2024', 'customer_id': '123', 'discount_code': None}}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-18 17:17:20,683 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:20,684 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,685 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,685 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,686 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,686 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,688 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,689 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,736 - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: utils.py:1177 - Wrapper: Completed Call, calling success_handler\n",
            "2025-04-18 17:17:20,738 - INFO - Wrapper: Completed Call, calling success_handler\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,739 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,739 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,740 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,740 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "Processing BFCL: 100%|██████████| 100/100 [00:09<00:00, 10.20it/s]\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,742 - INFO - selected model name for cost calculation: openai/google/gemma-3-4b-it\n",
            "\n",
            "\u001b[92m17:17:20 - LiteLLM:INFO\u001b[0m: cost_calculator.py:622 - selected model name for cost calculation: google/gemma-3-4b-it\n",
            "2025-04-18 17:17:20,743 - INFO - selected model name for cost calculation: google/gemma-3-4b-it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"order_food\",\n",
            "    \"arguments\": {\n",
            "      \"item\": [\n",
            "        \"burger\"\n",
            "      ],\n",
            "      \"quantity\": [\n",
            "        10\n",
            "      ],\n",
            "      \"price\": [\n",
            "        5.0\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"order_food\",\n",
            "    \"arguments\": {\n",
            "      \"item\": [\n",
            "        \"ice cream\"\n",
            "      ],\n",
            "      \"quantity\": [\n",
            "        7\n",
            "      ],\n",
            "      \"price\": [\n",
            "        2.0\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'order_food', 'arguments': {'item': ['burger'], 'quantity': [10], 'price': [5.0]}}, {'name': 'order_food', 'arguments': {'item': ['ice cream'], 'quantity': [7], 'price': [2.0]}}]\n",
            "Model raw response: ```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"order_food\",\n",
            "    \"arguments\": {\n",
            "      \"item\": [\n",
            "        \"dumplings\"\n",
            "      ],\n",
            "      \"quantity\": [\n",
            "        101\n",
            "      ],\n",
            "      \"price\": [\n",
            "        0.1\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"order_food\",\n",
            "    \"arguments\": {\n",
            "      \"item\": [\n",
            "        \"rice bowl\"\n",
            "      ],\n",
            "      \"quantity\": [\n",
            "        20\n",
            "      ],\n",
            "      \"price\": [\n",
            "        10.0\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "Parsed plan: [{'name': 'order_food', 'arguments': {'item': ['dumplings'], 'quantity': [101], 'price': [0.1]}}, {'name': 'order_food', 'arguments': {'item': ['rice bowl'], 'quantity': [20], 'price': [10.0]}}]\n"
          ]
        }
      ],
      "source": [
        "# Generate plans in parallel\n",
        "bfcl_df['bfcl_planned_calls'] = None\n",
        "def process_row(args):  idx, instr, tools = args;  return idx, generate_single_shot_plan(instr, tools, model, api_base, use_system_prompt)\n",
        "from tqdm import tqdm\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    args_list = [(i, row['instruction'], row['tool_dicts']) for i, row in bfcl_df.iterrows()]\n",
        "    for idx, plan in tqdm(executor.map(process_row, args_list), total=len(args_list), desc='Processing BFCL'):\n",
        "        bfcl_df.at[idx, 'bfcl_planned_calls'] = plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results\n",
        "bfcl_df = bfcl_df.drop(columns=['tools','tool_dicts'])\n",
        "bfcl_df.to_parquet('bfcl_eval_results.parquet', engine='fastparquet')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
